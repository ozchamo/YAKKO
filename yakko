#!/bin/bash

YAKKOVERSION=4.20
YAKKODATE=20220526.1733

###########################################################################
# YAKKO - Yet another KVM Konfigurator for OpenShift
# AUTHOR: Daniel Cifuentes
# ------------------------------------------------------------------------ 
# A COVID Pandemic Confinement project - Circa 09/2020 
# ------------------------------------------------------------------------ 
# Inspirational documentation for this:
# https://github.com/eitchugo/openshift-libvirt/blob/master/OpenShift_4_libvirt_install_1_master.md
###########################################################################

# This will be checked always on install
TESTEDPLATFORMS="fedora 35, fedora 36, rhel 8.5, rhel 8.6 and rhel 9.0"

##########################################################################
# DESIRED FEATURES:
# - Add a remote node!!!!
# - (COMPLEX) Work on non-virtual network. That may be a project for the next pandemic
##########################################################################


######## THESE CAN BE USER CONFIGURABLE FOR FURTHER TESTING.At your own risk.
MASTERNODECOUNT=3  # Unless instructed otherwise, OCP 4.8+
MASTERVCPUS=4      # Recommended 4
WORKERVCPUS=2      # Recommended 2
MASTERDISKSIZE=30  # Disk image size for master, GB
WORKERDISKSIZE=20  # Disk image size for worker, GB
MAXNODEVCPUS=4     # Max number of allowable CPUs for a worker node
MAXWORKERNODES=5   # Max number of worker nodes allowed at cluster BUILD time, after that, no limit 
REDUCEPROMETHEUS=N # Prometheus pod RAM can be reduced, which makes sense, change to N if not desired. 
                   # You can change this with MANUAL build too.
 
######### THESE CAN BE CHANGED INTERACTIVELY #############################
# OpenShift 4.9: https://docs.openshift.com/container-platform/4.9/installing/installing_bare_metal/installing-bare-metal.html
SINGLEMASTERRAMSIZE=32000 # Recommended 8192. 6000 not enough
# OpenShift 4.9: https://docs.openshift.com/container-platform/4.9/installing/installing_sno/install-sno-preparing-to-install-sno.html
THREEMASTERRAMSIZE=16000 # Recommended 8192. 6000 not enough
WORKERRAMSIZE=8000 # Recommended ... 2048!? Worked well with 5Gi. Use as 8 to do some real work
MINWORKERRAMSIZE=4000 # This boundary has been changing as OCP revs up!
##########################################################################

# The BASEMACADDRESS is missing the last two entries/hexes. The second to last is calculated on
# the last number of the BASEMACNETWORK, in case two clusters run on the same box, to prevent 
# virtual network confusion, even if perhaps... it may work without conflict. Original code had
# this number as 52:54:00:4a:66 but now the last hex number will be the 3 network digit i.e. 140 which is "8c"
COREMACADDRESS="52:54:00:4a"
PROXYADDRESS=1  # So that the overall "proxy" to the cluster is BASENETWORK.PROXY e.g. 192.168.140.1
WEBSERVERPORT=8080 # This may have to change

# File and directory variables used throughout
YAKKONAME=yakko   # In case we want to change the name of the script
OCPWGETTMP=/tmp/ocpsetupwget.$$.tmp
OCPVMDISKDIR=/var/lib/libvirt/images
CLUSTERDOMAIN=localdomain  
DHCPXMLTMPFILE=/tmp/yakkodhcpxmlline.$$.tmp
HTPASSWDFILE=/tmp/ocp-htpasswd.$$

# Cluster build progression variables
YAKKOSTAGE=0
STAGEPROGRESS=0
YAKKOREBUILD=0 
AUTOSETUP=0 # 1 is Auto, 0 is manual
YAKKOTEXTCOLOR=brightblue
DELETECLUSTERMODE=1  # This goes to 0 when we delete the entire cluster with deletecluster
DELETECLUSTERFORCE=1
ADDNODETIMEOUT=900 # If I cannot add a node within timeout (this multiplied by number of nodes)
KUBEADMIN=kubeadmin # once deleted this is stored as "" in CLUSTERCONFIGFILE
PAUSEFORCONFIGEDIT=1
VNCPORT=5905 # We'll leave the firt few ports open for traditional VNC uses
BOOTSTRAPWAITTIME=120 # Time to wait after bootstrap has finished and we delete the resource

# Some parameter options
YAKKOINFRAOPTIONS=" startcluster / stopcluster / addnode / deletenode / nodelogs / sshtonode / changeaccess / restartservices / listresources / purgedownloads / resizeram / nfsshare / deletecluster "
YAKKOCLUSTEROPTIONS=" htpasswd / useradd / userdelete / mastersched / nodelabel / localregistry / nfsregistry / nfsmap / ingresscert / approvecsrs / yakkotest "

# And some facts...
SYSTEMPHYSICALRAM=$(free -m | grep Mem:|awk '{ print $2 }')

# Decorations
SEPARATIONLINE="__________________________________________________________________________"

# Some useful constants
NUMBERRE='^[0-9]+$' # Number - regular expression

################ A FEW INITIALISATION FUNCTIONS ################################################

populate-clusterconfigfile() {
	# CLUSTERCONFIGFILE CREATION
	# Populate the config file with some references for future calls

	# this is an emergency break, has happened!
	[ -z "${CLUSTERNAME}" ] && check-for-error-and-exit 0 "Cluster name is blank - saving cluster config file"

	{
		echo "CLUSTERNAME=${CLUSTERNAME}" 
		echo "CLUSTERDOMAIN=${CLUSTERDOMAIN}"
		echo "CLUSTERFQDN=${CLUSTERFQDN}"
		echo "CLUSTERWEBURL=${CLUSTERWEBURL}"
		echo "CLUSTERAPIURL=${CLUSTERAPIURL}"
		echo "YAKKOSTAGE=0"
		echo "CLUSTERSETUPDIR=${CLUSTERSETUPDIR}" 
		echo "NETWORKNAME=${NETWORKNAME}" 
		echo "OCPGETCLIENTVERSION=${OCPGETCLIENTVERSION}"
		echo "OCPDOWNLOADCLIENT=${OCPDOWNLOADCLIENT}"
		echo "OCPINSTALLVERSION=${OCPGETCLIENTVERSION}" 
		echo "OCPINSTALLMINORVERSION=${OCPINSTALLMINORVERSION}"
		echo "OCPDOWNLOADIMAGE=${OCPDOWNLOADIMAGE}"
		echo "NETWORKXML=$CLUSTERSETUPDIR/${NETWORKNAME}.xml"
		echo "NETWORKADDRESSSLOT=20"
		echo "NODECOUNT=0"
		echo "OCPSSHKEY=${OCPSSHKEY}"
		echo "BUILTWITHYAKKOVERSION=${YAKKOVERSION}"
		echo "NOTICEYAKKOVERSION=${YAKKOVERSION}"
		echo "YAKKOHOSTIP=${YAKKOHOSTIP}"
		echo "VNCPORT=${VNCPORT}"
		# There two exist in lastclusterconfig too, but resizing will change it here only
		echo "MASTERRAMSIZE=${MASTERRAMSIZE}"
		echo "WORKERRAMSIZE=${WORKERRAMSIZE}"
		echo "HAPROXYACCESS=${HAPROXYACCESS}"
		echo "SYSTEMSTUBFILE_DNSMASQ=${SYSTEMSTUBFILE_DNSMASQ}"
		echo "SYSTEMSTUBFILE_NETWORKMANAGER=${SYSTEMSTUBFILE_NETWORKMANAGER}"
		echo "SYSTEMSTUBFILE_RESOLVED=${SYSTEMSTUBFILE_RESOLVED}"
		echo "SYSTEMSTUBFILE_HAPROXY=${SYSTEMSTUBFILE_HAPROXY}"
		echo "SYSTEMSTUBFILE_HTTPD=${SYSTEMSTUBFILE_HTTPD}"
		echo "STUBFILES=${STUBFILES}"
		echo "SELINUXSTATE=${SELINUXSTATE}"
		
	} > ${CLUSTERCONFIGFILE}

	source ${CLUSTERCONFIGFILE}
}

populate-yakkodefaults() {
  
	# this is an emergency break, has happened!
	[ -z "${CLUSTERNAME}" ] && check-for-error-and-exit 0 "Cluster name is blank - saving default config file"

	{
		echo "CLUSTERNAME=${CLUSTERNAME}" 
		echo "CLUSTERDOMAIN=${CLUSTERDOMAIN}"
		echo "OCPVMDISKDIR=${OCPVMDISKDIR}"
		echo "MASTERNODECOUNT=${MASTERNODECOUNT}"
		echo "WORKERNODECOUNT=${WORKERNODECOUNT}"
		echo "CLUSTERPROXY=${CLUSTERPROXY}"
		echo "WEBSERVERIP=${WEBSERVERIP}"
		echo "MASTERRAMSIZE=${MASTERRAMSIZE}"
		echo "WORKERRAMSIZE=${WORKERRAMSIZE}"
		echo "PAUSEFORCONFIGEDIT=${PAUSEFORCONFIGEDIT}"
	
		# NETWORK CONFIGURATION
		echo "BASEMACADDRESS=${BASEMACADDRESS}"
		echo "BASENETWORK=${BASENETWORK}"
		echo "YAKKOHOSTIP=${YAKKOHOSTIP}"
		echo "HAPROXYACCESS=${HAPROXYACCESS}"

		# This will be used for creating nodes later on so that any new nodes start at $NETWORKADDRESSSLOT
		# Note that bootstrap and masters have fixed numbers for IP and MAC
		# 52:54:00 is KVM/QEMU default    4A:66:00 is a transliteration of YAKKO ;)
		# All worker nodes will begin with MAC and IP $NETWORKADDRESSSLOT
		echo "NETWORKADDRESSSLOT=20"
		echo "BOOTSTRAPMAC=${BASEMACADDRESS}:09"
		echo "MASTER0MAC=${BASEMACADDRESS}:10"
		echo "MASTER1MAC=${BASEMACADDRESS}:11"
		echo "MASTER2MAC=${BASEMACADDRESS}:12"
		echo "BOOTSTRAPIP=${BASENETWORK}.9"
		echo "MASTER0IP=${BASENETWORK}.10"
		echo "MASTER1IP=${BASENETWORK}.11"
		echo "MASTER2IP=${BASENETWORK}.12"

	} > ${YAKKODEFAULTS}

	source ${YAKKODEFAULTS}

}

################ A FEW REUSABLE FUNCTIONS ################################################

print-yakko-header() {
	# Here comes the colorful YAKKO header!
	clear -x
	print-in-colour ${YAKKOTEXTCOLOR} ${SEPARATIONLINE}
	echo
	print-in-colour ${YAKKOTEXTCOLOR} " YAKKO: Yet Another KVM Konfigurator for Openshift (Ver. ${YAKKOVERSION})"
	print-in-colour ${YAKKOTEXTCOLOR} ${SEPARATIONLINE}
	echo
}

print-in-colour() {

	# $1 is the color:
	case "$1" in
		"red") TEXTCOLOR=1;;
		"green") TEXTCOLOR=2;;
		"lightblue") TEXTCOLOR=6;;
		"white") TEXTCOLOR=7;;
		"brightblue") TEXTCOLOR=14;;
		"orange") TEXTCOLOR=9;;
	esac
	
        tput setaf ${TEXTCOLOR};tput bold
	shift
	echo -e "$*"
        tput sgr0
}

print-in-blink() {

	# $1 is the message
	MESSAGE=$1
	echo -e $(tput blink)${MESSAGE}$(tput sgr0)
	echo

}


print-time-elapsed() {

	TIMEELAPSEDSECS=$(( $SECONDS - $TIMESTART))
	TIMEELAPSEDMINS=$(( $TIMEELAPSEDSECS / 60 ))

	print-in-colour ${YAKKOTEXTCOLOR} "Time elapsed: " ${TIMEELAPSEDMINS} mins $(( ${TIMEELAPSEDSECS} - (${TIMEELAPSEDMINS} * 60 ) )) secs

}

print-question-separator() {
	echo
	echo
	tput bold
	#echo "---- $((QUESTIONNUM++))/${QUESTIONSTOTAL}  $* ----"
	print-in-colour lightblue "[$((QUESTIONNUM++))/${QUESTIONSTOTAL}] $*:" 
	tput sgr0
}

blank-line() {
	
	# This little trick let's you overwrite a line with the next echo

	echo -ne "\r\e[0K"
}


ask-user() {

        # $1 is the string to display
	# $2 is the default if user presses <ENTER>
        # $3 as "noauto" ignores the AUTOSETUP flag
	# Returns 0 for YES and 1 for NO
        DIALOGUETEXT=$1
	DEFAULTRESPONSE=$2
        NOAUTO=$3

	# We are within a stage, so we need to setup a trap to rollback
	[ -n "${CURRENTSTAGE}" ] && trap "echo; echo 'Input interrupted. Aborting.'; ${CURRENTSTAGE} rollback; echo; cleanup-and-exit" SIGINT

	if [ $AUTOSETUP -eq 1 -a "$NOAUTO" == ""  ]
	then 
		# if in AUTO mode return DEFAULTRESPONSE
                if [ "$DEFAULTRESPONSE" == "y" -o "$DEFAULTRESPONSE" == "Y" ]
                then
                        return 0
                elif [ "$DEFAULTRESPONSE" == "n" -o "$DEFAULTRESPONSE" == "N" ]
                then
                        return 1 # 1 = false!
		fi
	fi

	# We use AURESPONSE as "Ask User Response" - because RESPONSE is global :(
 	while true
        do
                echo -n "$DIALOGUETEXT (Y/N) [$DEFAULTRESPONSE]? "
                read AURESPONSE

		[ -z "${AURESPONSE}" ] && AURESPONSE=${DEFAULTRESPONSE} 

                if [ "$AURESPONSE" == "y" -o "$AURESPONSE" == "Y" ]
                then
                        return 0
                elif [ "$AURESPONSE" == "n" -o "$AURESPONSE" == "N" ]
                then
                        return 1 # 1 = false!
                else
                        echo "Invalid reponse [$AURESPONSE]."
                fi
        done
}


cleanup-and-exit() {

	local TEXTCOLOUR=$1
	local TEXTMESSAGE=$2

	if [ -n "$TEXTMESSAGE" ]
	then
		print-in-colour $TEXTCOLOUR $TEXTMESSAGE
		echo
	fi
	
	exit
}


check-for-error-and-exit() {
	# Something bad got caught somewhere - write this out and abort
	# $1 is the error code passed (0 is good)
	# $2 is a string to report

	# If we are already in a rollback don't repeat!
	if [ "${ROLLBACKACTIVE}" == "Y"  ] 
	then
		return
	fi

	# There is no error found
	[ "$1" -eq 0 ] && return

	# Else... Doom!
	echo
	print-in-colour red  "ERROR: $2. Exiting."
	echo

	if [ -n "${CURRENTSTAGE}" ]
	then
		#We are within a stage so we rollback
		ask-user "Rollback steps of this stage (y) or leave for debugging (n)" "Y" noauto

		[ $? -eq 0 ] && ${CURRENTSTAGE} rollback 
	fi
	echo
	cleanup-and-exit
}


install-package-if-missing() {
	
	# $1 is the package to check for
	PACKAGE=$1

	dnf list installed | grep $PACKAGE > /dev/null 2>&1
	[ $? -ne 0 ] && {
		echo "Installing package [$PACKAGE]"
		dnf -y install $PACKAGE
		check-for-error-and-exit $? "Failed to install package [$PACKAGE]"
	}
}


set-selinux-state() {

	selinuxenabled > /dev/null 2>&1
	if [ $? -eq 0 ]
	then
		SELINUXSTATE=0
	else
		print-in-colour orange "SELinux is disabled in this system"
		SELINUXSTATE=1
	fi
}


get-node-fqdn()
{
	# This is a safety measure...
	# This function should be called as
	# $(get-node-fqdn $NODENAME)
	# it returns a nodename with the FQDN attached

	FQDNNODENAME=$1
	echo ${FQDNNODENAME} | grep ${CLUSTERFQDN} > /dev/null 2>&1
	[ $? -ne 0 ] && FQDNNODENAME=${FQDNNODENAME}.${CLUSTERFQDN}

	echo ${FQDNNODENAME}
}


check-node-name()
{
	# Quick function to check that user is passing valid yakk nodename
	# check-node-name CHECKNODENAME [exit]

	# Return 0 if the VM name belongs to the cluster
	# Return 1 if the VM name does not belong to the cluster
	# Return 2 if the VM name does not exist!

	CHECKNODENAME=$1
	EXITONINVALID=$2

	virsh list --all | grep ${CHECKNODENAME}  > /dev/null 2>&1
	if [ $? -eq 1 ]
	then
		# There is no such nodename
		return 2
	fi

	# If something skips the below check, buy the lotto with the nodename ASCIIs...
	virsh list --all | awk '{print $2}' | grep ${CHECKNODENAME} | grep -E '^master-|^node-|^bootstrap' | grep "${CLUSTERFQDN}"  > /dev/null 2>&1
	if [ $? -eq 0 ]
	then
		# Node name belongs to YAKKO setup
		return 0
	else
		[ "${EXITONINVALID}" == "exit" ] && {
			echo
			echo "Invalid node name [$CHECKNODENAME]. Exiting..."
			echo
			cleanup-and-exit
		}
		return 1
	fi
}


delete-kvm-machine()
{
	# This is a safety measure...
	NODETODELETEFQDN=$(get-node-fqdn $1)

	check-node-name $NODETODELETEFQDN
	RESULT=$?

	if [ $RESULT -eq 0 ]
	then
		virsh destroy ${NODETODELETEFQDN} 2>/dev/null #Errors when machine is not running... so what.
		virsh undefine --domain ${NODETODELETEFQDN} --remove-all-storage
	fi

	if [ $RESULT -eq 1 ]
	then
		echo "ERROR: Tried to delete non-cluster KVM machine: [${NODETODELETEFQDN}]"
		#exit
	fi
}

get-yakko-host-ip() {

	# $1 is "" or "notifychange" so that we can send the message that the IP address has changed
	# "" is used only during QUESTIONS

	NOTIFYCHANGE=$1
	for PHYSICALNWPORT in $(ls -l /sys/class/net/ | grep -v virtual | grep -v total | awk '{print $9}')
	do
		for CONNECTEDNWPORT in $(ip -br -4 addr show | grep UP |awk '{print$1}')
		do
			if [ $PHYSICALNWPORT == $CONNECTEDNWPORT ]
			then 
				YAKKOMAINHOSTPORT=$CONNECTEDNWPORT
				break
			fi
		done
		if [ -n "$YAKKOMAINHOSTPORT" ]
		then
			break
		fi
	done

	# This echoes the result to be captured typically into $YAKKOHOSTIP but doesn't have to be...
	# This is useful when 
	# 1. The cluster is being configured for the first time
	# 2. The cluster is being rebooted and the IP address may changed (think demo laptop)

	CURRENTYAKKOHOSTIP=$(ip -br -4 addr show | grep ${YAKKOMAINHOSTPORT} | awk '{print $3}' | cut -f1 -d/)

	# This parameter is just for flaggin a change message

	YAKKOHOSTIPCHANGED=1
	if [ "${CURRENTYAKKOHOSTIP}" != "${YAKKOHOSTIP}" ] 
	then
		if [ "$NOTIFYCHANGE" == "notifychange" ]
		then
			echo
			print-in-colour orange "ALERT: The IP address of the host has changed [${YAKKOHOSTIP} -> ${CURRENTYAKKOHOSTIP}] "
			echo
		fi

		while true
		do
			echo -n  "Enter the IP address of this host on your network [${CURRENTYAKKOHOSTIP}]: "
			read RESPONSE
	
			if [ -n "${RESPONSE}" ]
			then
				if [[ $RESPONSE =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]
				then
					ping -c 1 $RESPONSE > /dev/null 2>&1
					if [ $? -ne 0 ]
					then
						echo "ERROR: Could not identify this host IP address via PING. Check your IP address!"
						echo
						continue
					fi
					YAKKOHOSTIP=$RESPONSE
				else
 					echo "That's not a valid IP address!"
					echo
					continue
				fi
	
				YAKKOHOSTIP=$RESPONSE
				break
			else
				YAKKOHOSTIP=${CURRENTYAKKOHOSTIP}
				break
			fi
		done
		YAKKOHOSTIPCHANGED=0
	fi
	# get-yakko-host-ip is used in QUESTIONS so technically the below is out of place there
	# But, since there is nothing to update at the point, that's OK, it won't do anything
	if [ $YAKKOHOSTIPCHANGED -eq 0 ]
	then
		update-yakko-host-ip
		return 0 # 1 means IP address changed
	else
		return 1 # 0 means IP address did not change
	fi
}

advance-stage-progression() {

	# We skip all stages until we get to the one we were in...
	((++STAGEPROGRESS))

	#We'll get a timestamp of the first stage for a final run report
	[ -z "${TIMESTART}" ] && TIMESTART=$SECONDS

	if [ ${STAGEPROGRESS} -lt ${YAKKOSTAGE} ]
	then
		return 0
	else
		echo
		print-in-colour ${YAKKOTEXTCOLOR} ${SEPARATIONLINE}
		echo
		print-in-colour ${YAKKOTEXTCOLOR} "STAGE ${STAGEPROGRESS}: $1 (Time start: $(date +%H:%M%p))"
		echo
	
		# We write the stage we are at so that we can return if desired
		sed -i "/YAKKOSTAGE.*/c\YAKKOSTAGE=${STAGEPROGRESS}" ${CLUSTERCONFIGFILE} 2>/dev/null

		# Since this stage will progress, we capture CTRL-C to rollback 
		# we set it to 0 so that the running advance-stage can call itself back
		trap 'echo; ${FUNCNAME[0]} rollback; echo; exit' SIGINT

		# And we set the CURRENTSTAGE in case we have to rollback from a deeper function, to ease lookup
		# This works because advance-stage-progression CAN ONLY be called within a stage, and at the begining!
		CURRENTSTAGE=${FUNCNAME[1]}

		return 1
	fi
}


rollback-stage-progression() {
	echo
	# We set this variable so that YAKKO knows that we are in aborting mode
	# Particularly useful in check-for-error-and-exit as is may well call rollback
	# again, and end up in a loop
	ROLLBACKACTIVE=Y
	print-in-colour orange "ROLLBACK STAGE: $*"
}


get-node-list() {

	# call: get-node-list <all|active> [print]
	# returns the requested node list in NODELIST

	if [ $1 == "all" ]
	then
		NODELIST=" $(virsh list --all --name | grep -e "master-" -e "node-" -e "bootstrap" | grep "${CLUSTERFQDN}") "
	fi

	if [ $1 == "active" ]
	then
		NODELIST=" $(virsh list --name | grep -e "master-" -e "node-" -e "bootstrap" | grep "${CLUSTERFQDN}") "
	fi

	if [ "$2" == "print" ]
	then
		#we also print the list in columns
		for NODE in ${NODELIST}
		do
			echo ${NODE}
		done
	fi
}

pick-a-node() {

	# Call: pick-a-node <string-to-display-for-chooser-query>
	while true
	do
		echo "Available nodes for this action are:"
		get-node-list active print
		echo
		echo -n "$1: "
		read NODENAME
		[ $? -eq 0 ] && break
	done
}
	

compose-html-cluster-report() {

	# This here builds a landing page for the info of the last cluster built
	# the web server left a file index.html sitting there

	# To be honest, this just makes the whole thing look more professional ;)

	cat <<HTMLCONTENT > ${IMAGEREPO}/index.html

<HTML>
<HEAD>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<LINK REL="stylesheet" HREF="https://fonts.googleapis.com/css?family=Saira+Condensed">
<STYLE>
                H2 {
                        font-family: 'Saira Condensed', sans-serif;
                                font-size: 34px;
                }
                P {
                        font-family: 'Saira Condensed', sans-serif;
                        font-size: 24px;
                }
</STYLE>
</HEAD>

<BODY>

<A HREF=https://ozchamo.github.io/YAKKO/> <IMG SRC="https://ozchamo.github.io/YAKKO/yakkologo.png" height=400 ALIGN="Left" style="margin-right: 30;"> </A>
<BR>
<H2>OpenShift Cluster [$CLUSTERNAME] is available on this server:</H2>

<P>
<B>Console URL:</B> &nbsp;<A HREF="${CLUSTERWEBURL}" TARGET="_blank">${CLUSTERWEBURL}</A>
<BR>
<B>API server:</B> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;${CLUSTERAPIURL}</P>

<P>Administrator: kubeadmin
<BR>
Password: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$(cat ${CLUSTERSETUPDIR}/auth/kubeadmin-password)<BR>
<BR>
(Version: ${OCPINSTALLVERSION} &nbsp;&nbsp;Build date: $(echo ${CLUSTERCOMPLETE} | awk '{print $4}') &nbsp;&nbsp; Hostdir: $(echo ${CLUSTERCOMPLETE} | awk '{print $6}'))
</P>
</BODY>
</HTML>

HTMLCONTENT

}


check-cluster-state() {

	# This is only executed at the end of the process or on subsequent calls
	source ${CLUSTERCONFIGFILE}

	# If the web console is available, offer info for it regardless of the output above
	echo -n " Please wait - checking OCP cluster console availability..."
	wget -O $OCPWGETTMP ${CLUSTERWEBURL} --no-check-certificate -4 > /dev/null 2>&1
	RESULTCONSOLE=$?
	blank-line

	# VERSION 1.1 - Check virtual network status
	virsh net-list --all | grep ${NETWORKNAME} | grep " active" >/dev/null 2>&1
	if [ $? -ne 0 ]
	then
		print-in-blink "ALERT: The virtual network (${NETWORKNAME}) does not appear to be operational. Check status with 'virsh net-list --all'"
		echo
		cleanup-and-exit
	fi

	# VERSION 1.1 - Check HAproxy status
	systemctl status haproxy >/dev/null 2>&1
	if [ $? -ne 0 ]
	then
		print-in-blink " ALERT: HAproxy seems to be off-line. Check status with 'systemctl status haproxy'"
		echo
		cleanup-and-exit
	fi

	check-cluster-power exit

	#check-oc-credentials
	check-cluster-api # this is technically unnecessary as check-oc-credentials will bomb out if there is not API server anyway
	RESULTSERVER=$?

	CURRENTCLUSTERVERSION=$(${OCCOMMAND} get clusterversion 2>&1 | grep -v "^NAME")

	echo $CURRENTCLUSTERVERSION | grep "Forbidden\|error\|logged" >/dev/null 2>&1
	if [ $? -ne 0 ]
	then
		echo " CLUSTER: ${CLUSTERFQDN}  (Ver: $(${OCCOMMAND} get clusterversion | grep -v "^NAME" | awk '{print $2}')  Built: $(echo ${CLUSTERCOMPLETE} | awk '{print $4}'))"   
	else
		echo " CLUSTER: ${CLUSTERFQDN}  (Version not available - Built: $(echo ${CLUSTERCOMPLETE} | awk '{print $4}'))"  
	fi
	echo

	echo "               state      "
	if [ $RESULTCONSOLE -eq 0 ] 
	then
		echo " Web Console:  [ ✔ ]  ${CLUSTERWEBURL}"
	else
		echo " Web Console:  [ ✘ ]"
	fi

	if [ $RESULTSERVER -eq 0 ] 
	then
		echo " API Endpoint: [ ✔ ]  ${CLUSTERAPIURL}"
		echo " API Service:  [ ✔ ] "
	elif [ $RESULTSERVER -eq 1 ]
	then
		echo " API Endpoint: [ ✘ ]"
		echo " API Service:  [ ✔ ] "
	elif [ $RESULTSERVER -eq 2 ]
	then
		echo " API Endpoint: [ ✔ ]  ${CLUSTERAPIURL} "
		echo " API Service:  [ ✘ ]  (cannot execute 'oc' commands to check)"
		echo
		cleanup-and-exit orange "You need to be logged in to OpenShift (as admin) for additional information" 
	elif [ $RESULTSERVER -eq 3 ]
	then
		echo " API Endpoint: [ ✘ ] "
		echo " API Service:  [ ✘ ]  (cannot execute 'oc' commands to check)"
		echo
		cleanup-and-exit orange "You need to be logged in to OpenShift (as admin) for additional information"
	fi
	echo

	ACTIVEMASTERS=$(${OCCOMMAND} get nodes | grep "master-" | grep -c " Ready")
	TOTALMASTERS=$(${OCCOMMAND} get nodes | grep -c "master-")

	ACTIVENODES=$(${OCCOMMAND} get nodes | grep "node-" | grep -c " Ready" )
	TOTALNODES=$(${OCCOMMAND} get nodes | grep -c "node-")

	ACTIVEOPERATORS=$(${OCCOMMAND} get co | grep -v AVAILABLE | awk '{print $3}' | grep -c True)
	TOTALOPERATORS=$(${OCCOMMAND} get co | grep -cv AVAILABLE)

	echo " Active Masters:   ${ACTIVEMASTERS}/${TOTALMASTERS}"
	echo " Active Nodes:     ${ACTIVENODES}/${TOTALNODES} (workers/infra)"
	echo " Active Operators: ${ACTIVEOPERATORS}/${TOTALOPERATORS}"

	echo

	# VERSION 1.1 - Check for pending CSRs
	PENDINGCSRS=$(${OCCOMMAND} get csr 2>/dev/null | grep Pending | awk '{ print $1 }')
	if [ -n "${PENDINGCSRS}" ]
	then
		set $PENDINGCSRS
		print-in-blink " ALERT: There are [$#] Pending Certificate Signing Requests (CSRs) that need approval!"
		echo " You will need to issue 'yakko ops approvecsrs' to allow the cluster to come up."
		echo
	fi

	if [ -n "${YAKKOADMIN}" ]
	then
		echo " Administrator: ${YAKKOADMIN}  (Password not available for display)"
	else
		echo " Administrator: kubeadmin"
		echo " Password:      $(cat ${CLUSTERSETUPDIR}/auth/kubeadmin-password)"
	fi
	echo

	# VERSION 1.1 - report cluster access
	if [ $HAPROXYACCESS -eq 0 ]
	then
		echo " External access: ENABLED (to change: yakko infra changeaccess)"
	else
		echo " External access: DISABLED (to change: yakko infra changeaccess)"
	fi
	echo

	echo " - See yakko command usage --------> ${YAKKONAME} usage"
	echo " - Make infrastructure changes ----> ${YAKKONAME} infra <options>"
	echo " - Make operational changes -------> ${YAKKONAME} ops <options>"
	echo " - Use OpenShift's 'oc' command ---> source ocp-setup-env  (in this shell)"
	echo " - Retrieve basic cluster info from a browser: http://${YAKKOHOSTIP}:${WEBSERVERPORT}"
	if [ ${HAPROXYACCESS} -eq 0 ]
	then
		echo " - You can access this cluster from another system on your network," 
		echo "   just add [${YAKKOHOSTIP}] as a DNS server to that system"
	fi
	echo

	if [ -n "${NOTSETKUBECONFIG}" ]
	then
		echo " NOTE: You did not have KUBECONFIG set when you invoked YAKKO."
		echo "       Remember to use 'source ocp-setup-env' or adjust your environment accordingly!"
		echo
	fi

	cleanup-and-exit
}


build-ocp-node() {

	trap 'echo; ${FUNCNAME[1]} rollback; cleanup-and-exit' SIGINT

	#master example is  build-ocp-node master-X 52:00:84:12:34:56 $MASTERVCPUS $MASTERRAMSIZE $MASTERDISKSIZE master.ign

	NODEHOSTNAME=$1 

	# Check if httpd is up - I've hit this before
	systemctl is-active httpd > /dev/null 2>&1
	[ $? -ne 0 ] && {
		systemctl restart httpd
		check-for-error-and-exit $? "Provisioning HTTPD server seems to be inactive - cannot continue building node"
	}

	if [ "$2" == "auto" ]
	then
		# If $1 is not 'auto' it's because the MAC has been passed - for MASTER nodes only
		# If not, we're creating a new WORKER node, this calls for an auto mac and ip address
		NODEMACADDRESS=${BASEMACADDRESS}:${NETWORKADDRESSSLOT}

		# Update the networking tables for KVM
		# This function adds a dhcp entry in the virtual network table by inserting 
		# it in the DHCP scope XML definition and then restarting the network!
 		# <host mac='${NODEMAC}' name='nodename.${CLUSTERFQDN}' ip='${NODEIP}'/>"

		HOSTDHCPENTRY="<host mac=\"${NODEMACADDRESS}\" name=\"${NODEHOSTNAME}.${CLUSTERFQDN}\" ip=\"${BASENETWORK}.${NETWORKADDRESSSLOT}\"/>"
		sed -i "/<\/dhcp>/i\			${HOSTDHCPENTRY}" ${NETWORKXML}
		echo "${HOSTDHCPENTRY}" > ${DHCPXMLTMPFILE} #It's way too hard to pass this as an argument below!
		restart-virtual-network add-last ip-dhcp-host

		# while this will all be handled dynamically later on by update-haproxy-config-file
		# we must do this manually until the cluster is operational, i.e. when oc get nodes works!
		echo "Updating and restarting HAproxy"
		sed -i "/addingressrouternode80/a\    server ${NODEHOSTNAME} ${BASENETWORK}.${NETWORKADDRESSSLOT}:80 check inter 1s" ${STUBFILES}/haproxy.cfg
		sed -i "/addingressrouternode443/a\    server ${NODEHOSTNAME} ${BASENETWORK}.${NETWORKADDRESSSLOT}:443 check inter 1s" ${STUBFILES}/haproxy.cfg
		cp ${STUBFILES}/haproxy.cfg ${SYSTEMSTUBFILE_HAPROXY} 
		systemctl restart haproxy
		check-for-error-and-exit $? "Could not start HA Proxy, the cluster cannot function without this."

		# Update the last mac address used in the CLUSTERCONFIGFILE 
		((NETWORKADDRESSSLOT++))
		sed -i "/NETWORKADDRESSSLOT=/c\NETWORKADDRESSSLOT=${NETWORKADDRESSSLOT}" ${CLUSTERCONFIGFILE}
	else
		NODEMACADDRESS=$2
	fi

	NODEVCPUS=$3
	NODERAMSIZE=$4
	NODEDISKSIZE=$5
	IGNITIONFILE=$6

	VNCPORT=$(($VNCPORT+1))
	sed -i "/VNCPORT=/c\VNCPORT=${VNCPORT}" ${CLUSTERCONFIGFILE}

	echo
	print-in-colour lightblue "Building OCP node: ${NODEHOSTNAME}.${CLUSTERFQDN}"
	echo
	echo "Configuration:"
       	echo "- vCPUs:  ${NODEVCPUS}"
	echo "- Memory: ${NODERAMSIZE} MiB"
       	echo "- MAC Addr: ${NODEMACADDRESS}"

	if [ ${OCPINSTALLMINORVERSION} -ge 6 ]  # We are on OCP 4.6 or higher
	then
		virt-install \
			--memory=${NODERAMSIZE},maxmemory=${SYSTEMPHYSICALRAM} \
			--vcpus ${NODEVCPUS} \
			--cpu host \
			--disk path=${OCPVMDISKDIR}/${NODEHOSTNAME}.${CLUSTERFQDN}.qcow2,size=${NODEDISKSIZE},bus=virtio,format=qcow2 \
			--install kernel=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-live-kernel-x86_64,initrd=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-live-initramfs.x86_64.img,kernel_args_overwrite=yes,kernel_args="coreos.inst=yes coreos.inst.install_dev=vda coreos.live.rootfs_url=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-live-rootfs.x86_64.img coreos.inst.image_url=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-metal.x86_64.raw.gz coreos.inst.ignition_url=${WEBSERVERURL}/${IGNITIONFILE} coreos.inst.insecure ip=dhcp rd.neednet=1" \
			--os-variant=rhel8-unknown \
			--graphics vnc,port=${VNCPORT}  \
			--network network=${NETWORKNAME},mac=${NODEMACADDRESS}  \
			--noautoconsole --wait -1 \
			--name ${NODEHOSTNAME}.${CLUSTERFQDN}
		BUILDOCPNODERESULT=$?
	else
      		virt-install \
			 --memory=${NODERAMSIZE},maxmemory=${SYSTEMPHYSICALRAM} \
	       	         --vcpus ${NODEVCPUS} \
       		         --cpu host \
       		         --disk path=${OCPVMDISKDIR}/${NODEHOSTNAME}.${CLUSTERFQDN}.qcow2,size=${NODEDISKSIZE},bus=virtio,format=qcow2 \
       		         --install kernel=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-installer-kernel-x86_64,initrd=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-installer-initramfs.x86_64.img,kernel_args_overwrite=yes,kernel_args="coreos.inst=yes coreos.inst.install_dev=vda coreos.inst.image_url=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-metal.x86_64.raw.gz coreos.inst.ignition_url=${WEBSERVERURL}/${IGNITIONFILE} ip=dhcp rd.neednet=1" \
       		         --os-variant=rhel8-unknown \
       		         --graphics vnc,port=${VNCPORT} \
       		         --network network=${NETWORKNAME},mac=${NODEMACADDRESS}  \
       		         --noautoconsole --wait -1 \
       		         --name ${NODEHOSTNAME}.${CLUSTERFQDN}
		BUILDOCPNODERESULT=$?
	fi

	# We clear any old entries in known hosts so that user sees no nasty security business
	sed -i "/${NODEHOSTNAME}.${CLUSTERFQDN}/d" /root/.ssh/known_hosts > /dev/null 2>&1

	echo

	return $BUILDOCPNODERESULT
}


approve-csrs-normal() {

	# $1 is umber of nodes we are waiting for
	# this changes depending on wheter we are building an entire cluster or just adding nodes

	TIMEOUTANDEXIT=$(($1 * ${ADDNODETIMEOUT}))

	# running oc here is a little trickier as this gets forked off, so we test for it before
	[ -x ${OCCOMMAND} ] 
	check-for-error-and-exit $? "Cannot process CSRs as this stage cannot execute command ${OCPINSTALLSOURCE}/oc"

	# This runs in the backgound approving certificates as they come...
	{
		trap "echo 'Certificate Approval (oc get csr) stopped.'; echo;  exit" SIGTERM

		while true 
		do
			${OCCOMMAND} get csr 2>/dev/null | grep Pending | awk '{ print $1 }' | xargs ${OCCOMMAND} adm certificate approve > /dev/null 2>&1

			sleep 10

			# Insurance policy should parent die...
			TIMEOUTANDEXIT=$((${TIMEOUTANDEXIT} - 15))
			[ ${TIMEOUTANDEXIT} -le 0 ] && exit
		done
	} &
	
	# The callers should reference $! to get the PID for the above, so this should be followed by
	# CSRAPPROVALPID=$!
}


yakko-backup() {

	# NOTE: THIS CALL UPDATES THIS FILE WITH sed -i for VERSION
	# Tread carefully

	# A small developer backdoor...
	# Too lazy to push to git all the time
	# $2 creates a message that accompanies the backup... Like commit -m ;)

	shift # get rid of backup parameter

	BACKUPDATE=$(date +%Y%m%d.%H%M)
	BACKUPFILE=${YAKKONAME}.$BACKUPDATE
	BACKUPMSG="$*"

	# This is the first thing that can be called so don't have much info
	cd ${YAKKODIRECTORY}
	
	if [ -r .yakkohome -a -r .yakkobackups ]
	then
		echo
		print-in-colour green "Backing up yakko code"
		echo

		# If there is a message attached, construe this as an updated version!
		if [ -n "$BACKUPMSG" ]
		then
			echo "Yakko version is $YAKKOVERSION."
			cp ${YAKKOEXECUTABLE} /tmp/yakko.tmp.$BACKUPDATE

			MINORRELEASE="$(echo $YAKKOVERSION | cut -f2 -d.)"
			NEWMINOR=$((MINORRELEASE + 1))
			NEWVERSION="$(echo $YAKKOVERSION | cut -f1 -d.)".$NEWMINOR

			echo
			ask-user "Update NEW RELEASE version to [$NEWVERSION]" Y
			if [ $? -ne 0 ]
			then
				echo -n "Enter version number to stamp to this release [${YAKKOVERSION}]: "
				read RESPONSE
				if [ -n "${RESPONSE}" ]
				then
					NEWVERSION=${RESPONSE}
				else
					NEWVERSION=${YAKKOVERSION}
				fi
			fi

			sed -i "s/YAKKODATE=${YAKKODATE}/YAKKODATE=${BACKUPDATE}/" ${YAKKOEXECUTABLE}
			echo "Version: DATE stamp updated to [${BACKUPDATE}]"
			echo

			if [ "${NEWVERSION}" != ${YAKKOVERSION} ]
			then
				sed -i "s/YAKKOVERSION=${YAKKOVERSION}/YAKKOVERSION=${NEWVERSION}/" ${YAKKOEXECUTABLE}
				echo "Version: VERSION stamp updated to [${NEWVERSION}]"

				ask-user "Commit new version to GITHUB" Y
				if [ $? -eq 0 ]
				then
					# We change the README.md file
					sed -i "/## CURRENT VERSION/c\## CURRENT VERSION: ${NEWVERSION} (${BACKUPDATE})" README.md

					# We add changes
					git add yakko README.md YAKKO-architecture.png

					# We commit them with the same message
					git commit -m "${BACKUPMSG}"

					# We push
					echo $GCLAVE
					git push

					# We tag
					git tag "v${NEWVERSION}"

					#We comment tag, same  for now
					git push --tags
				fi
			fi
		fi

		for YBD in $(cat .yakkobackups)
		do
			if [ ! -d "$YBD" ]
			then
				mkdir /YAKKO-BACKUPS >/dev/null 2>&1
				cp ${YAKKOEXECUTABLE} /YAKKO-BACKUPS/${BACKUPFILE}
				echo
				echo "ERROR: [$YBD] cannot be written to for backup."
				echo "NOTE: A backup has been made in root directory (/YAKKO-BACKUPS)"
				echo
				break
			fi
				
			cp ${YAKKOEXECUTABLE} $YBD/${BACKUPFILE}
			cp ${YAKKOEXECUTABLE} $YBD/${YAKKONAME} # This will always be the latest. ln does not work on VFAT ;)

			if [ -n "$BACKUPMSG" ]
			then
				echo $BACKUPMSG > $YBD/${BACKUPFILE}.txt
			fi
	
			echo "Backed up current ${YAKKONAME} as ${YBD}/${BACKUPFILE}"
		done
	else
		echo "Cannot backup because .yakkobackups is not defined"
		echo "Just drop a directory in that filename and yakko will back itself up in there!"
	fi

	echo
	cleanup-and-exit

}


print-option-header() {

	# $1 reads 'infra' or 'ops'
	# Maybe we redecorate on this later but placeholder in place
	if [ "$1" == "infra" ]
	then
		HEADERCATEGORY="INFRA:"
	elif [ "$1" == "ops" ]
	then
		HEADERCATEGORY="OPS:"
	else
		HEADERCATEGORY=""
	fi

	shift

	echo
	print-in-colour lightblue "$HEADERCATEGORY $*"
	echo
}


restart-virtual-network() {

	# call simply with restart params
	# this is an attempt to avoid
	# error: Failed to update network net-yakko-testcluster
	# error: internal error: Failed to apply firewall rules /usr/sbin/iptables -w --table filter 
	# --insert LIBVIRT_INP --in-interface virbrocp --protocol tcp --destination-port 67 --jump ACCEPT: iptables: No chain/target/match by that name.

	echo "Restarting virtual network"

	virsh net-update ${NETWORKNAME} $* ${DHCPXMLTMPFILE} --live --config #> /dev/null 2>&1
	if [ $? -ne 0 ]
	then
		systemctl restart libvirtd
		sleep 2
		virsh net-update ${NETWORKNAME} $* ${DHCPXMLTMPFILE} --live --config #> /dev/null 2>&1
        	check-for-error-and-exit $? "Could not restart the virtual network - with libvirt restart attempted!"
	fi
	rm ${DHCPXMLTMPFILE}
}


check-cluster-api() {

	#check-cluster-api

	# Not sure this is all that necessary but here it is

	# Returns
	# 0 all good
	# 1 API https endpoint is available but API servers are not
	# 2 API servers are available but https endpoint is not
	# 3 All bad

	RESULTENDPOINT=0
	RESULTAPIOPERATORS=0

	wget -O /tmp/wget.$$.clusterapi --no-check-certificate https://api.${CLUSTERFQDN}:6443 > /dev/null 2>&1
	if [ $? -ne 8 ]
	then
		RESULTENDPOINT=1
	fi

	NUMAPISERVERS=$(oc get co 2>/dev/null | grep '\-api' | grep -v machine | awk '{ print $3 }' | wc -l)
	if [ $NUMAPISERVERS -ne 2 ]
	then
		RESULTAPIOPERATORS=2
	fi

	# Crazy huh?
	return $((RESULTENDPOINT+RESULTAPIOPERATORS))
}


check-cluster-power() {

	#check-cluster-power

	DOEXIT=$1  #blank or "exit"

	MASTERNODECOUNT=$(virsh list --all | grep "master-" | grep -c ${CLUSTERFQDN}) # This value should exist in .lastyakkobuild, but nevertheless
	MASTERUPCOUNT=$(virsh list --all | grep "master-" | grep running | grep -c ${CLUSTERFQDN})
	MASTERSUSPENDEDCOUNT=$(virsh list --all | grep "master-" | grep pause | grep -c ${CLUSTERFQDN})

	if [ ${MASTERSUSPENDEDCOUNT} -eq ${MASTERNODECOUNT} ]
	then
		if [ "$DOEXIT" == "exit" ]
		then
			echo "The custer is currently in suspended state. Run 'yakko startcluster'."
			echo
			cleanup-and-exit
		fi

		return 5 #  The masters are suspended (note that this is not granular enough, but c'mon)
	fi

	if [ ${MASTERUPCOUNT} -eq 0 ]
	then
		if [ "$DOEXIT" == "exit" ]
		then
			echo "The custer is currently shutdown. Run 'yakko startcluster'."
			echo
			cleanup-and-exit
		fi

		return 4 # Special case - the cluster is SHUTDOWN!
	fi

	return 0 # The cluster is powered up
}


check-oc-credentials() {

	OCPUSER=$(${OCCOMMAND} whoami 2>/dev/null)
	if [ $? -ne 0 ]
	then
		OCPUSER=unknown
		echo "Could not obtain user credentials for OpenShift (oc whoami). "
	fi
	echo " system:admin kube:admin ${YAKKOADMIN} " | grep  "${OCPUSER}" >/dev/null 2>&1
	check-for-error-and-exit $? "You must be logged in to OpenShift as an administrator to run ${YAKKONAME}\n       Try 'oc login -u <admin>  https://api.${CLUSTERFQDN}:6443'\n       If kubeadmin is still available, the password is [$(cat ${CLUSTERSETUPDIR}/auth/kubeadmin-password)]\n       If you cannot login, check 'oc get co', 'oc get nodes' and 'oc get csr'\n       to understand the state of the cluster before the API server can let you in"
}


check-oc-credentials-and-state() {

	check-cluster-power exit

	check-oc-credentials
}


check-if-yakko-running() {

	# If YAKKO is already running, we block this run. Don't want to clobber an install...
	# except for the stray timeouts with addnode...
	MAINYAKKOPID=$BASHPID
	OTHERYAKKOPID=$(THISYAKKOPID=$BASHPID;pgrep yakko | grep -v "PID\|$MAINYAKKOPID\|$THISYAKKOPID" | tr '\n' ' ')
	if [ -n "$OTHERYAKKOPID" ]
	then
		if [ ${DELETECLUSTERMODE} -eq 0 ]
		then
			# Killing any remaining instances of yakko such as csr approvals
			kill -9 ${OTHERYAKKOPID} > /dev/null
		fi

		check-for-error-and-exit 1 "It appears that 'yakko' is already running - see PID [ $OTHERYAKKOPID]"
	fi

}


check-if-another-yakko-cluster-running() {

	# This check, which I don't love, uses virsh. If virsh is not installed then YAKKO is not running, that simple
	# This was slow...
	# dnf list installed | grep "libvirt-client\."  >/dev/null  2>&1
	# [ $? -ne 0 ] && return  # libvirt is not installed, grep came back with non-zero value
	[ ! -x /usr/bin/virsh ] && return

	if [ -z "${CLUSTERFQDN}" ]
	then
		# We are starting a new cluster so we need to lookout that this is not yet set
		CLUSTERFQDN="CLUSTERNAMENOTSET" # This is a 'whatever' string 
	fi

	RUNNINGCLUSTER=$(virsh list | grep master-0 | grep -v ${CLUSTERFQDN} | cut -f2 -d. | awk '{print $1}')
	[ -n "${RUNNINGCLUSTER}" ] && {
		OTHERCLUSTERDIR=$(curl http://localhost:${WEBSERVERPORT} 2>/dev/null | grep Hostdir | awk '{ print $8 }' |sed -e "s/)//")
		
		if [ ${CLUSTERFQDN} == "CLUSTERNAMENOTSET" ]
		then
			echo "You cannot install a new cluster when another cluster is running."
		else
			echo "This cluster is currently shutdown."
		fi

		echo

		# This is just a small precaution should the above curl fail
		if [ -z "${OTHERCLUSTERDIR}" ]
		then
			echo "OpenShift cluster [${RUNNINGCLUSTER}] is running on this host"
		else
			echo "OpenShift cluster [${RUNNINGCLUSTER}] is running on this host, installed at [${OTHERCLUSTERDIR}]"
		fi
		
		echo
		echo "You can only one run cluster at a time!" 
		echo

		cleanup-and-exit
	}	
}


restore-stubfiles() {
	[ -r ${STUBFILES}/resolved.conf ] && cp ${STUBFILES}/resolved.conf ${SYSTEMSTUBFILE_RESOLVED}
	# We need to take into account that the main IP address may have changed
	update-dnsmasq-config-file ${HAPROXYACCESS} # This is painful but we must rebuild the dnsmasq file on the fly
	cp ${STUBFILES}/haproxy.cfg ${SYSTEMSTUBFILE_HAPROXY}
	cp ${STUBFILES}/NetworkManager.conf ${SYSTEMSTUBFILE_NETWORKMANAGER}
	cp ${STUBFILES}/httpd.conf ${SYSTEMSTUBFILE_HTTPD}
}


remove-stubfiles() {

	# This routine deletes all current stub files

	rm /etc/NetworkManager/dnsmasq.d/yakko-* >/dev/null 2>&1
	rm /etc/NetworkManager/conf.d/yakko-* >/dev/null 2>&1
	rm /etc/systemd/resolved.conf.d/yakko-* >/dev/null 2>&1
	rm /etc/haproxy/conf.d/yakko-* >/dev/null 2>&1
	rm /etc/httpd/conf.d/yakko-* >/dev/null 2>&1

}


update-services() {

	# $1 is one of [ start | stop | restart ]

	SERVICESMODE=$1

	if [ $SERVICESMODE == "start" ]
	then
		echo
		print-in-colour green "Starting YAKKO supporting services"
		echo

		echo "- Inserting stub files for YAKKO services into system..."
		restore-stubfiles
		echo

		echo "- Starting virtual Network..."
		virsh net-list | awk '{ print $1 }' | grep "${NETWORKNAME}$" >/dev/null 2>&1
		if [ $? -ne 0 ]
		then	
			# This here because sometimes, the virtual network is still active and
			# will throw a fit of asked to restart
			virsh net-start ${NETWORKNAME} > /dev/null 2>&1
			check-for-error-and-exit $? "Could not start virtual network ${NETWORKNAME}"
			echo
		fi

		echo "- Re/starting libvirtd service..."
		systemctl restart libvirtd
		echo

		if [ -f ${SYSTEMSTUBFILE_RESOLVED} ]
		then
			echo "- Starting systemd-resolved service..."
			systemctl restart systemd-resolved
			echo
		fi

		echo "- Re/starting NetworkManager service and testing..."
		systemctl restart NetworkManager
		WAITTIME=30
		while true
		do
			sleep 1
			ping -c 1 ${YAKKOHOSTIP} >/dev/null 2>&1 && break
			((WAITTIME--))
			[ $WAITTIME -eq 0 ] && {
				echo "Timed out waiting for main interface to come UP. Exiting."
				clean-up-and-exit
			}
		done
		echo

		echo "- Starting HAproxy service..."
		systemctl start haproxy
		check-for-error-and-exit $? "Could not start HAproxy service"
		echo

		echo "- Re/starting HTTPD service..."
		systemctl restart httpd > /dev/null 2>&1
		#check-for-error-and-exit $? "Could not start HTTPD service"
		echo

		sleep 5

		print-in-colour green "All services started. Some operators may take some time to settle."
		echo
	fi

	if [ $SERVICESMODE == "stop" ]
	then
		echo
		print-in-colour green "Stopping YAKKO supporting services"
		echo

		echo "- Removing stub files for YAKKO services from system..."
		remove-stubfiles
		echo

		echo "- Stopping HAproxy service..."
		systemctl stop haproxy
		echo

		if [ -f ${SYSTEMSTUBFILE_RESOLVED} ]
		then
			echo "- Re/starting systemd-resolved service..."
			systemctl restart systemd-resolved
			echo
		fi

		echo "- Restarting NetworkManager service..."
		systemctl restart NetworkManager
		echo

		echo "- Restarting HTTPD service without port :${WEBSERVERPORT}..." 
		systemctl restart httpd > /dev/null 2>&1
		#check-for-error-and-exit $? "Could not start HTTPD service"
		echo

		echo "- Stopping virtual network..."
		virsh net-destroy ${NETWORKNAME} >/dev/null 2>&1
		echo

		echo "- Restarting libvirtd service..."
		systemctl restart libvirtd
		echo

		sleep 5
	fi

	if [ $SERVICESMODE == "restart" ]
	then
		# There is no need to test if IP address has changed because it's always
		# checked in advance of getting here
		update-services stop
		update-services start
	fi
}


purge-downloads() {

	# At this point, CLUSTERCONFIGFILE is not loaded so we do that to avoid deleting the current image
	[ -r ${CLUSTERCONFIGFILE} ] && source ${CLUSTERCONFIGFILE}

	if [ -z "${OCPINSTALLVERSION}" ]
	then 
		VERSIONINUSE="NONE"
	else 
		VERSIONINUSE=${OCPINSTALLVERSION}
	fi

	OCPDOWNLOADS=$(ls -c ${IMAGEREPO} 2>/dev/null | grep "^[4-5]" | grep -v ${VERSIONINUSE}  2>/dev/null)

	if  [ -z "${OCPDOWNLOADS}" ]
	then
		echo "There are no downloaded OCP images available for purging."
		if [ ${VERSIONINUSE} != "NONE" ]
		then
			echo "${OCPINSTALLVERSION} is currently in use and thus cannot be deleted."
		fi
		echo
	else
		echo "The following unused images presently reside on disk:" 

		for OCPDOWNLOADIMAGE in ${OCPDOWNLOADS}
		do
			echo ${OCPDOWNLOADIMAGE}: $(du -hs ${IMAGEREPO}/${OCPDOWNLOADIMAGE} 2>/dev/null | awk '{ print $1 }')
		done
		echo

		ask-user "Delete OCP images listed" Y
		if [ $? -eq 0 ]
		then
			cd ${IMAGEREPO}
			if [ ${PWD} == ${IMAGEREPO} ]
			then
				# The above check is to ENSURE we don't blow up the wrong thing. Past learnings :)
				for OCPDOWNLOADIMAGE in ${OCPDOWNLOADS}
				do
       	                		echo Deleting ${OCPDOWNLOADIMAGE} 
					rm -rf ${OCPDOWNLOADIMAGE}
				done
				echo Done!
				echo
			fi
			cd ..
		fi
	fi
}

check-registry-type() {

	# This little function checks whether a NFS registry is active or a local registry is active...
	REGISTRYPOD=$(${OCCOMMAND} get pods -n openshift-image-registry | grep image-registry | grep -v operator | grep Running | awk '{print $1}')

	if [ -z "${REGISTRYPOD}" ]
	then
		echo none # there is no pod, so it's unmanaged
	else
		${OCCOMMAND} -n openshift-image-registry rsh ${REGISTRYPOD} mount | grep registry | grep nfs > /dev/null 2>&1
		if [ $? -eq 0 ]
		then 
			echo nfs 
		else
			echo local 
		fi
	fi
}


create-nfs-pvc() {

	# This routine handles the test and creation of a NFS mountpoint to hand to OpenShift
	# https://docs.openshift.com/container-platform/4.9/storage/understanding-persistent-storage.html
	
	NFSNAME=$1
	NFSSERVER=$2
	NFSSHARE=$3
	NAMESPACE=$4
	PVCSIZE=$5

	# We test that the share is there and has the right permissions
	# eg /mnt/MIRROR/NFS-SHARE/terminus/ocptestregistry *(rw,sync,no_wdelay,no_root_squash,insecure)
	# and mount point needs to be 777

	# We check that if it exists already...
	${OCCOMMAND} get pv | grep pv-${NFSNAME} | grep pv-${NFSNAME} >/dev/null 2>&1
	if [ $? -eq 0 ]
	then
		print-in-color red "The requested PV [pv-${NFSNAME}] already exists - cannot continue!"
		echo
		cleanup-and-exit
	fi

	# We create a PV from an NFS share
	cat <<NFSPVDEF | ${OCCOMMAND} create -f - 
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-${NFSNAME}
spec:
  capacity:
    storage: ${PVCSIZE}Gi
  accessModes:
  - ReadWriteMany
  nfs:
    path: ${NFSSHARE}
    server: ${NFSSERVER}
  persistentVolumeReclaimPolicy: Retain
NFSPVDEF
	check-for-error-and-exit $? "Could not create PV (name: pv-${NFSNAME})"

	# We create a PVC from the above PV
	cat <<NFSPVCDEF | ${OCCOMMAND} create -f - 
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-${NFSNAME}
  namespace: ${NAMESPACE}
spec:
  capacity:
    storage: ${PVCSIZE}Gi 
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: ${PVCSIZE}Gi
NFSPVCDEF
	check-for-error-and-exit $? "Could not create PVC (name: pvc-${NFSNAME})"

}

mount-nfs-share() {

	while true
	do
		echo
		echo -n "Enter the hostname or IP address of an existing NFS server: "
		read NFSSERVER

		ping -c 1 ${NFSSERVER} >/dev/null 2>&1
		if [ $? -eq 0 ]
		then
			#echo -n "Getting available shares from [${NFSSERVER}] - this may take a while..."

			showmount -e ${NFSSERVER} > /dev/null 2>&1
			RESULT=$?

			if [ $RESULT -ne 0 ]
			then
				echo "Unable to obtain any shares from [${NFSSERVER}] via showmount (error $RESULT)"
				continue
			else
				echo
				showmount -e ${NFSSERVER}  2>&1
				break
			fi
		else
			echo "Server [${NFSSERVER}] not found or not avilable (could not ping it!)"
		fi

	echo
	done

	NFSTESTDIR=/mnt/yakkonfstest.$$

	while true
	do
		echo
		echo -n "Select a share directory from above to mount (copy/paste path): "
		read NFSSHARE
		echo

		[ -z "${NFSSHARE}" ] && continue

		echo "Testing share..."
		sleep 1
		mkdir ${NFSTESTDIR} 2>/dev/null
		mount -t nfs ${NFSSERVER}:/${NFSSHARE} ${NFSTESTDIR}

		NFSMOUNTTESTRESULT=$?


		if [ ${NFSMOUNTTESTRESULT} -eq 0 ]
		then
			echo "Share mounted successfully, testing permissions..."
			sleep 1
			# Mount is successful, but is it writeable?
			# Just in case we test it's writeable by world
			PERMISSIONS=$(stat -c "%A" ${NFSTESTDIR})
			PERMISSIONOTHER=${PERMISSIONS:8:1}
			if [ "$PERMISSIONOTHER" == "-" ]
			then
				echo
				echo "ERROR: ${NFSSERVER}:/${NFSSHARE} does not have write permissions for the world (it has \"${PERMISSIONS}\")"
				echo "       This will prevent the image registry operator from being able to write unless user permissions match"
				echo "       To continue, change the permissions - you can always tune later!"
			        echo
				umount ${NFSTESTDIR}
				cleanup-and-exit
			fi	

			echo "Share mounted successfully, testing write..."
			touch ${NFSTESTDIR}/testfile

			if [ $? -eq 0 ]
			then
				echo "NFS share tested successfully."
				rm ${NFSTESTDIR}/testfile > /dev/null 2>&1
				umount ${NFSTESTDIR}
				sleep 1
				rmdir ${NFSTESTDIR}
				break
			else
				echo
				echo "ERROR: Test write failed - could not write to share."
				echo "       Ideally, export options of share on host should be: *(rw,sync,no_wdelay,no_root_squash,insecure)"
				echo
				cleanup-and-exit
			fi

		else
			echo
			echo "Failed to mount ${NFSSERVER}://${NFSSHARE} ${NFSTESTDIR} on test dir [${NFSTESTDIR}] - Code [${NFSMOUNTTESTRESULT}]"
			echo "Try again! (or CTRL-C to exit)"
			echo
		fi
	done
}

update-yakko-host-ip() {

	sed -i "/YAKKOHOSTIP/c\YAKKOHOSTIP=${YAKKOHOSTIP}" ${CLUSTERCONFIGFILE} > /dev/null 2>&1
}


update-haproxy-access() {

	# $1 is 0 for open access and 1 for closed access (host only)
	HAPROXYACCESS=$1
	sed -i "/HAPROXYACCESS/c\HAPROXYACCESS=${HAPROXYACCESS}" ${CLUSTERCONFIGFILE} > /dev/null 2>&1
}


update-dnsmasq-config-file() {

	# We set the state to the parameter passed and then adjust files accordingly
	# $1 can be
	# 0 - build the dnsmasq file with OPEN access 
	# 1 - build the dnsmasq file with CLOSED access
	# 2 - build the dnsmasq file with the current HAPROXYACCESS value 

	# There should be no DNSmasq conf file if we are not using DNSmasq locally
	if [ ${USEYAKKODNSMASQ} -eq 0 ]
	then
		if [ $1 == 0 ]
		then
			cat ${STUBFILES}/dnsmasq.conf | sed -e "s/,STRINGYAKKOHOSTIP/,${YAKKOHOSTIP}/" -e "s/\/STRINGYAKKOHOSTIP/\/${YAKKOHOSTIP}/" > ${SYSTEMSTUBFILE_DNSMASQ}
		fi
		if [ $1 == 1 ]
		then
			cat ${STUBFILES}/dnsmasq.conf | sed -e "s/,STRINGYAKKOHOSTIP//" -e "s/\/STRINGYAKKOHOSTIP/\/${CLUSTERPROXY}/" > ${SYSTEMSTUBFILE_DNSMASQ}
		fi
	fi

}

build-haproxy-config-section() {

	# This is just to avoid repetion and errors

	SECTIONNAME=$1
	PORT=$2
	NODETYPE=$3

	if [ ${HAPROXYACCESS} -eq 0 ]
	then 
		# We have open access to the cluster
		HAPROXYVALUE=""
	else
		# We have restricted access to the cluster
		HAPROXYVALUE=${CLUSTERPROXY}
	fi

	echo "listen ${CLUSTERNAME}-${SECTIONNAME}-${PORT}"
	echo "    bind ${HAPROXYVALUE}:${PORT}"
	echo "    mode tcp"
	echo "    balance source"

	if [ -n "${NODETYPE}" ]
	then
		# Specifying nodetype means we will depend on what the cluster already has
		for NODENAME in $(${OCCOMMAND} get nodes | grep ${NODETYPE} | awk '{ print $1 }')
		do
			echo "    server ${NODENAME}.${CLUSTERFQDN} $(dig +short ${NODENAME}.${CLUSTERFQDN}):${PORT} check inter 1s"
		done
	fi
	echo
}

update-haproxy-config-file() {

	# See the below for loadbalancer info
	# https://docs.openshift.com/container-platform/4.1/installing/installing_bare_metal/installing-bare-metal.html#installation-network-user-infra_installing-bare-metal

	# this creates a new haproxy loadbalancer config file based on the state of the cluster
	# infra nodes are accounted for as workers (called node-*) so they can be used for 80/443

	#BTW, see this for the importance of updated HAProxy
	#https://bugzilla.redhat.com/show_bug.cgi?id=2025555

	echo "Testing cluster API server availability... (issuing 'oc get nodes')"
	RESULT=$(${OCCOMMAND} get nodes)
	check-for-error-and-exit $? "Cannot run 'oc' command which prevents building a reliable/up-to-date haproxy config file"

	# We check if the cluster is just masters or masters and workers
	WORKERNODESAVAILABLE=$(${OCCOMMAND} get nodes | grep -c "^node-")

	echo "Rebuilding HAProxy config file..."
	sleep 1

	# Defaults example at
	# https://docs.openshift.com/container-platform/4.8/installing/installing_bare_metal/installing-bare-metal-network-customizations.html
	# Scroll to "Example load balancer configuration for user-provisioned clusters" section!

	{
		echo "defaults"
		echo "    mode http"
  		echo "    option http-server-close"
		echo "    option redispatch"
		echo "    option dontlognull"
   	 	echo "    timeout connect          10s"
    		echo "    timeout client           1m"
    		echo "    timeout server           1m"
  		echo "    timeout queue            1m"
		echo "    timeout http-request     10s"
  		echo "    timeout http-keep-alive  10s"
		echo "    retries                  3"
		echo "    timeout check            10s"
		echo "    maxconn                  3000"
		echo

		build-haproxy-config-section api-server 6443 master
		build-haproxy-config-section machine-config-server 22623 master

	} > ${STUBFILES}/haproxy.cfg

	if [ ${WORKERNODESAVAILABLE}  -eq 0 ]
	then
		${OCCOMMAND} get nodes | grep "^master-" | grep worker >/dev/null 2>&1
		if [ $? -ne 0 ]
		then
			echo
			print-in-blink "ATTENTION: The cluster has no worker nodes. Enable master scheduling by issuing 'yakko ops mastersched'"
		fi

		{		
			build-haproxy-config-section ingress-router 80 master
			build-haproxy-config-section ingress-router 443 master
		} >> ${STUBFILES}/haproxy.cfg
	else
		{		
			build-haproxy-config-section ingress-router 80 worker
			build-haproxy-config-section ingress-router 443 worker
		} >> ${STUBFILES}/haproxy.cfg
	fi
	
	# The above leaves the latest file in play for later
	cp ${STUBFILES}/haproxy.cfg ${SYSTEMSTUBFILE_HAPROXY}

	echo "Restarting HAProxy"
	systemctl restart haproxy
	check-for-error-and-exit $? "Failed to restart HAProxy"
	echo "HAProxy restarted."
	echo
}


##########################################################################################################
### YAKKO INFRA 
##########################################################################################################

print-yakko-infra-operations-menu() {

	# Catchall for any other passed parameted at this point
	echo "USAGE: ${YAKKONAME} infra <OPTION> [parameters]" 
	echo
	echo "OPTION is one of:"
	echo "    - startcluster    ->  Start up an existing cluster"
	echo "    - stopcluster     ->  Shutdown or suspend the cluster in memory"
	echo "    - addnode         ->  Grow the cluster compute capacity by adding a new compute/infra node"
	echo "    - deletenode      ->  Remove a running node from the cluster"
	echo "    - nodelogs        ->  Display the logs of a particular node"
	echo "    - sshtonode       ->  Provide terminal access to an individual cluster node"
	echo "    - changeaccess    ->  Enable/disable OpenShift access by other clients in your network"
	echo "    - restartservices ->  Restart supporting services for cluster (virt network/HAproxy/libvirtd)"
	echo "    - listresources   ->  Print a summary of services and files in use by the (YAKKO) cluster"
	echo "    - resizeram       ->  Change the RAM size of a node"
	echo "    - purgedownloads  ->  Delete all downloaded OCP images on disk"
	echo "    - nfsshare        ->  Setup a directory as NFS share for creating a PVC for registry or NS store"
	echo "    - deletecluster   ->  Delete entire cluster and all infrastructure"
	echo
}

yakko-infra-operations() {

	# We're here bacause 'yakko infra' was invoked

	# $1 is an op listed in $YAKKOINFRAOPTIONS
	# YAKKOINFRAOPTIONS is defined at the top with the list of valid ops on an existing cluster	

	OPTION=$1
	shift

	echo "${YAKKOINFRAOPTIONS}" | grep " ${OPTION} " > /dev/null
	if [ $? -ne 0 -o -z "${OPTION}" ]
	then
		print-yakko-infra-operations-menu
		cleanup-and-exit
	fi

	if [ "${OPTION}" == "startcluster" ]
	then
		#infrastartcluster

		print-option-header infra "Start cluster [${CLUSTERNAME}]"

		check-cluster-power
		CLUSTERSTATE=$?
		if [ $CLUSTERSTATE -eq 0 ]
		then
			echo "Cluster [${CLUSTERFQDN}] is already running."
			echo
			cleanup-and-exit
		fi

		get-yakko-host-ip notifychange 
		update-services start

		if [ $CLUSTERSTATE -eq 5 ]
		then
			echo "Resuming (from in-memory) all cluster nodes"
			echo
			sleep 1
			get-node-list all
	
			for NODE in ${NODELIST}
			do
				virsh list --all | grep ${NODE} | grep running >/dev/null 2>&1
				if [ $? -eq 0 ] 
				then
					echo  "Node [${NODE}] is already in \"running\" state"
					echo
				else
					virsh resume $NODE 
					[ $? -ne 0 ] && echo "Failed to resume node [${NODE}]"
				fi
			done
			sleep 1
			print-in-colour green "All nodes are now resumed. Check 'oc get nodes'."

		else
			get-node-list all
			for NODENAME in ${NODELIST}
			do
				virsh setmaxmem ${NODENAME} ${SYSTEMPHYSICALRAM}M >/dev/null 2>&1

      		 			echo "Starting up: ${NODENAME}"
      		 			virsh start ${NODENAME}
				sleep 1
			done

			echo "You can check:"
			echo "- virsh list --all | grep ${CLUSTERFQDN}  to see if all nodes are running"
			echo "- oc get nodes  to see if all nodes become Ready"
			echo "- oc get clusterversion  to check cluster status"
			echo "- yakko  for a general update"
			echo
			echo Nodes are coming up. Waiting up to 10 minutes for API and User Login services.
	
			TIMER=300 # This is just for the API
			while true
			do 
				wget -O /tmp/wget.$$.startcluster https://api.${CLUSTERFQDN}:6443 > /dev/null 2>&1
				[ $? -eq 5 -o $? -eq 0 ] && break
				echo -n .
				sleep 5
				TIMER=$((TIMER-5))
				if [ $TIMER -eq 0 ]
				then
					echo
					echo "ERROR: Failed to observe API server running"
					echo "       Cannot proceed - debug separately!"
					echo
					cleanup-and-exit
				fi
			done
			echo
			echo "API server now available - waiting for administrator login."
			sleep 60
	
			TIMER=300 # if this takes too long it could be CSRs awaiting
	
			if [ -z "${YAKKOADMIN}" ] 
			then
				YAKKOADMIN=kubeadmin
				ADMINPASSWORD=$(cat ${CLUSTERSETUPDIR}/auth/kubeadmin-password)
			else
				echo -n "To allow YAKKO to report on the cluster state, please enter the password for administrative user [${YAKKOADMIN}]: "
				read -s ADMINPASSWORD
				echo
			fi
	
			while true
			do 
				${OCCOMMAND} login --insecure-skip-tls-verify=true -u ${YAKKOADMIN} -p ${ADMINPASSWORD} https://api.${CLUSTERFQDN}:6443 > /dev/null 2>&1
	
				${OCCOMMAND} whoami > /dev/null 2>&1
				[ $? -eq 0 ] && {
					echo
					echo "Now logged in to OCP as $(${OCCOMMAND} whoami)"
					break
				}
	
				echo -n .
				sleep 10
	
				TIMER=$((TIMER-10))
	
				if [ $TIMER -eq 0 ]
				then
					PENDINGCSRS=$(${OCCOMMAND} get csr 2>/dev/null | grep Pending | awk '{ print $1 }')

       	               		  	if [ -n "${PENDINGCSRS}" ]
       	                 			then
       	                        		set $PENDINGCSRS
						echo
       	                        		print-in-blink "ALERT: There are [$#] Pending Certificate Signing Requests (CSRs) that need approval!"
						echo "You will need to issue 'yakko ops approvecsrs' to allow the cluster to come up."
       	                        		echo
						cleanup-and-exit
					fi
					echo
					echo "Not waiting any longer for administrative login. "
					echo "You should attempt 'oc login -u <admin>  https://api.${CLUSTERFQDN}:6443'"
					echo
					cleanup-and-exit
       	                	 fi
			done
			#oc config use-context "${CLUSTERCONTEXT}" 
	
			echo
			print-in-colour green "Cluster API endpoint https://${CLUSTERFQDN}:6443 is now available."
			print-in-colour green "Web console may take a little longer."
		fi
		echo
	fi

	if [ ${OPTION} == "stopcluster" ]
	then
		#infrastopcluster

		print-option-header infra "Stop cluster [${CLUSTERNAME}]"

		check-cluster-power exit

		if [ -n "$1" ]
		then
			if [ "$1" == "suspend" ]
			then
				STOPCLUSTEROPTION=1
			elif [ "$1" == "shutdown" ]
			then
				STOPCLUSTEROPTION=2
			else
				echo "Invalid option [$1] - cannot proceed with stopping the cluster."
				echo
				exit
			fi
		else
			echo "This option lets you shutdown a cluster OR suspend it in memory."
			echo "You can pass an additional parameter to specify the behaviour"
			echo "through the command line (useful in cronjobs for example):"
			echo "  - yakko stopcluster shutdown"
			echo "  - yakko stopcluster suspend"
			echo
			echo
	
			while true
			do
				echo "What do you want to do?"
				echo "(1) Suspend cluster"
				echo "(2) Shutdown cluster"
				echo
				echo -n "Select (1) or (2): "
	
				read STOPCLUSTEROPTION
				if [ ${STOPCLUSTEROPTION} == "1" -o ${STOPCLUSTEROPTION} == "2" ]
				then
					break
				else
					echo "You must enter 1 or 2".
					echo
				fi
			done
			echo
		fi

		if [ ${STOPCLUSTEROPTION} == "1" ]
		then
			echo "Suspending (in-memory) all cluster nodes"
			echo
			sleep 1
			get-node-list active
	
			for NODE in ${NODELIST}
			do
				virsh list --all | grep ${NODE} | grep paused >/dev/null 2>&1
				if [ $? -eq 0 ] 
				then
					echo  "Node [${NODE}] is already in \"pause\" state"
					echo
				else
					virsh suspend $NODE  # & will make them stop more or less at the same time...
					[ $? -ne 0 ] && { echo  "Failed to suspend node [${NODE}]"; echo; }
				fi
			done
			sleep 1
			print-in-colour green "All nodes are now suspended."
		else
			# User picked 2...
			get-node-list active
			for NODENAME in ${NODELIST}
			do
				echo "Shutting down: ${NODENAME}"
				ssh -i ${OCPSSHKEY} -o "StrictHostKeyChecking no" core@${NODENAME} sudo shutdown -h 1
				#check-for-error-and-exit $? "Failed to log in to node [$NODENAME] for shutdown"
				#exit
				echo
			done
	
			echo "Shutting down all nodes, please wait a few moments."
			while true
			do
				[ $(virsh list --all | grep ${CLUSTERFQDN} | grep -c running) -eq 0 ] && break
				sleep 2
				echo -n "."
			done
			echo
			print-in-colour green "All cluster nodes are now powered off."
		fi

		update-services stop

	fi

	if [ "${OPTION}" == "addnode" ]
	then
		#infraaddnode
		
		print-option-header infra "Add a new worker node to the cluster"

		# We dont want to have two addnodes running
		check-if-yakko-running
		
		check-oc-credentials-and-state

		echo "NOTE 1: YAKKO will NOT TEST for capacity to handle this request, proceed with caution"
		echo
		echo "NOTE 2: You can also call addnode with parameters for automatic node addition:"
		echo "        - spec: yakko infra addnode <# workers> <# cpuspernode> <RAM in MiB>"
		echo "        - e.g.: yakko infra addnode 3 2 6000"
		echo

		WORKERNODECOUNT=1
		if [ -n "$1" -a -n "$2" -a -n "$3" ]
		then
			# Automation: 
			AUTOSETUP=1

			# We use alternative variables to perform checks. RAM only for now
			PARAMWORKERNODECOUNT=$1
			PARAMWORKERVCPUS=$2
			PARAMWORKERRAMSIZE=$3

			if [ $PARAMWORKERRAMSIZE -lt $MINWORKERRAMSIZE ]
			then
				echo
				echo "ERROR: RAM size needs to be at least $MINWORKERRAMSIZE"
				echo
				cleanup-and-exit
			fi
			WORKERNODECOUNT=$PARAMWORKERNODECOUNT
			WORKERVCPUS=$PARAMWORKERVCPUS
			WORKERRAMSIZE=$PARAMWORKERRAMSIZE

		else

			# For now we will use the stock configuration, add query for RAM and CPU?
			while true
       	         	do
       	         		echo -n "How many cores should be allocated to this node [${WORKERVCPUS}]: "
				read VALUE
				if [ -n "$VALUE" ]
				then
					if ! [[ $VALUE =~ $NUMBERRE ]] ; then
						echo "Error: Not a number. Try again..."
						continue
					elif [ $VALUE -gt ${MAXNODEVCPUS} ]
					then
						echo "Error: Cannot assign more than ${MAXNODEVCPUS}"
						continue
					elif [ $VALUE -eq 0 ]
					then
						echo "Error: Cannot assign ZERO CPUs"
						continue
					else
						WORKERVCPUS=$VALUE
					fi
				fi
				break
			done
			echo
	
			while true
			do
				echo -n "How much RAM (MiB) should be allocated to this node (min: ${MINWORKERRAMSIZE}) [${WORKERRAMSIZE}]: "
				read VALUE
				if [ -n "$VALUE" ]
				then
					if ! [[ $VALUE =~ $NUMBERRE ]] ; then
						echo "Error: Not a number. Try again..."
						continue
					else
						AVAILRAM=$(free -m | grep Mem:|awk '{ print $7 }')
						echo "Your system has $AVAILRAM MiB RAM currently available"
						if [ $VALUE -lt ${MINWORKERRAMSIZE} -o $VALUE -gt $((2*$AVAILRAM)) ]
						then
							echo "RAM size needs to be between ${MINWORKERRAMSIZE} and ideally no more than available RAM"
							echo
							continue
						else
							WORKERRAMSIZE=$VALUE
						fi
					fi
				fi
				break
			done
		fi

		YAKKOSTAGE=0 # This is to artificially use the process-stage framework
		process-stage-build-ocp-workernodes progress

		# This sets CSRAPPROVALPID for later use below
		approve-csrs-normal ${WORKERNODECOUNT}
		CSRAPPROVALPID=$!

		trap "echo;echo \"Node [${NEWNODENAME}]  has not joined the cluster - deleting...\"; delete-kvm-machine ${NEWNODENAME}; exit" SIGINT

		echo "Node(s) ready to begin integration into the cluster. This will take a few minutes..."
		echo "This process will timeout in ${ADDNODETIMEOUT} seconds." 
		echo
		echo "To observe node progress you can run, on another terminal:"
		echo "- oc get nodes "
		echo "- ${YAKKONAME} infra nodelogs"
		echo

		# We'll start the timeout in case this fails - using ADDNODETIMEOUT
		# NEWNODELIST was populated during process-stage-build-ocp-workernodes

		CHECKINTERVAL=15
		ADDNODETIMEOUT=$((${ADDNODETIMEOUT} * ${WORKERNODECOUNT}))

		print-in-colour lightblue  "Waiting up to $(($ADDNODETIMEOUT /60)) minutes to complete the node addition(s)"
		echo

		while [ -n "${NEWNODELIST}" ]
		do 
			for EACHNODE in ${NEWNODELIST}
			do
				${OCCOMMAND} get node ${EACHNODE} 2>/dev/null  | grep -v NAME | grep -v "NotReady" | grep Ready  >/dev/null 2>&1
				if [ $? -eq 0 ]
				then 
					echo "Node (${EACHNODE}) has been added to the cluster and is in READY state "
					echo
					NEWNODELIST=$(echo ${NEWNODELIST} | sed -e "s/\ *${EACHNODE}//")
				fi
				sleep ${CHECKINTERVAL}

				# We will timedown the success of this stage - hit 0 and bail out
				ADDNODETIMEOUT=$((ADDNODETIMEOUT - CHECKINTERVAL))

				if [ ${ADDNODETIMEOUT} -le 0 ]
				then
					# process-stage-build-ocp-workernodes uses NEWNODELIST to know what to roll-back
					print-in-colour red  "ERROR: timed out trying to complete node addition to cluster [${CLUSTERNAME}]"
					process-stage-build-ocp-workernodes rollback
					NEWNODELIST=""
					echo
				fi
			done
		done 

		echo "Stopping background certificate approval..."
		kill -s SIGTERM $CSRAPPROVALPID > /dev/null 2>&1
		sleep 1 ${CHECKINTERVAL} # we wait a cycle for the sleep to let go + 1 second

		if [ ${ADDNODETIMEOUT} -le 0 ]
		then
			print-in-colour red "- Check  'oc get node'  to understand your current cluster configuration"
			print-in-colour red "- Have you assigned enough RAM to the nodes? You requested ${WORKERRAMSIZE} MiB"
			print-in-colour red "- If your system is slow, perhaps you may want to increase ADDNODETIMEOUT in yakko" 
		else
			update-haproxy-config-file
			print-time-elapsed
		fi
		echo
	fi

	if [ "${OPTION}" == "deletenode" ]
	then
		#infradeletenode
		
		print-option-header infra "Delete an existing worker node from the cluster"

		check-oc-credentials-and-state

		echo "Deleting a node may cause unintended consequences and prevent some workloads from"
		echo "restarting, depending on their dependencies and the resources left in the cluster"
		echo "Use at your own risk!"
		echo

		if [ -n "$1" ]
		then
			# Here's hoping the user knows what he's doing
			NODENAME=$1

			echo "Deleting node [${NODENAME}]"
			echo

			${OCCOMMAND} get nodes | awk '{print $1}' | grep "^${NODENAME}$"
                        [ $? -ne 0 ] && {
				echo
                        	echo "Invalid node name [${NODENAME}]. Exiting..."
				echo
				cleanup-and-exit
			}
		else

			CURRENTNODES=$(${OCCOMMAND} get nodes | awk '{print $1}' | grep "^node-")
		
			if [ -z "${CURRENTNODES}" ]
			then
				echo "There are no worker/infra nodes defined, nothing to delete!"
				echo
				cleanup-and-exit
			fi

			if [ -z "${CURRENTNODES}" ]
			then
				echo "There are no nodes available for deletion!"
				echo
				cleanup-and-exit
			fi

			while true
			do
				echo "The following nodes are available for deletion: "
				for EACHNODE in ${CURRENTNODES}
				do
					echo ${EACHNODE}
				done
				echo
	
				echo -n "Enter the name of the node you want to delete from the cluster: "
				read NODENAME
	
				${OCCOMMAND} get nodes | awk '{print $1}' | grep "^${NODENAME}$"
				[ $? -eq 0 ] && break
	
				echo "Invalid node name."
			done
		fi

		# Drain the node...
		${OCCOMMAND} adm drain ${NODENAME} --force=true --ignore-daemonsets
		${OCCOMMAND} delete node ${NODENAME}

		# Delete the VM
		delete-kvm-machine ${NODENAME}

		# Update the virtual network
		echo "Restarting virtual network"

		cat ${NETWORKXML} | grep ${NODENAME} > ${DHCPXMLTMPFILE} #It's way too hard to pass this as an argument below!
		sed -i "/${NODENAME}/d" ${NETWORKXML}
		restart-virtual-network delete ip-dhcp-host # this knows of ${DHCPXMLTMPFILE}

		#and we update the haproxy
		echo
		update-haproxy-config-file
                check-for-error-and-exit $? "Could not start HA Proxy, the cluster cannot function without this."
		echo
	fi


	if [ "${OPTION}" == "resizeram" ]
	then
		#infraresizeram

		print-option-header infra "Resize node RAM"
	
		echo "Nodes in cluster [${CLUSTERNAME}] are:"
		echo "- masters  (you must resize all masters equally)"
		WORKERLIST=" masters "
		for EACHWORKER in $(virsh list --all | grep "node-" | grep ${CLUSTERFQDN} | awk '{print $2}')
		do
			echo "-" ${EACHWORKER}
			WORKERLIST=" ${WORKERLIST} ${EACHWORKER} "
		done
		echo

		while true
		do
			echo -n "Pick a node name to resize RAM (copy/paste): "
			read NODETORESIZE

			echo ${WORKERLIST} | grep ${NODETORESIZE} > /dev/null 2>&1
			if [ $? -eq 0 ] 
			then
				break
			else
				echo "Invalid node, try again."
			fi
		done
		
		if [ ${NODETORESIZE} == masters ]
		then
			NODETORESIZERAM=$(virsh dominfo master-0.${CLUSTERFQDN} | grep Used | awk '{print $3}')
			NODETORESIZERAM=$((NODETORESIZERAM/1024))
			echo Master nodes are defined with ${NODETORESIZERAM} MiB 
		else
			NODETORESIZERAM=$(virsh dominfo ${NODETORESIZE} | grep Used | awk '{print $3}')
			NODETORESIZERAM=$((NODETORESIZERAM/1024))
			echo Node [${NODETORESIZE}] is defined with ${NODETORESIZERAM} MiB
		fi
		echo

		while true
		do
			echo -n "Enter the new RAM size (MiB) for node ${NODETORESIZE}: "
			read NEWRAMSIZE


			if [ ${NEWRAMSIZE} -lt 2000 -o ${NEWRAMSIZE} -gt 64000 ]
			then 
				echo "Invalid RAM size - try your luck between 2000 and 64000 MiB!"
				echo
			else	
				break
			fi
		done
		# virsh setmaxmem takes KiB, so we multiply times 1024
		NEWRAMSIZE=$((NEWRAMSIZE*1024))
		echo

		if [ ${NODETORESIZE} == masters ]
		then
			echo "Changing VM definition for master-0.${CLUSTERFQDN}" 
			virsh setmem master-0.${CLUSTERFQDN} ${NEWRAMSIZE}
			ssh -i ${OCPSSHKEY} -o "StrictHostKeyChecking no" -q core@master-0.${CLUSTERFQDN} "sudo systemctl restart kubelet"
			sleep 20

			if [ ${MASTERNODECOUNT} -eq 3 ]
			then	
				echo "Changing VM definition for master-1.${CLUSTERFQDN}" 
				virsh setmem master-1.${CLUSTERFQDN} ${NEWRAMSIZE}
				ssh -i ${OCPSSHKEY} -o "StrictHostKeyChecking no" -q core@master-0.${CLUSTERFQDN} "sudo systemctl restart kubelet"
				sleep 20

				echo "Changing VM definition for master-2.${CLUSTERFQDN}" 
				virsh setmem master-2.${CLUSTERFQDN} ${NEWRAMSIZE}
				ssh -i ${OCPSSHKEY} -o "StrictHostKeyChecking no" -q core@master-0.${CLUSTERFQDN} "sudo systemctl restart kubelet"
				sleep 20
			fi
		else
			echo "Changing VM definition for ${NODETORESIZE}"
			virsh setmem ${NODETORESIZE} ${NEWRAMSIZE}
			ssh -i ${OCPSSHKEY} -o "StrictHostKeyChecking no" -q core@${NODETORESIZE} "sudo systemctl restart kubelet"
			sleep 20
		fi
		sleep 1
		echo "Resizing completed. Check 'oc adm top nodes'!"
		echo 
	fi


	if [ "${OPTION}" == "nodelogs" ]
	then
		#infranodelogs

		print-option-header infra "Display logs for a cluster node"

		if [ -n "$1" ]
		then
			# Surely the user knows what he's doing...
			NODENAME=$(get-node-fqdn $1)
			check-node-name $NODENAME exit
		else
			pick-a-node "Select the node name whose logs you want to follow"
		fi

		echo
		echo "Displaying logs for node [${NODENAME}] - (CTRL-C to disconnect when done)"
		echo
		ssh -i ${OCPSSHKEY} core@${NODENAME}  journalctl -b -f -u crio.service
	fi

	if [ "${OPTION}" == "sshtonode" ]
	then
		#infrasshtonode

		print-option-header infra "SSH into a cluster node"

		if [ -n "$1" ]
		then
			# Surely the user knows what he's doing...
			NODENAME=$(get-node-fqdn $1)
			check-node-name $NODENAME exit
		else
			pick-a-node "Select the node you want to ssh into"
		fi
		echo
		echo "Establishing SSH session to node [${NODENAME}] - (CTRL-D to disconnect when done)"
		echo
		ssh -i ${OCPSSHKEY} -o "StrictHostKeyChecking no" core@${NODENAME}
	fi


	if [ "${OPTION}" == "changeaccess" ]
	then
		#infrachangeaccess

		print-option-header infra "Change external access to cluster with FQDN [${CLUSTERFQDN}]"

		if [ ${HAPROXYACCESS} -eq 0 ]
		then
			PROXYACCESSSTATUS=ENABLED
			PROXYCHANGESTATUS=DISABLED
		else
			PROXYACCESSSTATUS=DISABLED
			PROXYCHANGESTATUS=ENABLED
		fi			

		echo -n "ACCESS STATUS: "
		if [ ${PROXYACCESSSTATUS} == "ENABLED"  ]
		then
			print-in-colour green "External access is ENABLED"
		else
			print-in-colour orange "External access is DISABLED" 

			echo
			echo "Enabling \"${OPTION}\" will permit access to your cluster from external clients in "
		        echo "your network. Disabling restricts access to ONLY the server running the cluster."
			echo "Open access is achieved by changing the haproxy configuration and by enabling"
			echo "wildcard DNS in your network configuration to provide access to all sub-domains"
			echo "created by OpenShift/Kubernetes for projects/namespaces."
			echo 
			echo "HOW \"${OPTION}\" WORKS ON YOUR LAN:"
			echo
			echo "   - After installation, YAKKO permits access to OpenShift to all clients in your network."
			echo "     This is achieved by allowing HAproxy to listen on all networks, via ports 80/443/6443/22623."
			echo
			echo "   - For other clients to know of your server, you need to extend a DNS wildcard:"
			echo
			echo "     1) You can use a DNS wildcard lookup facility served from this host *if needed*."
			echo "        For home/lab purposes, DNSMASQ is a great tool with this capability. "
			echo "        YAKKO can deploy a DNS workaround on this server. OR..."
			echo 
			echo "     2) If you choose to use your own DNS facility, you need to add a wildcard pointing"
			echo "        to this host's OCP entrypoint. If you already use DNSmasq, just add this line "
			echo "        to your DNSmasq configuration (be sure to replace the IP address if not correct):"
			echo
			echo "             address=/${CLUSTERFQDN}/${YAKKOHOSTIP}"
			echo
		fi
		echo

		ANSWER="N"
		if [ "$1" == "" ]
		then
			ask-user "Set OpenShift Cluster external access to [${PROXYCHANGESTATUS}]"  "Y" noauto
			ANSWER=$?
		else
			ANSWER=$1
		fi

		if [ "$ANSWER" == "1" -o "$ANSWER" == "n" -o "$ANSWER" == "N" ] 
		then
			echo
			echo "No changes were made. You can only access OpenShift from this server."
			echo
			cleanup-and-exit
		fi

		echo

		# We update the haproxy file to contain bind with restricted ports

		if [ ${PROXYCHANGESTATUS} == "ENABLED" ]
		then
			update-haproxy-access 0
			update-dnsmasq-config-file 0 # This will set HAPROXYACCESS to 0, which will be ENABLED
		else
			update-haproxy-access 1
			update-dnsmasq-config-file 1 # This will set HAPROXYACCESS to 1, which will be DISABLED
		fi

		update-haproxy-config-file 

		echo "Restarting NetworkManager (with DNSmasq plugin)"
		systemctl restart NetworkManager
		check-for-error-and-exit $? "Could not restart NetworkManager, the cluster cannot function without this - please check!"
		echo

		if [ ${PROXYCHANGESTATUS} == "ENABLED" ]
		then
			print-in-colour green "External access is now ENABLED: To access this cluster from another system"
			print-in-colour green "on your network add [${YAKKOHOSTIP}] as a DNS server to that system"
		else
			print-in-colour orange "External access is now DISABLED: Only this system can access this cluster"
		fi
		echo

	fi


	if [ ${OPTION} == "restartservices" ]
	then
		#infrarestartservices

		print-option-header infra "Restart Services: Virtual Network/HAproxy/libvirtd"

		echo "Restarting services allows the cluster to adapt to changes in your host"
		echo "IP address, for example when your laptop changes wireless/physical networks."
		echo
		echo "Restarting services can  also be useful when you are having issues that"
	       	echo "cascade from manually manipulating virtual networking, HAproxy and libvirtd. "
		echo "These components can also become 'stale' when making changes in SElinux and "
		echo "firewalld. 'restartservices' refreshes these components in coordination"
		echo
		echo "When the cluster is suspended or shut down, 'restartservices' can be used"
		echo "to attempt removal of any suspected services that may still be running."

		echo

		check-cluster-power
		CLUSTERSTATE=$?
		if [ $CLUSTERSTATE -eq 4 -o $CLUSTERSTATE -eq 5 ]
		then
			print-in-colour orange  "Cluster [${CLUSTERFQDN}] is not currently active."
			echo
			ask-user "Attempt stopping all supporting services" Y
			if [ $? -eq 0 ]
			then
				update-services stop
			fi
			cleanup-and-exit
		fi

		ask-user "Restart all supporting services" Y
		if [ $? -eq 1 ]
		then
			echo
			echo "Restart services aborted."
			echo
			cleanup-and-exit
		fi

		get-yakko-host-ip notifychange 
		update-services restart
	fi


	if [ ${OPTION} == "listresources" ]
	then
		#infralistresources

		print-option-header infra "Manage services introduced in your system by YAKKO"

		echo "This option helps you understand what services and files YAKKO has added or"
		echo "activated in your system, for better understanding and control. To deactivate"
		echo "any service, delete the associated file and run 'systemctl restart <service>'."
		echo "To regain full control of all services, issue 'yakko infra restartservices'"
		echo
		echo "Note that stopping a cluster with YAKKO will remove associated system files"
		echo "and stop associated services while the cluster is not in use."
		echo
		echo "There is one permanent change: to run on the host, YAKKO comments out the" 
		echo "Listen directive on port 80 in /etc/httpd/conf/httpd.conf"
		echo "_________________________________________________________________________"
		echo
		echo "The following YAKKO configuration files are present in this system:"
  
		FILESINUSE=1
		[ -e "${SYSTEMSTUBFILE_HAPROXY}" ] && {
			FILESINUSE=0
			print-in-colour lightblue  "- service: HAProxy"
			echo "  ${SYSTEMSTUBFILE_HAPROXY}"
			echo
		}

		[ -e "${SYSTEMSTUBFILE_DNSMASQ}" ] && {
			FILESINUSE=0
			print-in-colour lightblue  "- service: DNSmasq/NetworkManager"
			echo "  ${SYSTEMSTUBFILE_DNSMASQ}"
			echo
		}

		[ -e "${SYSTEMSTUBFILE_NETWORKMANAGER}" ] && {
			FILESINUSE=0
			print-in-colour lightblue  "- service: NetworkManager"
			echo "  ${SYSTEMSTUBFILE_NETWORKMANAGER}"
			echo
		}

		[ -e "${SYSTEMSTUBFILE_HTTPD}" ] && {
			FILESINUSE=0
			print-in-colour lightblue  "- service: httpd"
			echo "  ${SYSTEMSTUBFILE_HTTPD}"
			echo
		}

		[ -e "${SYSTEMSTUBFILE_RESOLVED}" ] && { 
			print-in-colour lightblue "- service: systemd-resolved"
			echo "  ${SYSTEMSTUBFILE_RESOLVED}"
			echo
		}

		if [ ${FILESINUSE} -eq 1 ]
		then
			echo "There are no files in use by any services at the moment."
			echo
		fi

		echo "Additionally, the following files are in use by the VM(s) of cluster:"
		ls -1 ${OCPVMDISKDIR} | grep "${CLUSTERNAME}.${DOMAINAME}" | sed -e "s+^+- ${OCPVMDISKDIR}/+"
		echo
	fi


	if [ ${OPTION} == "purgedownloads" ]
	then
		#infrapurgedownlaods

		print-option-header infra "Purge all OpenShift images on disk"

		purge-downloads
	fi 

	if [ ${OPTION} == "nfsshare" ]
	then
		#infranfsshare

		print-option-header infra "Configure NFS Share on YAKKO server"

		echo "This option allows you to setup a NFS share with OPEN permissions 777 to enable"
		echo "the share to be mounted as the registry store or as a store for a designated"
		echo "namespace to use with either of:"
	     	echo "    - yakko ops nfsregistry "
		echo "    - yakko ops nfspvc"
		echo

		install-package-if-missing nfs-utils

		while true
		do
			echo -n "Enter a directory on this server you want to share as NFS: "
			read NFSSHARE

			if [ ${NFSSHARE:0:1} != "/" ]
			then
				echo "You must enter an absolute path, starting with \"/\". Try again..."
				echo
				continue
			fi

			if [ ${NFSSHARE: -1} == "/" ]
			then
				# Remove trailing /
				NFSSHARE=${NFSSHARE::-1}
			fi

			echo
			echo "Testing the directory for establishing a NFS share..."
			sleep 1

			cat /etc/exports | grep "${NFSSHARE}" >/dev/null 2>&1
			if [ $? -eq 0 ]
			then
				echo "[${NFSSHARE}] is already in the exports list for this server, see /etc/exports"
				echo "You may want to check for permissions, ideally they should be:"
				echo "     *(rw,sync,no_wdelay,no_root_squash,insecure)"
				echo
				cleanup-and-exit
			fi
			
			mkdir -p "${NFSSHARE}" >/dev/null 2>&1
			if [ $? -ne 0 ]
			then
				echo "Could not create/access directory [${NFSSHARE}]. Try again..."
				continue
			fi

			chmod 777 "${NFSSHARE}" >/dev/null 2>&1
			if [ $? -ne 0 ]
			then
				echo "Could not change mode of [${NFSSHARE}] to all-rw (777). Try again..."
				echo
				continue
			fi

			touch ${NFSSHARE}/testfile >/dev/null 2>&1
			if [ $? -ne 0 ]
			then
				echo "Could not create test file  [${NFSSHARE}/testfile]. Try again..."
				echo
				continue
			else
				rm ${NFSSHARE}/testfile >/dev/null 2>&1
				break
			fi
		done

		echo "Directory [${NFSSHARE}] tested successfully. Setting up NFS share."
		sleep 1

		echo "${NFSSHARE} *(rw,sync,no_wdelay,no_root_squash,insecure)" >> /etc/exports
		if [ $? -eq 0 ]
                then
                	echo "Added [${NFSSHARE} *(rw,sync,no_wdelay,no_root_squash,insecure)] to /etc/exports"
			echo
		else 
			echo "Could not add share to /etc/exports. Cannot continue!"
			echo
			cleanup-and-exit
		fi

		exportfs -a >/dev/null 2>&1
		showmount -e | grep "${NFSSHARE}" >/dev/null 2>&1
		if [ $? -ne 0 ]
                then
			echo "Failed to export [${NFSSHARE}] (see exportfs -a and showmount -e). Cannot continue!"
			cleanup-and-exit
		else
			print-in-colour green "NFS share [${NFSSHARE}] established successfully!"
			echo
		fi
	fi 

	if [ ${OPTION} == "deletecluster" ]
	then

		#infradeletecluster

		# Danger Will Robinson!
		echo
		print-in-colour red "ALERT: DELETE CLUSTER REQUEST"
		echo

		if  [ "$1" == "force" ]
		then
			# Someone's feeling lucky
			print-in-colour red "FORCE REQUESTED - NO QUESTIONS ASKED!"
			DELETECLUSTERMODE=0
			DELETECLUSTERFORCE=0
			DELETECLUSTERNAME=${CLUSTERNAME}
			yakko-process-stages rollback
		fi

		if  [ "$1" == "${CLUSTERNAME}" ]
		then
			echo "You have requested to DELETE the current cluster: [${CLUSTERNAME}]"
			echo
			echo -n "Please confirm by entering the cluster name again: "
			read DELETECLUSTERNAME
			if [ "${DELETECLUSTERNAME}" == "${CLUSTERNAME}" ]
			then
				# We signal that this is happening in case it's needed to know in rollbacks
				DELETECLUSTERMODE=0
				DELETECLUSTERFORCE=1
				yakko-process-stages rollback
			else
				echo
				echo "ERROR: incorrect cluster name, delete not confirmed."
			fi
		else
			echo "ALERT: To delete cluster [${CLUSTERNAME}] and all associated ${YAKKONAME} configuration, you also need to pass the clustername" 
			echo "RUN:   yakko infra deletecluster ${CLUSTERNAME}"
			echo
		fi
	fi

	cleanup-and-exit

}


##########################################################################################################
### YAKKO OPS 
##########################################################################################################

print-yakko-ops-operations-menu() {

	# Catchall for any other passed parameted at this point
	echo "USAGE: ${YAKKONAME} ops <OPTION> [parameters]" 
	echo
	echo "OPTION is one of:"
	echo "    - htpasswd      ->  Deploy local password access and a new administrator"
	echo "    - useradd       ->  Add a new user to local htpasswd DB"
	echo "    - userdelete    ->  Delete an existing user from the local htpasswd DB"
	echo "    - mastersched   ->  Enable/disable master scheduling"
	echo "    - nodelabel     ->  Change the label of a node between worker <-> infra"
	echo "    - localregistry ->  Enable localstorage registry (volatile)"
	echo "    - nfsregistry   ->  Enable an existing NFS share as registry (persistent)"
	echo "    - nfsmap        ->  Map an existing NFS share to a namespace"
	echo "    - ingresscert   ->  Install an existing wildcard certificate"
	echo "    - approvecsrs   ->  Approve any outstanding CSRs (Certificate Signing Requests)"
	echo "    - yakkotest     ->  Deploy the 'yakkotest' app on your cluster, to test the lot!!"
	echo
}


yakko-ops-operations() {

	# This is just nice stuff to have after the install is done
	# we're here because the user called "yakko ops"

	OPTION=$1
	shift 

	echo "${YAKKOCLUSTEROPTIONS}" | grep " ${OPTION} " > /dev/null
	if [ -z "${OPTION}" -o $? -ne 0 ]
	then
		print-yakko-ops-operations-menu
		cleanup-and-exit
	fi

	if [ ${OPTION} == "htpasswd" ]
	then
		#opshtpasswd

		print-option-header ops "Enable ADMIN and local passwords"

		check-oc-credentials-and-state

		# Need htpasswd from httpd-tools
		install-package-if-missing httpd-tools 

		if [ -z "${YAKKOHTPASSWD}" ]
		then
			if [ -z "$1" ]
			then
				NEWUSER=administrator
				echo "You must enter a new administrator who will be granted cluster-admin role."
				echo -n "Enter a new admin username to add to the HTPasswd provider [administrator]: "
				read NEWUSER
			        [ -z "${NEWUSER}" ] && NEWUSER="administrator"	
			else
				NEWUSER="$1"
			fi

			if [ -z "$2" ]
			then
				echo
				echo -n "Enter password for user [$NEWUSER]: "
				read -s NEWPASSWORD
				echo
				echo -n "Retype password for confirmation: "
				read -s CONFIRMPASSWORD
				echo
				if [ "$NEWPASSWORD" != "$CONFIRMPASSWORD" ]
				then
					echo "Passwords didn't match! Exiting..."
					echo
					cleanup-and-exit
				fi
			else
				NEWPASSWORD="$2"
			fi

			TMPOAUTHCONFIGFILE=/tmp/oauth-config-$$.yaml

			{
				echo "apiVersion: config.openshift.io/v1"
				echo "kind: OAuth"
				echo "metadata:"
				echo "  name: cluster"
				echo "spec:"
				echo "  identityProviders:"
				echo "  - name: Local Password"
				echo "    mappingMethod: claim"
				echo "    type: HTPasswd"
				echo "    htpasswd:"
				echo "      fileData:"
				echo "        name: htpass-secret"
			} > ${TMPOAUTHCONFIGFILE}

			${OCCOMMAND} apply -f ${TMPOAUTHCONFIGFILE}
			check-for-error-and-exit $? "Could not apply OAuth Custom Resource for HTaccess (see ${TMPOAUTHCONFIGFILE})" 

			htpasswd -c -B -b ${HTPASSWDFILE} $NEWUSER $NEWPASSWORD
			${OCCOMMAND} create secret generic htpass-secret --from-file=htpasswd=${HTPASSWDFILE} -n openshift-config
			echo "YAKKOHTPASSWD=1" >> ${CLUSTERCONFIGFILE}
			sleep 3

			${OCCOMMAND} adm policy add-cluster-role-to-user cluster-admin $NEWUSER
			check-for-error-and-exit $? "Could not enable $NEWUSER as a user." 
			echo
			echo "Added [$NEWUSER] admin user with cluster-admin role successfuly"
			echo
			YAKKOADMIN=${NEWUSER}
			echo "YAKKOADMIN=${NEWUSER}" >> ${CLUSTERCONFIGFILE}

			if [ -z "$3" ]
			then
				ask-user "Disable 'kubeadmin' account" Y 
				ANSWER=$?
			else
				ANSWER=$3
			fi

			if [ "$ANSWER" == "0" -o "$ANSWER" == "Y" -o "$ANSWER" == "y" ]
			then
				echo "Deleting secret for 'kubeadmin' account" 
				${OCCOMMAND} --user=admin delete secret kubeadmin -n kube-system
				[ $? -eq 0 ] && echo "KUBEADMIN=''" >> ${CLUSTERCONFIGFILE}
				echo "Note that the system:admin account is still available"

				# and ... the webpage
				sed -i "s/kubeadmin/${YAKKOADMIN}/" ${IMAGEREPO}/index.html
				sed -i "/Password:/d" ${IMAGEREPO}/index.html
			fi

			echo
			echo "It may take a while for this change to become effective."
				echo
			echo
	
		else
			echo "Local passwords have already been enabled."
			echo
		fi
	fi

	if [ ${OPTION} == "useradd" ]
	then
		#opsuseradd

		print-option-header ops "Add a local htpasswd user"

		check-oc-credentials-and-state

		[ "${YAKKOHTPASSWD}" == 1 ] 
		check-for-error-and-exit $? "You need to first configure Local Passwords via \"$YAKKONAME ops htpasswd\"" 

		if [ -z "$1" ]
		then
			echo -n "Enter the name for a new user to add to the HTPasswd provider: "
			read NEWUSER
		else
			NEWUSER="$1"
		fi
		
		if [ -z "$2" ]
		then
			echo -n "Enter password for user [$NEWUSER]: "
			read -s NEWPASSWORD
			echo
			echo -n "Retype password for confirmation: "
			read -s CONFIRMPASSWORD
			echo
			if [ "$NEWPASSWORD" != "$CONFIRMPASSWORD" ]
			then
				echo "Passwords didn't match! Exiting..."
				echo
				cleanup-and-exit
			fi
		else
			NEWPASSWORD=$2
		fi

		${OCCOMMAND} get secret htpass-secret -n openshift-config -o jsonpath="{.data.htpasswd}" | base64 -d > ${HTPASSWDFILE}
		htpasswd -Bb ${HTPASSWDFILE} ${NEWUSER} "${NEWPASSWORD}"
		${OCCOMMAND} patch secret htpass-secret -n openshift-config -p "{\"data\":{\"htpasswd\":\"$(base64 -w0 ${HTPASSWDFILE})\"}}"
		check-for-error-and-exit $? "Could not retrieve existing htpasswd file from the cluster" 

		${OCCOMMAND} adm policy add-cluster-role-to-user self-provisioner $NEWUSER
		check-for-error-and-exit $? "Could not assign self-provisioner role to $NEWUSER" 

		echo
		echo "It may take a while for this change to become effective."
		echo

		rm ${HTPASSWDFILE} >/dev/null 2>&1

		echo
		echo "Success: added user [$NEWUSER] and assigned self-provisioner role."
		echo "It may take a few moments before you can login."
		echo
	fi

	if [ "${OPTION}" == "userdelete" ]
	then
		#opsuserdelete

		print-option-header ops "Delete a local htpasswd user"

		check-oc-credentials-and-state

		[ "${YAKKOHTPASSWD}" -eq 1 ]
                check-for-error-and-exit $? "There is no local HTPasswd configured, cannot delete anyone yet!"

                [ -n "$1" ]
                check-for-error-and-exit $? "You need to pass a USERNAME for the username to delete - yakko ops userdelete <username>"

		DELUSER=$1
		${OCCOMMAND} get secret htpass-secret -n openshift-config -o jsonpath="{.data.htpasswd}" | base64 -d > ${HTPASSWDFILE}

		cat ${HTPASSWDFILE} | grep $DELUSER > /dev/null
		if [ $? -eq 0 ]
		then
			htpasswd -D ${HTPASSWDFILE} $DELUSER
			${OCCOMMAND} patch secret htpass-secret -n openshift-config -p "{\"data\":{\"htpasswd\":\"$(base64 -w0 ${HTPASSWDFILE})\"}}"
			check-for-error-and-exit $? "Could not update password file in OCP, user not deleted"

			echo "It may take a while for this change to become effective."
			echo
		else
			echo "User [$DELUSER] not found in OCP, could not delete."	
		fi
		echo
	fi
		
	if [ "${OPTION}" == "localregistry" ]
	then
		#opslocalregistry

		print-option-header ops "Enable local registry"

		check-oc-credentials-and-state

		if [ $(check-registry-type) == local ]
		then
			echo "Local Registry is already configured!"
		        echo "But can be replaced with NFS - yakko ops nfsregistry"
			echo
			cleanup-and-exit
		fi

		if [ $(check-registry-type) == nfs ]
		then
			print-in-blink "ALERT: NFS Registry is already configured! Continue to replace." 
		fi

		# The below is for automating by issuing "yakko ops localregistry Y"
		ANSWER=N
		if [ "$1" == "" ]
		then
			ask-user "Enable local registry (images will be lost on registry restart)" "Y" noauto
			ANSWER=$?
		else
			ANSWER=$1
		fi

		if [ "$ANSWER" == 0 -o "$ANSWER" == "Y" -o "$ANSWER" == "y" ]
		then
			# This first line is just so can change from NFS to local if you are already on NFS. It also lets me test quickly :)
			${OCCOMMAND} patch configs.imageregistry.operator.openshift.io cluster --type json -p='[{"op": "remove", "path": "/spec/storage/pvc"}]' >/dev/null 2>&1
			${OCCOMMAND} patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"storage":{"emptyDir":{}}}}'
			${OCCOMMAND} patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Managed"}}'

			#We clean up any remaining nfs mounts for the cluster registry - it doesn't matter if there are none
			if [ $(check-registry-type) == nfs ]
			then
				echo "Deleting existing NFS persistent volume and claim for registry..."
				${OCCOMMAND} delete pvc pvc-ocpclusterregistry -n openshift-image-registry >/dev/null 2>&1
				${OCCOMMAND} delete pv pv-ocpclusterregistry >/dev/null 2>&1
			fi

			COUNTER=300
			echo
			echo "Waiting up to 5 minutes to allow image-registry operator to become locally available..."
			echo

			while [ ${COUNTER} -gt 0 ]
			do
				((COUNTER-=10))
				sleep 10 # We let ocp settle the change and spin a "Running" container

				if [ $(check-registry-type) == local ]
				then
					print-in-colour green "Local registry is now operational"
					break
				fi
			done

			if [ ${COUNTER} -eq 0 ]
			then
				print-in-colour red "Local registry is NOT operational - check image-registry pod in namespace openshift-image-registry"
			fi
			echo
		fi
	fi

	if [ "${OPTION}" == "nfsregistry" ]
	then
		#opsnfsregistry

		print-option-header ops "Enable NFS registry"

		check-oc-credentials-and-state

		if [ $(check-registry-type) == nfs ]
		then
			echo "NFS Registry is already configured!"
			echo "To replace it, move the registry to local - yakko ops localregistry"
			echo
			cleanup-and-exit
		fi

		if [ $(check-registry-type) == local ]
		then
			print-in-blink "ALERT: Local Registry is already configured! Continue to replace."
		fi

		ANSWER=N
		if [ "$1" == "" ]
		then
			ask-user "Enable NFS registry" "Y" noauto
			ANSWER=$?
		else
			if [ $# -ne 3 ]
			then 
				echo "USAGE: yakko ops nfsregistry <SERVER> <SHARE> <CAPACITY in Gib>"
			else
				ANSWER=Y
				NFSSERVER=$1
				NFSSHARE=$2
				NFSCAPACITY=$3
			fi
		fi

		if [ "$ANSWER" == 0 -o "$ANSWER" == "Y" -o "$ANSWER" == "y" ]
		then

			mount-nfs-share # This populates $NFSSERVE and $NFSHARE

			echo
			echo "Capacity availability on the selected share will not be tested."
			while true
			do
				echo -n "What capacity should the PVC request have in GiB [100]? "
				read NFSCAPACITY
				if [ -z "${NFSCAPACITY}" ] 
				then
					NFSCAPACITY=100
				fi
				if ! [[ ${NFSCAPACITY} =~ $NUMBERRE ]] ; then
					echo "Error: Not a number. Try again..."
					continue
				fi
				if [[ ${NFSCAPACITY} -lt 10 ]] ; then
					echo "That's not very big... up to you!"
					continue
				fi 
				break
			done

			create-nfs-pvc ocpclusterregistry "${NFSSERVER}" "${NFSSHARE}" openshift-image-registry ${NFSCAPACITY} 
			${OCCOMMAND} patch configs.imageregistry.operator.openshift.io cluster --type json -p='[{"op": "remove", "path": "/spec/storage/emptyDir"}]' >/dev/null 2>&1
			${OCCOMMAND} patch configs.imageregistry.operator.openshift.io/cluster --type merge --patch '{"spec":{"managementState": "Managed","storage":{"managementState": "Unmanaged","pvc":{"claim":"pvc-ocpclusterregistry"}}}}' 

			COUNTER=300
			echo
			echo "Waiting up to 5 minutes to allow image-registry operator to mount NFS share..."
			echo

			while [ ${COUNTER} -gt 0 ]
			do
				((COUNTER-=10))
				sleep 10 # We let ocp settle the change and spin a "Running" container

				if [ $(check-registry-type) == nfs ]
				then
					print-in-colour green "NFS Mount for registry is now operational"
					echo "You may have to wait for the change to register across all operators - check 'oc get co'"
					break
				fi
			done

			if [ ${COUNTER} -eq 0 ]
			then
				print-in-colour red "NFS Mount for registry is NOT operational - check image-registry pod in namespace openshift-image-registry"
			fi

			echo
		fi
	fi

	if [ "${OPTION}" == "nfsmap" ]
	then
		#opsnfsmap

		#Lots of good stuff here:
		#https://docs.openshift.com/container-platform/4.9/storage/persistent_storage/persistent-storage-nfs.html

		print-option-header ops "Map an existing NFS share to a namespace"

		echo "Here you can use an existing NFS share to be mounted and mapped to a namespace"
		echo "If you don't have a share yet, you can create a new share on this server by issuing:"
		echo "    - yakko infra nfsshare"

		check-oc-credentials-and-state

		ANSWER=N
		if [ "$1" == "" ]
		then
			echo
			ask-user "Map (mount) an existing NFS share on a namespace" "Y" noauto
			ANSWER=$?
		else
			if [ $# -ne 2 ]
			then 
				echo "USAGE: yakko ops nfsregistry <SERVER> <SHARE>"
			else
				ANSWER=Y
				NFSSERVER=$1
				NFSSHARE=$2
			fi
		fi
		echo

		if [ "$ANSWER" == 0 -o "$ANSWER" == "Y" -o "$ANSWER" == "y" ]
		then

			mount-nfs-share # This populates $NFSSERVER and $NFSHARE

			echo
			echo -n "Enter a base name for the persistent volume / claim that will appear in OpenShift: "
			read PVCNAME
			echo
			while true
			do
				echo -n "Enter the namespace that you want to map this NFS share to: "
				read NAMESPACE

				oc get projects | awk '{ print $1 }' | grep ${NAMESPACE} >/dev/null 2>&1
				if [ $? -ne 0 ]
				then
					echo "That namespace (project) does not exist, try again..."
					echo
					continue
				fi
				break
			done

			echo
			echo "Capacity availability on the selected share will not be tested."
			while true
			do
				echo -n "What capacity should the PVC request have in GiB [100]? "
				read NFSCAPACITY
				if [ -z "${NFSCAPACITY}" ] 
				then
					NFSCAPACITY=100
				fi
				if ! [[ ${NFSCAPACITY} =~ $NUMBERRE ]] ; then
					echo "Error: Not a number. Try again..."
					continue
				fi
				if [[ ${NFSCAPACITY} -lt 10 ]] ; then
					echo "That's not very big... up to you!"
					continue
				fi 
				break
			done

			create-nfs-pvc ${PVCNAME} "${NFSSERVER}" "${NFSSHARE}" ${NAMESPACE} ${NFSCAPACITY} 

			echo
			print-in-colour green "NFS share [${NFSSHARE}] should now be available in namespace [${NAMESPACE}]"

			# REF: https://infohub.delltechnologies.com/l/deployment-guide-red-hat-openshift-container-platform-4-2/creating-a-pod-using-nfs-pvc-5
			echo
			echo "If you want to test this, you can create the following pod as pod.yaml"
			echo
			echo "apiVersion: v1"
			echo "kind: Pod"
			echo "metadata:"
			echo "  name: nfspod"
			echo "spec:"
			echo "  containers:"
			echo "  - name: myfrontend"
			echo "    image: nginx"
			echo "    volumeMounts:"
			echo "    - mountPath: \"/var/www/html\""
			echo "      name: nfsshare"
			echo "  volumes:"
			echo "  - name: nfsshare"
			echo "    persistentVolumeClaim:"
			echo "      claimName: pvc-${PVCNAME}"
			echo 
			echo "and finally run:   oc apply -f pod.yaml"
			echo
			echo "If you are not in an pirivileged account, you may want to help nginx along:"
			echo "oc adm policy add-scc-to-user anyuid system:serviceaccount:<PROJECTNAME>:default"
			echo
			echo "This will mount your share on /var/www/html of the pod - create an index.html file in your share!"
			echo "You can also issue 'oc get pods <namespace>' and then 'oc rsh nfspod'"
			echo "Once in the pod, simply call 'mount' and you should see your NFS mount there"
			echo
		fi
	fi


	if [ "${OPTION}" == "mastersched" ]
	then
		#opsmastersched

		print-option-header ops "Change MASTER node(s) scheduling state"

		# We check that you can still go on after cred check
		check-oc-credentials-and-state

		echo "This is an important change that may affect the behaviour of your workloads"
		echo "and is simply being provided by YAKKO as a mechanism to change new nodes quickly."
		echo "Use at your own risk!"
		echo

		${OCCOMMAND} get nodes | grep master-0 | grep worker > /dev/null 2>&1
		if [ $? -eq 0 ] #Masters are schedulable because they read 'worker'
		then
			MASTERSCHEDSTATE=true
			echo -n "Masters are currently "
			print-in-colour green "SCHEDULABLE"
			echo
			if [ $(${OCCOMMAND} get nodes | grep "node-" | grep -v NotReady | grep -c Ready) -eq 0 ] 
			then
				echo 
				print-in-blink "ATTENTION: There are no worker nodes available! Proceed with caution."
				echo
			fi
			ask-user "Change masters to [NOT SCHEDULABLE]" Y noauto
			[ $? -eq 0 ] && NEWMASTERSCHEDSTATE=false
		else
			MASTERSCHEDSTATE=false
			echo -n "Masters are currently " 
			print-in-colour orange "NOT SCHEDULABLE"
			echo
			ask-user "Change masters to [SCHEDULABLE]" Y noauto
			[ $? -eq 0 ] && NEWMASTERSCHEDSTATE=true
		fi

		if [ -n "${NEWMASTERSCHEDSTATE}" ]
		then
			# Little hack...
			export KUBE_EDITOR="sed -i s+mastersSchedulable:\ ${MASTERSCHEDSTATE}+mastersSchedulable:\ ${NEWMASTERSCHEDSTATE}+"

			${OCCOMMAND} edit schedulers.config.openshift.io cluster
			[ $? -ne 0 ] && echo "This operation was not succssful"
			echo
		fi

		update-haproxy-config-file
	fi

	if [ "${OPTION}" == "nodelabel" ]
	then
		#opsnodelabel
		# This one is for fun, has a cute little hack

		print-option-header ops "Change node label: WORKER ←→ INFRA"

		check-oc-credentials-and-state

                CURRENTNODES=" $(${OCCOMMAND} get nodes | grep "^node-" | awk '{print $1}') "

                if [ -z "${CURRENTNODES}" ]
                then
                        echo "There are no worker/infra nodes defined, nothing to change!"
                        echo
                        cleanup-and-exit
                fi


		if [ -z "$(${OCCOMMAND} get nodes | grep "^node-" | awk '{print $1, $3}')" ]
		then
			echo "There are no nodes available for relabeling!"
			echo
			cleanup-and-exit
		fi

		echo "This is an important change that may affeect the behaviour of your workloads"
		echo "and is simply being provided by YAKKO as a mechanism to change new nodes quickly."
		echo "Use at your own risk!"
		echo

                echo "The following nodes are available for relabeling: "
		${OCCOMMAND} get nodes | grep "^node-" | awk '{print $1, $3}'

                while true
                do

                        echo -n "Enter the name of the node you want to relabel: "
                        read NODENAME
			
			echo ${CURRENTNODES} | grep ${NODENAME} > /dev/null 2>&1
			[ $? -ne 0 ] && {
				echo "Invalid node name"
				echo
				continue
			}
		break
		done

		NODELABEL=$(${OCCOMMAND} get nodes | grep ${NODENAME}" "| awk '{print $3}')

		if [ ${NODELABEL} == "worker" ]
		then
			NEWNODELABEL="infra"
		else
			NEWNODELABEL="worker"
		fi
		
		# Little hack...
		export KUBE_EDITOR="sed -i s+node-role.kubernetes.io/${NODELABEL}+node-role.kubernetes.io/${NEWNODELABEL}+"

		echo
		ask-user "Change [${NODENAME}] label from [${NODELABEL}] to [${NEWNODELABEL}]" Y noauto
		if [ $? -eq 0 ]
		then
			${OCCOMMAND} edit node ${NODENAME}
			[ $? -ne 0 ] &&
				echo "This operation was not succssful"
		else
			echo "No changes were made./"
		fi
		echo
	
	fi

	if [ "${OPTION}" == "ingresscert" ]
	then
		#opsingresscert

		print-option-header ops "Install an ingress wildcard certificate"

		check-oc-credentials-and-state

		if [ -n "$1" ]
		then
			AUTOSETUP=1
			CERTBUNDLEFILE=$1
			CERTBUNDLEPATH=$(dirname $1)

			if [ ! -r ${CERTBUNDLEFILE} ]
			then
				echo "$1 is not a valid certificate bundle - check file and permissions!"
				echo
				cleanup-and-exit
			fi
		else
			echo "To proceed you must:" 
			echo "- own your own domain [${CLUSTERDOMAIN}]!"
			echo "- have admin access to the domain's control panel"
			echo "- provide a wildcard certificate for apps.${CLUSTERFQDN} as a certificate bundle in your filesystem"

			echo
			print-in-colour green "GUIDELINES FOR USING letsencrypt.com AS A CERTIFICATE SOURCE"
			echo
			echo "  1) Obtain a certificate from this server using the free 'letsencrypt.com' service"
			echo "     you will need to install  certbot, e.g.  dnf install certbot"
			echo 
			echo "     For RHEL you may require adding EPEL repos: "
			echo "     dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm"
			echo
			echo "  2) Issue a request like:  certbot -d '*.apps.${CLUSTERFQDN}' --manual --preferred-challenges dns certonly"
			echo
			echo "  3) Follow the instructions above and use the following to test if the DNS challenge is resolving"
			echo "     before certbot checks the challenge!"
			echo "     https://dnschecker.org/#TXT/_acme-challenge.apps.${CLUSTERFQDN}"
			echo
			echo "  NOTE: Visit for help: https://stephennimmo.com/securing-openshift-ingress-with-lets-encrypt/"
			echo "  NOTE: See here for expired certificates: https://dentrassi.de/2021/01/18/recovering-from-an-expired-openshift-certificate/"
			echo

			ask-user "Are you ready to proceed?" Y auto
			if [ $? -ne 0 ]
			then
				echo "Exiting. Just run this command again when all requirements are met."
				echo
				cleanup-and-exit
			fi
			echo

			CERTBUNDLEPATH=/etc/letsencrypt/live/apps.${CLUSTERFQDN}
			CERTBUNDLEFILE=${CERTBUNDLEPATH}/fullchain.pem

			# WE check in advance if the cert is where certbot puts it...
			if [ ! -r ${CERTBUNDLEFILE} ]
			then
				CERTBUNDLEFILE=""
			fi

			while true
			do
				if [ -z "${CERTBUNDLEFILE}" ]
				then
					echo -n "Enter path to certificate bundle: "
				else
					echo -n "Enter path to certificate bundle [$CERTBUNDLEFILE]: "
				fi
				read CERTBUNDLEALTFILE
	
		       		if [ -z "${CERTBUNDLEALTFILE}" -a -n "${CERTBUNDLEFILE}" ]
				then 
					# The user accepted the default which has been verified already
					break
				fi

		       		if [ -n "${CERTBUNDLEALTFILE}" ]
				then
					if [ -r ${CERTBUNDLEALTFILE} ]
					then
						CERTBUNDLEFILE=${CERTBUNDLEALTFILE}
						break
					else
						echo "Invalid certificate bundle."
						echo
						continue
					fi
				fi

			done
		fi

		if [ -r ${CERTBUNDLEPATH}/privkey.pem ]
		then
			echo "Private key [privkey.pem] found at ${CERTBUNDLEPATH} - continuing..."
		else
			echo "Private key [privkey.pem] was expected at ${CERTBUNDLEPATH} but not found there. Exiting!"
			cleanup-and-exit
		fi

		echo

		${OCCOMMAND} create configmap custom-ca --from-file=ca-bundle.cert=${CERTBUNDLEFILE} -n openshift-config
		${OCCOMMAND} patch proxy/cluster --type=merge  --patch='{"spec":{"trustedCA":{"name":"custom-ca"}}}'
		check-for-error-and-exit $? "Unable to apply patched config map in / custom-ca!"

		${OCCOMMAND} create secret tls custom-ca-secret --cert=${CERTBUNDLEFILE} --key=${CERTBUNDLEPATH}/privkey.pem -n openshift-ingress
		${OCCOMMAND} patch ingresscontroller.operator default \
		       	--type=merge -p '{"spec":{"defaultCertificate": {"name": "custom-ca-secret"}}}' -n openshift-ingress-operator
		check-for-error-and-exit $? "Unable to apply patched private key in / custom ca!"

		echo
		echo "NOTE: If the 'network' and/or 'machine-config' operator goes into degraded mode, run 'oc edit proxy.config.openshift.io cluster'  and:"
		echo "      - clear field trustedCA: "
		echo "      - change 'name:' field to \"\" "
		echo "      - save changes"
		echo "      - oc describe co/network should show an error message that describes the issue"
		echo

	fi

	# VERSION 1.1 - Approve outstanding CSRs
	if [ "${OPTION}" == "approvecsrs" ]
	then
		#opsapprovecsrs

		print-option-header ops "Pending Certificate Signing Request (CSR) approval" 

		PENDINGCSRS=$(${OCCOMMAND} get csr 2>/dev/null | grep Pending | awk '{ print $1 }')

		set ${PENDINGCSRS} > /dev/null

		if [ $# -gt 0 ]
		then
			ask-user "There are [$#] CSRs in PENDING state. Approve" Y

			if [ $? -eq 0 ]
			then
				CURRENTCSRNUM=0

				for CSRNAME in ${PENDINGCSRS}
				do
					((CURRENTCSRNUM+=1))
					echo -n "${CURRENTCSRNUM}: "
					${OCCOMMAND} adm certificate approve ${CSRNAME}
				done
			fi
			echo
			echo "CSR approval can cascade for additional CSRs. Be sure to check again."
		else
			echo
			echo "There are no pending CSRs to approve"
		fi
		echo
	fi

	if [ "${OPTION}" == "yakkotest" ]
	then
		#opsyakkotest

		print-option-header ops "Deploy the YAKKO test application"

		if [ $(check-registry-type) == "none" ]
		then
			echo "Cannot deploy YAKKO test app as there is no registry defined."
			echo "First, run 'yakko ops localregistry' or 'yakko ops nfsregistry'"
			echo
			cleanup-and-exit
		fi

		${OCCOMMAND} new-project yakkotest
		check-for-error-and-exit $? "Could not create project 'yakkotest' in OpenShift"
		${OCCOMMAND} new-app httpd:latest~https://github.com/ozchamo/yakko-test.git --name=yakko
		check-for-error-and-exit $? "could not create new application 'yakko' in OpenShift"
		# Long form: oc new-app --image-stream httpd:latest https://github.com/ozchamo/yakko-test.git --name=yakko
		# Except this does not work because Language Detection is enabled and... it doesn't detect!
		${OCCOMMAND} expose service yakko --hostname=yakkotest.apps.${CLUSTERFQDN}
		check-for-error-and-exit $? "Could not expose route for 'yakkotest.apps.${CLUSTERFQDN}'"

		echo ${SEPARATIONLINE}
		echo
		echo
		echo "OpenShift will begin building the project"
		echo "Inspect progress by issuing 'oc get pods -n yakkotest'"
		echo
		echo "Once yakkotest is up, point your browser to: http://$(${OCCOMMAND} get routes | grep yakkotest | awk '{print $2}')"
		echo
	fi
		
	cleanup-and-exit
}


###### STAGE PROCESSORS FOLLOW ################################################
# progress is move forwarwd, configure, install
# rollback is move back, undo, delete
###############################################################################


process-stage-libvirt() {
	
	#stagelibvirt

	[ $1 == "progress" ] && {
	
		advance-stage-progression "Libvirt package install/start" 
		# This one is mandatory so there is no && return at the end of the call
		# The thing is, if there is no KVM, there is no hope!

		#VIRTUALISATION IS MANDATORY THE FIRST TIME WE RUN THIS
		systemctl status libvirtd --no-pager > /dev/null 2>&1
		[ $? -ne 0 ] && {

			install-package-if-missing libvirt 
			#install-package-if-missing bridge-utils 
			install-package-if-missing virt-install
			install-package-if-missing qemu-kvm
			install-package-if-missing virt-top
		}

		cat /proc/cpuinfo | grep -E "vmx|svm" >/dev/null 2>&1
		check-for-error-and-exit $? "Virtualisation extensions are not enabled in this system!"			

		systemctl enable libvirtd --now > /dev/null 2>&1
		systemctl status libvirtd --no-pager > /dev/null 2>&1
		check-for-error-and-exit $? "Failed to enable [libvirtd]" 

		echo "Libvirt is installed and active"

		# and just in case...
		lsmod | grep kvm >/dev/null
		check-for-error-and-exit $?  "KVM kernel modules are not loaded!"
	}

	# Nothing to rollback
	[ $1 == "rollback" ] && {
		rollback-stage-progression "Libvirt will remain installed"
	}
}


process-stage-pullsecret() {

	#stagepullsecret

	[ $1 == "progress" ] && {

		advance-stage-progression "Load pull secret" && return

		[ -r ${PULLSECRETFILE} ] && PULLSECRET=$(cat ${PULLSECRETFILE})

		ask-user "Add a new pull secret" N
		WANTPULLSECRET=$?

		# There is no pull secret on file or user wants a new one now
		if [ -z "${PULLSECRET}" -o ${WANTPULLSECRET} -eq 0 ]
		then
			echo "A new pull secret is required."
		        echo "Please copy/paste pull secret from [ https://cloud.redhat.com/openshift/install/metal/user-provisioned ] or enter the path of a local file with it:"
		        read PULLSECRET
			if [ -f $PULLSECRET ]
			then
				PULLSECRET=$(cat $PULLSECRET)
			fi
		        echo $PULLSECRET > ${PULLSECRETFILE}
		else
			echo "Using saved pull secret"
		fi
	}

	# Nothing to rollback - we don't want to delete the existing pull secret
	[ $1 == "rollback" ] && {
		rollback-stage-progression "Existing Pull Secret will remain in place"
	}
}


process-stage-sshclient() {

	#stagesshclient

	[ $1 == "progress" ] && {

	        advance-stage-progression "SSH key configuration" && return

		ask-user "Create new SSH key for node access" "Y"  && {
			
			#We clear a potential clash for ssh logins in .known_hosts
			sed -i "/bootstrap.${CLUSTERFQDN}/d" /root/.ssh/known_hosts > /dev/null 2>&1
			ssh-keygen -t rsa -b 4096 -N '' -f ${OCPSSHKEY}
		 	check-for-error-and-exit $?  "Failed to create SSH key"
			eval "$(ssh-agent -s)"
			ssh-add ${OCPSSHKEY}
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting ssh key and removing cluster hosts from ssh known hosts"
		rm -r ${OCPSSHKEY} > /dev/null 2>&1
		rm -r ${OCPSSHKEY}.pub > /dev/null 2>&1

		get-node-list all
		for NODENAME in ${NODELIST}
		do
			sed -i "/${NODENAME}/d" /root/.ssh/known_hosts 2> /dev/null
		done
	}
}


process-stage-virtualnetwork() {

	#stagevirtualnetwork

	[ $1 == "progress" ] && {
	
        	advance-stage-progression "Virtual Network Configuration" && return

		ask-user "Configure Virtual Network" "Y" && {

			NETWORKXML=$CLUSTERSETUPDIR/${NETWORKNAME}.xml
		
			echo Cleaning up network...
			virsh net-destroy ${NETWORKNAME} > /dev/null 2>&1
			virsh net-undefine ${NETWORKNAME} > /dev/null 2>&1
			
			NETWORKTYPE=1 # Query when BRIDGE is supported. Not yet ;)
		
			if [ $NETWORKTYPE == 1 ] # NAT
			then
				echo "YAKKO will create all infrastructure in the ${BASENETWORK}/24 subnet with preallocated IP addresses:"
				echo Bootstrap: ${BOOTSTRAPIP}	
				if [ ${MASTERNODECOUNT} -eq 1 ]
				then
					echo Master: ${MASTER0IP} 
				else
					echo Masters: ${MASTER0IP} ${MASTER1IP} and ${MASTER2IP}
				fi
				echo
		
				{
					echo "<network>" 
					echo "	<name>${NETWORKNAME}</name>"
		
	 				echo "	<forward mode='nat'>"
					echo "		<nat>"
					echo "			<port start='1024' end='65535'/>"
					echo "		</nat>"
					echo "	</forward>"
		
					# There's a 14 character limit for the virtual bridge name!
					#echo "	<bridge name='virbrocp' stp='on' delay='0'/>"
					echo "  <bridge name='yakko-${CLUSTERNAME:0:8}' stp='on' delay='0'/>"
		
					echo "	<domain name='${CLUSTERFQDN}' localOnly='yes'/>"
					echo "	<dns>"
					echo "		<forwarder domain='apps.${CLUSTERFQDN}' addr='127.0.0.1'/>"
					echo "		<host ip='${CLUSTERPROXY}'>"
					echo "			<hostname>api</hostname>"
					echo "			<hostname>api-int</hostname>"
					echo "		</host>"
					echo "		<host ip='${MASTER0IP}'>"
					echo " 	         	<hostname>etcd-0</hostname>"
					echo " 	         	<hostname>master-0</hostname>"
					echo "		</host>"
					if [ ${MASTERNODECOUNT} -eq 3 ]
					then
						echo "		<host ip='${MASTER1IP}'>"
						echo " 	         	<hostname>etcd-1</hostname>"
						echo " 	         	<hostname>master-1</hostname>"
						echo "		</host>"
						echo "		<host ip='${MASTER2IP}'>"
						echo " 	         	<hostname>etcd-2</hostname>"
						echo " 	         	<hostname>master-2</hostname>"
						echo "		</host>"
					fi
		
					# SRV Records are not required from OCP 4.4 onwards... But never mind
		
					echo " 	 	<srv service='etcd-server-ssl' protocol='tcp' domain='${CLUSTERFQDN}' target='etcd-0.${CLUSTERFQDN}' port='2380' priority='0' weight='10'/>"
					if [ ${MASTERNODECOUNT} -eq 3 ]
					then
						echo " 	 	<srv service='etcd-server-ssl' protocol='tcp' domain='${CLUSTERFQDN}' target='etcd-1.${CLUSTERFQDN}' port='2380' priority='0' weight='10'/>"
						echo " 	 	<srv service='etcd-server-ssl' protocol='tcp' domain='${CLUSTERFQDN}' target='etcd-2.${CLUSTERFQDN}' port='2380' priority='0' weight='10'/>"
					fi
					echo "	</dns>"
					echo "	<ip address='${CLUSTERPROXY}' netmask='255.255.255.0'>"
	   	 			echo "		<dhcp>"
					echo "			<range start='${BASENETWORK}.5' end='${BASENETWORK}.254'/>"
					echo "			<host mac='${BOOTSTRAPMAC}' name='bootstrap.${CLUSTERFQDN}' ip='${BOOTSTRAPIP}'/>"
					echo " 			<host mac='${MASTER0MAC}' name='master-0.${CLUSTERFQDN}' ip='${MASTER0IP}'/>"
					if [ ${MASTERNODECOUNT} -eq 3 ]
					then
						echo " 			<host mac='${MASTER1MAC}' name='master-1.${CLUSTERFQDN}' ip='${MASTER1IP}'/>"
						echo " 			<host mac='${MASTER2MAC}' name='master-2.${CLUSTERFQDN}' ip='${MASTER2IP}'/>"
					fi
					echo "		</dhcp>"
					echo "	</ip>"
					echo "</network>"
		
				} > $NETWORKXML
			fi

			if [ ${NETWORKTYPE} == 2 ] # BRIDGED
			then
				# All virtual machines will have LAN IP Addresses
				echo ONE DAY...
			fi
			
			echo Defining network at $NETWORKXML
			virsh net-define --file $NETWORKXML
			check-for-error-and-exit $? "Error defining virtual network at $NETWORKXML. Check 'virsh net-list --all'"
			
			echo Setting network to start on boot...
			virsh net-autostart ${NETWORKNAME}
			check-for-error-and-exit $? "Could not configure virtual network for auto-start"
		}
		echo "Re/starting network to ensure it is operational..."
		virsh net-destroy ${NETWORKNAME} 2>/dev/null

		# This blows up here sometimes
		systemctl restart libvirtd

		virsh net-start ${NETWORKNAME}
		check-for-error-and-exit $? "Could not start virtual network"
		echo "Virtual network is up"
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting virtual network configuration"
		virsh net-destroy ${NETWORKNAME} > /dev/null 2>&1
		virsh net-undefine ${NETWORKNAME} > /dev/null 2>&1

		# We didn't remove libvirtd but we will give it a kick as this has 
		# caused trouble before with the virtual network
		systemctl restart libvirtd

	}
}


process-stage-dns() {

	#stagedns

	[ $1 == "progress" ] && {
	
        	advance-stage-progression "DNS Configuration" && return

		ask-user "Configure DNS for KVM network (dnsmasq/NetworkManager)" "Y" && {

			# Courtesy of Sebastiaan Stoffels - installed from minimal F34 and found this helps
			install-package-if-missing bind-utils

			systemctl status dnsmasq >/dev/null 2>&1
			if [ $? -eq 0 ]
			then
				USEYAKKODNSMASQ=1
				echo "USEYAKKODNSMASQ=1" >> ${CLUSTERCONFIGFILE}
				# DNSMASQ is enabled on this host, we should use this instead of NetworkManager plugin
				# But, this is dangerous, so we have to leave this one to the ADMIN

				echo "YAKKO has detected that you are not using the dnsmasq plugin for NetworkManager"
				echo "and instead you are using standard DNSMASQ."
				echo
				echo "You will need to add these two addresses to your DNSMASQ configuration before continuing"
				echo "upon which ${YAKKONAME} will test the DNS of your system before continuing"
				echo
				# Version 1.2 changed the CLUSTERPROXY references below to YAKKOHOSTIP
				echo "  server=/${CLUSTERFQDN}/${CLUSTERPROXY}"
				echo "	address=/apps.${CLUSTERFQDN}/${YAKKOHOSTIP}"
				echo "	address=/api.${CLUSTERFQDN}/${YAKKOHOSTIP}"
				echo
				ask-user "Confirm that DNSMASQ has been configured and restarted" "Y" noauto
				echo
			else
				# First test
				NAMESERVICESHOST=$(host testing.apps.${CLUSTERFQDN} | grep "has address" | awk '{ print $4 }')
					
				if [ -n "${NAMESERVICESHOST}" -a "${NAMESERVICESHOST}" != ${YAKKOHOSTIP} ]
				then
					print-in-colour red "ALERT: Your network DNS service does not agree with the name you have given this host."
					print-in-colour red "       This host has IP address: ${YAKKOHOSTIP}"
					print-in-colour red "       The name lookup for the cluster FQDN has IP address: ${NAMESERVICESHOST}"
					sleep 5
					ALERTNETWORKDNS=1
					echo
				else
					ALERTNETWORKDNS=0
				fi
				echo "ALERTNETWORKDNS=${ALERTNETWORKDNS}" >> ${CLUSTERCONFIGFILE} # This in case the cluster fails to build and we pickup later

				USEYAKKODNSMASQ=0
				echo "USEYAKKODNSMASQ=0" >> ${CLUSTERCONFIGFILE}
				echo Configuring dnsmask plugin in NetworkManager and
				echo Adding DNSmasq configuration as ${SYSTEMSTUBFILE_DNSMASQ}
	
				# New for version 2.2+
				{
					echo "[main]"
					echo "dns = dnsmasq"
				} > ${SYSTEMSTUBFILE_NETWORKMANAGER}
				cp ${SYSTEMSTUBFILE_NETWORKMANAGER} ${STUBFILES}/NetworkManager.conf

                                # Version 1.2 changed the CLUSTERPROXY references below to YAKKOHOSTIP
				# And with 4.0 this creates the boot dnsmaqk file and...
                                {
                                       # Version 1.2 changed the use of CLUSTERPROXY below
                                       echo "cache-size=300"
				       #NOTE: This was causing conflict in YAKKO 4.0 beta
                                       echo "listen-address=127.0.0.1,${YAKKOHOSTIP}"
                                       echo "server=/${CLUSTERFQDN}/${CLUSTERPROXY}"
                                       echo "address=/apps.${CLUSTERFQDN}/${YAKKOHOSTIP}"
                                       echo "address=/api.${CLUSTERFQDN}/${YAKKOHOSTIP}"
                                } > ${SYSTEMSTUBFILE_DNSMASQ}
				# 4.0 also creates an editable version of the dnsmasq - in case you want to change the IP address!
                                {
                                       # Version 1.2 changed the use of CLUSTERPROXY below
                                       echo "cache-size=300"
				       #NOTE: This was causing conflict in YAKKO 4.0 beta
                                       echo "listen-address=127.0.0.1,STRINGYAKKOHOSTIP"
                                       echo "server=/${CLUSTERFQDN}/${CLUSTERPROXY}"
                                       echo "address=/apps.${CLUSTERFQDN}/STRINGYAKKOHOSTIP"
                                       echo "address=/api.${CLUSTERFQDN}/STRINGYAKKOHOSTIP"
                                } > ${STUBFILES}/dnsmasq.conf

				systemctl restart NetworkManager
				check-for-error-and-exit $? "Could not restart NetworkManager"

				# Trying to see if we can address the systemd-resolved changes in Fedora 33
				cat /etc/resolv.conf | grep "nameserver 127.0.0.53"
				if [ $? -eq 0 ]
				then	

					# New for version 2.2+
					echo
					echo "ATTENTION: This system is using systemd-resolved. YAKKO will use a stub file in /etc/systemd/resolved.conf.d/"
					mkdir -p /etc/systemd/resolved.conf.d
					check-for-error-and-exit $? "Could not create /etc/systemd/resolved.conf.d directory for stub file"

					# Version 4.0 - changed Domains=~${CLUSTERDOMAIN} to Domains=~${CLUSTERFQDN} 
					# As this host should not become the authority for the domain as a whole
					{
						echo "[Resolve]"
						echo "Domains=~${CLUSTERFQDN}"
						echo "DNS=127.0.0.1"
					} > ${STUBFILES}/resolved.conf
					cp ${STUBFILES}/resolved.conf ${SYSTEMSTUBFILE_RESOLVED} 

					sleep 1 # This sometimes takes a bit to revive
					systemctl restart systemd-resolved.service
					sleep 1

				fi
			fi

			sleep 2

			echo
			echo "DNS test - from Virtual Network ${BASENETWORK}.0:"

			host api-int.${CLUSTERFQDN} ${CLUSTERPROXY} | grep "has address"
			check-for-error-and-exit $? "Could not resolve api-int.${CLUSTERFQDN} on ${BASENETWORK}"

			host etcd-0.${CLUSTERFQDN} ${CLUSTERPROXY} | grep "has address"
			check-for-error-and-exit $? "Could not resolve etcd-0.${CLUSTERFQDN} on ${BASENETWORK}"

			if [ ${MASTERNODECOUNT} -eq 3 ]
			then
				host etcd-1.${CLUSTERFQDN} ${CLUSTERPROXY} | grep "has address"
				check-for-error-and-exit $? "Could not resolve etcd-1.${CLUSTERFQDN} on ${BASENETWORK}"

				host etcd-2.${CLUSTERFQDN} ${CLUSTERPROXY} | grep "has address"
				check-for-error-and-exit $? "Could not resolve etcd-2.${CLUSTERFQDN} on ${BASENETWORK}"
			fi

			host -t srv _etcd-server-ssl._tcp.${CLUSTERFQDN} ${CLUSTERPROXY}
			check-for-error-and-exit $? "Could not resolve etcd-server-ssl.${CLUSTERFQDN} on ${BASENETWORK}"
				
			echo
			echo "DNS test - from the host (Re/trying first test 5 times)"

			LOOPDNSSUCCESS=1
                        for LOOPTRY in 1 2 3 4 5
                        do
                                sleep 3
                                host api.${CLUSTERFQDN} 127.0.0.1 | grep "has address"
                                [ $? -eq 0 ] && {
					LOOPDNSSUCCESS=0
				       	break
				}
                        done

			if [ ${LOOPDNSSUCCESS} -eq 1 ]
			then
				echo "Failed DNS test to api.${CLUSTERFQDN} from host"
				echo "This is common - just press Y and let YAKKO automatically run to this point again"
				check-for-error-and-exit 1 "Could not resolve api.${CLUSTERFQDN} on 127.0.0.1"
			fi

			host etcd-0.${CLUSTERFQDN} 127.0.0.1 | grep "has address"
			check-for-error-and-exit $? "Could not resolve etcd-0.${CLUSTERFQDN} on 127.0.0.1"

			if [ ${MASTERNODECOUNT} -eq 3 ]
			then
				host etcd-1.${CLUSTERFQDN} 127.0.0.1 | grep "has address"
				check-for-error-and-exit $? "Could not resolve etcd-1.${CLUSTERFQDN} on 127.0.0.1"

				host etcd-2.${CLUSTERFQDN} 127.0.0.1 | grep "has address"
				check-for-error-and-exit $? "Could not resolve etcd-2.${CLUSTERFQDN} on 127.0.0.1"
			fi

			host testing.apps.${CLUSTERFQDN} 127.0.0.1 | grep "has address"
			check-for-error-and-exit $? "Could not resolve testing.apps on 127.0.0.1"

		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting DNS configuration and restarting"
		if [ -f "${SYSTEMSTUBFILE_RESOLVED}" ]
		then
			rm ${SYSTEMSTUBFILE_RESOLVED} > /dev/null 2>&1
			systemctl restart systemd-resolved # Fixed type system-resolved 10/01/22
		fi
		rm ${SYSTEMSTUBFILE_DNSMASQ} > /dev/null 2>&1
		rm ${SYSTEMSTUBFILE_NETWORKMANAGER} > /dev/null 2>&1
		systemctl restart NetworkManager
	}
}

	
process-stage-haproxy() {

	#stagehaproxy

	[ $1 == "progress" ] && {

        	advance-stage-progression "Configure Load Balancer "  && return

		ask-user "Configure Load Balancer (HA Proxy) for cluster bootstrap and operation" "Y" && {

			install-package-if-missing haproxy
	
			cat /etc/httpd/conf/httpd.conf | grep "^Listen 80" >/dev/null 2>&1
			[ $? -eq 0 ] && {
				echo "ATTENTION: HAPROXY needs to run on port 80. Currently, port 80 is marked for listening by httpd."
				ask-user "Disable port 80 on httpd" "Y" noauto
				if [ $? -eq 0 ]
				then		
					# CHANGE TO END USER SYSTEM HERE
					# THIS IS NOT DONE on STUBFILES as it is permanent
					sed -i "/^Listen 80/c\# Listen 80" /etc/httpd/conf/httpd.conf  2>/dev/null
				else
					echo
					echo "ERROR: Cannot continue until PORT 80 is freed up for HAPROXY. Fix and come back! Exiting..."
					echo
					cleanup-and-exit
				fi
			}
	
			# We defined SYSTEMSTUBFILE_HAPROXY during question time - it will reside in the directory below
			mkdir -p /etc/haproxy/conf.d

			#HAPROXY still wants to find a config file in the default place
			touch /etc/haproxy/haproxy.cfg

			#but, we can add others, and we do! As a directory, this will make haproxy load any configs in there...
			#this does not get blown away on cluster deletion. Tricky.
			echo "OPTIONS=\"-f /etc/haproxy/conf.d\"" > /etc/sysconfig/haproxy

			# VERSION 1.1 adds opening by default so here we go
			# This value came from QUESTIONS and is later stored in yakkodefaults
			if [ ${HAPROXYACCESS} -eq 0 ]	
			then
				# 0 is yes and yes is open, so no value!
				echo "Setting up HAproxy with OPEN access"
				HAPROXYVALUE=""
			else
				echo "Setting up HAproxy with HOST-ONLY access"
				HAPROXYVALUE=${CLUSTERPROXY}
			fi
			echo "You can change this later with 'yakko infra changeaccess'"

			echo Creating initial HAProxy config file
			echo
			
			{
				# SET UP THE PROXY ON THE VIRTUAL NETWORK - FOR THE HOST

				echo "defaults"
    				echo "timeout connect 5s"
    				echo "timeout client 1m"
    				echo "timeout server 1m"
				echo

				echo "listen ${CLUSTERNAME}-api-server-6443"
				echo "    bind ${HAPROXYVALUE}:6443"
				echo "    mode tcp"
				echo "    balance source"
				echo "    server master-0.${CLUSTERFQDN} ${MASTER0IP}:6443 check inter 1s"
				[ ${MASTERNODECOUNT} -eq 3 ] && {
					echo "    server master-1.${CLUSTERFQDN} ${MASTER1IP}:6443 check inter 1s"
					echo "    server master-2.${CLUSTERFQDN} ${MASTER2IP}:6443 check inter 1s"
				}
				echo "    server bootstrap.${CLUSTERFQDN} ${BOOTSTRAPIP}:6443 check inter 1s"

				echo 
				echo "listen ${CLUSTERNAME}-machine-config-server-22623"
				echo "    bind ${HAPROXYVALUE}:22623"
				echo "    mode tcp"
				echo "    balance source"
				echo "    server master-0.${CLUSTERFQDN} ${MASTER0IP}:22623 check inter 1s"
				[ ${MASTERNODECOUNT} -eq 3 ] && {
					echo "    server master-1.${CLUSTERFQDN} ${MASTER1IP}:22623 check inter 1s"
					echo "    server master-2.${CLUSTERFQDN} ${MASTER2IP}:22623 check inter 1s"
				}
				echo "    server bootstrap.${CLUSTERFQDN} ${BOOTSTRAPIP}:22623 check inter 1s"
				echo 

				echo "listen ${CLUSTERNAME}-ingress-router-80"
				echo "    bind ${HAPROXYVALUE}:80"
				echo "    mode tcp"
				echo "    balance source"
				echo "    server master-0.${CLUSTERFQDN} ${MASTER0IP}:80 check inter 1s"
				[ ${MASTERNODECOUNT} -eq 3 ] && {
					echo "    server master-1.${CLUSTERFQDN} ${MASTER1IP}:80 check inter 1s"
					echo "    server master-2.${CLUSTERFQDN} ${MASTER2IP}:80 check inter 1s"
				}
				echo "    # addingressrouternode80"

				echo 
				echo "listen ${CLUSTERNAME}-ingress-router-443"
				echo "    bind ${HAPROXYVALUE}:443"
				echo "    mode tcp"
				echo "    balance source"
				echo "    server master-0.${CLUSTERFQDN} ${MASTER0IP}:443 check inter 1s"
				[ ${MASTERNODECOUNT} -eq 3 ] && {
					echo "    server master-1.${CLUSTERFQDN} ${MASTER1IP}:443 check inter 1s"
					echo "    server master-2.${CLUSTERFQDN} ${MASTER2IP}:443 check inter 1s"
				}
				echo "    # addingressrouternode443"
			} > ${STUBFILES}/haproxy.cfg

			# Although the creation of HAProxy config file become dynamic with update-haproxy-config-file 
			# we still need a skeleton config to kickstart the cluster
			cp ${STUBFILES}/haproxy.cfg ${SYSTEMSTUBFILE_HAPROXY} 

			setsebool -P haproxy_connect_any 1
			systemctl --now enable haproxy
			check-for-error-and-exit $? "Could not restart haproxy/loadbalancer"
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting and stopping Load Balancer service"
		systemctl stop haproxy
		# We delete the individual haproxy config for the cluster at hand
		rm ${SYSTEMSTUBFILE_HAPROXY} 2>/dev/null
	}
}


process-stage-downloadocpbinaries() {

	#stagedownloadocp

	# Too bad. You are running multiple clusters? Download multiple times...


	[ $1 == "progress" ] && {

        	advance-stage-progression "Obtain OCP binaries (Installer and RHCOS)"  && return

		install-package-if-missing wget

		# This is the directory that the web server will run from
		[ ! -d $IMAGEREPO ] && mkdir -p $IMAGEREPO > /dev/null 2>&1
		cd $IMAGEREPO

		# We test whether we need to download the version. If there is no directory, we need to download.
		# If the directory is there but it doesnt contain a ".downloadcomplete" file, we need to download.

		if [ ! -d "$OCPGETCLIENTVERSION" -o ! -e "$OCPGETCLIENTVERSION"/.downloadcomplete ]
		then
			# Note that this script bundles your client and RHCOS dependencies under the client version number
			# we treat bad errors here differently to try to avoid repeating entire downloads

			mkdir $OCPGETCLIENTVERSION > /dev/null 2>&1
			cd $OCPGETCLIENTVERSION 
			echo "Getting the OCP installer (for version $OCPGETCLIENTVERSION) --> $PWD"

			# DOWNLOAD CLIENT STUFF FIRST (as of 4.6 it is common to all versions)
			wget $OCPDOWNLOADCLIENT/openshift-install-linux.tar.gz -O - | tar xz
			[ $? -ne 0 ] && { echo "Error downloading *openshift-installer*, exiting..."; cd ..; rm -rf ${OCPGETCLIENTVERSION}; cleanup-and-exit; } 

			echo "Getting the OCP client -> $PWD"
			wget $OCPDOWNLOADCLIENT/openshift-client-linux.tar.gz -O - | tar xz 
			[ $? -ne 0 ] && { echo "Error downloading *openshift-client*, exiting..."; cd ..; rm -rf ${OCPGETCLIENTVERSION}; cleanup-and-exit; } 
		
			echo "Getting RHCOS installer files... -> $PWD"

			if [ ${OCPINSTALLMINORVERSION} -ge 6 ]
			then
		
				##### KERNEL
				wget $OCPDOWNLOADIMAGE/rhcos-live-kernel-x86_64
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-initramfs*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; cleanup-and-exit; } 
			
				##### INITRAMFS
				wget $OCPDOWNLOADIMAGE/rhcos-live-initramfs.x86_64.img
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-initramfs*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; cleanup-and-exit; } 
		
				##### ROOTFS
				wget $OCPDOWNLOADIMAGE/rhcos-live-rootfs.x86_64.img
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-initramfs*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; cleanup-and-exit; } 
		
				##### METAL
				wget $OCPDOWNLOADIMAGE/rhcos-metal.x86_64.raw.gz
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-metal*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; cleanup-and-exit; } 
				
			else # Version 4.5 or earlier
		
				##### KERNEL
				wget $OCPDOWNLOADIMAGE/rhcos-installer-kernel-x86_64
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-kernel*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; cleanup-and-exit; } 
			
				### INITRAMFS
				wget $OCPDOWNLOADIMAGE/rhcos-installer-initramfs.x86_64.img
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-initramfs*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; cleanup-and-exit; } 
		
				##### METAL
				wget $OCPDOWNLOADIMAGE/rhcos-metal.x86_64.raw.gz
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-metal*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; cleanup-and-exit; } 
			fi

			# if we get this far it means that all the files were downloaded successfully
			# although cksum would be ideal. For now, leave a marker in the directory
			touch .downloadcomplete
		else
			echo "Using OCP Version $OCPGETCLIENTVERSION already downloaded..."
		fi
	
		cd ${YAKKOSETUPDIR}
	}

	[ $1 == "rollback" ] && {
		if [ -e "${IMAGEREPO}/${OCPGETCLIENTVERSION}/.downloadcomplete" ]
		then 
			rollback-stage-progression "Downloaded binaries will remain in place"
		else
			rollback-stage-progression "Deleting OCP files for version ${OCPGETCLIENTVERSION} (Download not completed)"
			# The below :? is JUST IN CASE everything went crazy. We don't want to delete /
			rm -rf ${IMAGEREPO:?}/${OCPGETCLIENTVERSION}
		fi
	}
}


process-stage-httpserver() {

	#stagehttp


	[ $1 == "progress" ] && {

        	advance-stage-progression "Configure HTTP server for installation of all cluster components"  && return

		ask-user "Configure and enable HTTP Server in virtual network for iPXE RHCOS VM installs on this host" "Y" && {

			# First, make sure that nothing is listening already on port ${WEBSERVERPORT}

			CANDIDATEPORT=${WEBSERVERPORT}

			install-package-if-missing lsof

			while true 
			do
				PORTAVAILABLE=N  # Checkpointer

				# Check of the port is in use, if so, LSOFPORSTATE == 0
				lsof -i -P -n | grep LISTEN | grep ":${CANDIDATEPORT} " >/dev/null  # list open files - lsof
				LSOFPORTSTATE=$?

				if [ $LSOFPORTSTATE -eq 1 ]
				then
					WEBSERVERPORT=$CANDIDATEPORT 
					PORTAVAILABLE=Y

					if [ ${SELINUXSTATE} -eq 0 ] 
					then
						semanage port -a -t http_port_t -p tcp ${WEBSERVERPORT} 2>/dev/null
					fi
				fi

				if [ $PORTAVAILABLE == "N" ]
				then
					echo
					echo "ERROR: Port ${CANDIDATEPORT} is not available for serving RHCOS images."
					echo "       If this is not something you can change, enter an alternative port"
					echo "       now, or press <CTRL-C> to address."
					echo
					echo -n "Enter alternative (4-digit) port for RHCOS image webserver: "
					read RESPONSE
					if [[ ${RESPONSE} =~ ^[0-9]+[0-9]+[0-9]+[0-9]+$ ]]  
					then
						echo "Testing port ${RESPONSE} for availability"
						CANDIDATEPORT=$RESPONSE
						sleep 1
					else
						echo "That's not a port number, try again!"
					fi
				else
					WEBSERVERURL=http://${WEBSERVERIP}:${WEBSERVERPORT}
					echo "WEBSERVERPORT=${WEBSERVERPORT}" >> ${YAKKODEFAULTS}
					echo "WEBSERVERURL=http://${WEBSERVERIP}:${WEBSERVERPORT}" >> ${YAKKODEFAULTS}
					break

				fi
			done 
			echo "Using port [${WEBSERVERPORT}] for RHCOS image delivery"

			# Now that we know what we are running up, we can set the directory to provide the sources
			# From the below dir, things will get cookin'
			OCPINSTALLSOURCE=$IMAGEREPO/$OCPINSTALLVERSION
			OCCOMMAND=${OCPINSTALLSOURCE}/oc
			echo "OCP will be made available by HTTP server from directory $OCPINSTALLSOURCE"
			echo
	
			install-package-if-missing httpd

			echo "<BR><BR><H1>The YAKKO web server is working!</H1>" > ${IMAGEREPO}/index.html # to have a test file there...
		
			{
				#echo "Listen ${WEBSERVERIP}:${WEBSERVERPORT}"
				echo "Listen ${WEBSERVERPORT}"
				#echo "<VirtualHost ${WEBSERVERIP}:${WEBSERVERPORT}>"
				echo "<VirtualHost *:${WEBSERVERPORT}>"
				echo "	DocumentRoot ${IMAGEREPO}"
	   	 		echo "	<Directory ${IMAGEREPO}>"
	   	    		echo "		Options Indexes FollowSymLinks"
	   	    		echo "		Require all granted"
	   	    		echo "		AllowOverride None"
	   	 		echo "	</Directory>"
				echo "</VirtualHost>"
		
			} > ${SYSTEMSTUBFILE_HTTPD}
			cp ${SYSTEMSTUBFILE_HTTPD} ${STUBFILES}/httpd.conf
		
			if [ ${SELINUXSTATE} -eq 0 ]
			then
				# Figure out which of these SELinux values are required
				# and needed to survive a reboot...

				chcon  --user system_u --type httpd_sys_content_t -Rv $IMAGEREPO
				check-for-error-and-exit $? "Failed to change security context (chcon) for $IMAGEREPO (filesystem type is $(stat -f -c %T $IMAGEREPO))"
				semanage fcontext -a -t httpd_sys_content_t "$IMAGEREPO(/.*)?"
				if [ $? -ne 0 ]
				then
					semanage fcontext -m -t httpd_sys_content_t "$IMAGEREPO(/.*)?"
					check-for-error-and-exit $? "Failed to change security context (semanage fcontext) for files in $IMAGEREPO"
				fi
				restorecon -Rv $IMAGEREPO
				check-for-error-and-exit $? "Failed to restore context (restorecon) for files in $IMAGEREPO"
			fi

			# We disable port 80 since we know it should not be served via httpd
			# Note that this is done directly on the system, not on the yakko httpd conf file in stubfiles
			sed -i "/^Listen 80/c\# Listen 80" /etc/httpd/conf/httpd.conf  2>/dev/null
	
			systemctl restart httpd
			check-for-error-and-exit $? "Could not start HTTPD server"
			systemctl enable httpd

			echo "OCPINSTALLSOURCE=$OCPINSTALLSOURCE" >> $CLUSTERCONFIGFILE
			echo "OCCOMMAND=${OCCOMMAND}" >> $CLUSTERCONFIGFILE
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Unconfiguring installation webserver - content will remain in place."
		rm ${SYSTEMSTUBFILE_HTTPD}  2>/dev/null
		rm $IMAGEREPO/index.html  2>/dev/null
		sed -i "/WEBSERVERPORT/d" ${YAKKODEFAULTS}
		systemctl restart httpd > /dev/null 2>&1
	}
}


process-stage-changefirewall() {

	#stagefirewall

	#If using a firewall on host, don't forget to allow connections to these ports on IP ${CLUSTERPROXY}: 6443, 22623, 80 and 443.

	[ $1 == "progress" ] && {

        	advance-stage-progression "Configure Firewall" && return

		firewall-cmd --state >/dev/null 2>&1
		if [ $? -eq 252 ]
		then
			echo "Firewall is not running. Configuration is not required."
		else
			install-package-if-missing firewalld # seen strange things in AWS...

			ask-user "Change Firewall rules" "Y" && { 

				echo "Changing firewall port for HTTP apps - 80/tcp access"
				firewall-cmd --add-port=80/tcp --permanent
				firewall-cmd --zone=libvirt --add-port=80/tcp --permanent

				echo "Changing firewall port for HTTP infra - ${WEBSERVERPORT}/tcp access"
				firewall-cmd --add-port=${WEBSERVERPORT}/tcp --permanent
				firewall-cmd --zone=libvirt --add-port=${WEBSERVERPORT}/tcp --permanent

				echo "Changing firewall port for HTTPS 443/tcp access"
				firewall-cmd --add-port=443/tcp --permanent
				firewall-cmd --zone=libvirt --add-port=443/tcp --permanent

				echo "Changing firewall port for COCKPIT - 9090/tcp access" 
				firewall-cmd --add-port=9090/tcp --permanent
				firewall-cmd --zone=libvirt --add-port=9090/tcp --permanent

				echo "Changing firewall port for OCP API - 6443/tcp access"
				firewall-cmd --add-port=6443/tcp --permanent
				firewall-cmd --zone=libvirt --add-port=6443/tcp --permanent

				echo "Changing firewall port for OCP comms - 22623/tcp access"
				firewall-cmd --add-port=22623/tcp --permanent
				firewall-cmd --zone=libvirt --add-port=22623/tcp --permanent

				echo "Changing firewall port for OCP comms - 22623/udp access"
				firewall-cmd --add-port=22623/udp --permanent
				firewall-cmd --zone=libvirt --add-port=22623/udp --permanent

				echo "Changing firewall port for DHCP"
				firewall-cmd --add-service=dhcp --permanent

				echo "Changing firewall port for DNS / external access"
				firewall-cmd --add-service=dns --permanent

				firewall-cmd --reload
		}
		fi	
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Firewall will remain unchanged - ports stay open"
	}
}


process-stage-generateocpinstallerconfig() {

	#stagegenerateocpinstaller

	[ $1 == "progress" ] && {

                advance-stage-progression "OCP Configuration for Installation"  && return

		ask-user "Generate OCP cluster manifests and ignition files required for cluster bootstrap" "Y" && {
	
			echo Writing "ocp-setup-env" script for administration. Run \"source ${YAKKOSETUPDIR}/ocp-setup-env\" to load post-install...
			{
				echo "PATH=\$PATH:${OCPINSTALLSOURCE}" 
				echo export KUBECONFIG=${CLUSTERSETUPDIR}/auth/kubeconfig
			}  > ocp-setup-env
			chmod +x ocp-setup-env

			# And we do this for the config file too, which is for the system
			{
				echo "PATH=\$PATH:${OCPINSTALLSOURCE}" 
				echo export KUBECONFIG=${CLUSTERSETUPDIR}/auth/kubeconfig
			}  >> ${CLUSTERCONFIGFILE}

			#And we set KUBECONFIG from here on too...
                        export KUBECONFIG=${CLUSTERSETUPDIR}/auth/kubeconfig
	
			# We load/reload, in case there was an interrupt to the AUTO setup and these values were released
			SSHPUBKEY=$(cat $OCPSSHKEY.pub)
			PULLSECRET=$(cat ${PULLSECRETFILE})

			# Check if HyperThreading is enabled, just in case
			SOCKETCOUNT=$(lscpu | grep "Socket(s):" | cut -f2 -d: | awk '{print $1}')
			CORECOUNTPS=$(lscpu | grep "Core(s) per socket:" | cut -f2 -d: | awk '{print $1}')
			CORECOUNT=$((${SOCKETCOUNT} * ${CORECOUNTPS}))
			THREADCOUNTPC=$(lscpu | grep "Thread(s) per core" | cut -f2 -d: | awk '{print $1}')
			THREADCOUNT=$((${THREADCOUNTPC} * ${CORECOUNT}))

			echo "The server has [$CORECOUNT] CPU cores and [$THREADCOUNT] threads"

			if [ ${CORECOUNT} -eq ${THREADCOUNT} ]
			then
				# No HT
				HYPERTHREADING=Disabled
			elif [ $((${CORECOUNT}*2)) -eq ${THREADCOUNT} ]
			then
				# HT is on
				HYPERTHREADING=Enabled
			else
				echo "CANNOT TELL IF HYPER-THREADING IS ENABLED, ASSUMING IT IS NOT"
				HYPERTHREADING=Disabled
			fi

			echo
			echo "Generating INSTALL CONFIG file..."
			
			{
				echo "apiVersion: v1"
				echo "baseDomain: ${CLUSTERDOMAIN}"
				echo "compute:"
				echo "- hyperthreading: ${HYPERTHREADING}"
				echo "  name: worker"
				echo "  replicas: 0"
				if [ ${OCPINSTALLMINORVERSION} -lt 10 ] # This is an OCP 4.10 thing, not sure use case
				then
					echo "  skipMachinePools: true"
				fi
				echo "controlPlane:"
				echo "  hyperthreading: ${HYPERTHREADING}"
				echo "  name: master"
				echo "  replicas: ${MASTERNODECOUNT}"
				echo "metadata:"
				echo "  name: ${CLUSTERNAME}"
				echo "networking:"
				echo "  clusterNetwork:"
				echo "  - cidr: 10.128.0.0/14 "
				echo "    hostPrefix: 23"
				echo "  networkType: OpenShiftSDN"
				echo "  serviceNetwork:"
				echo "  - 172.30.0.0/16"
				echo "platform:"
				echo "  none: {} "
				echo "fips: false "
				echo "pullSecret: '$PULLSECRET' "
				echo "sshKey: '$SSHPUBKEY'"
		
			} > ${CLUSTERSETUPDIR}/install-config.yaml
	
			# we make a copy for later review as this gets deleted by the create-manifests stage
			cp ${CLUSTERSETUPDIR}/install-config.yaml ${CLUSTERSETUPDIR}/install-config.yaml.original
			echo "Making a reference copy of install-config.yaml as install-config.yaml.original"
	
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting cluster ignition and configuration files"
		rm ocp-setup-env > /dev/null 2>&1
		rm ${CLUSTERSETUPDIR}/install-config.yaml  > /dev/null 2>&1
		rm ${CLUSTERSETUPDIR}/install-config.yaml.original  > /dev/null 2>&1
		rm $IMAGEREPO/*ign  > /dev/null 2>&1
	}
}


process-stage-ingestmanifestsandignition() {

	#stageingestmanifest

	[ $1 == "progress" ] && {

                advance-stage-progression "OCP Ingest manifest and ignition files"  && return

		if [ ${PAUSEFORCONFIGEDIT} -eq 0 ]
		then
			echo
			print-in-colour orange "ALERT: PAUSE REQUESTED AT THIS POINT TO ALLOW MANUAL EDITING OF install-config.yaml."
			print-in-colour orange "       File is located at:  ${CLUSTERSETUPDIR}/install-config.yaml"
			echo
			echo -n "<Press any key to continue from here when ready - or CTRL-C and re-issue 'yakko' later> "
			read RESPONSE
			echo
		fi
		
		ask-user "Ingest OCP cluster manifests and ignition files required for cluster bootstrap" "Y" && {

			echo Creating manifests...
			${OCPINSTALLSOURCE}/openshift-install create manifests --dir=${CLUSTERSETUPDIR} 
			check-for-error-and-exit $? "Could not create OCP manifests"

			if [ ${WORKERNODECOUNT} -gt 0 ]
			then
				# There are worker nodes to be built, so masters will become non-schedulable
				sed -i -r 's/(mastersSchedulable: ).*/\1False/' $CLUSTERSETUPDIR/manifests/cluster-scheduler-02-config.yml
			fi

			echo
			echo Creating OCP Cluster ignition files required for node configuration
			$OCPINSTALLSOURCE/openshift-install create ignition-configs --dir=$CLUSTERSETUPDIR
			check-for-error-and-exit $? "Could not create OCP ignition files"
			cp $CLUSTERSETUPDIR/*.ign $IMAGEREPO
			chmod 644 $IMAGEREPO/*.ign
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Manifest and ignition file ingest"
		cp ${CLUSTERSETUPDIR}/install-config.yaml  ${CLUSTERSETUPDIR}/install-config.yaml.edit 2>/dev/null
	}
}


process-stage-build-bootstrapnode() {

	#stagebootstrapnode

	[ $1 == "progress" ] && {

                advance-stage-progression "KVM Bootstrap Host Configuration" && return

		ask-user "Configure OCP bootstrap VM host" "Y" && {
			# Bootstrap node is MAC address is the first to be defined 
			build-ocp-node bootstrap ${BOOTSTRAPMAC} 2 6000 20 bootstrap.ign
			check-for-error-and-exit $? "Could not build VM for node [bootstrap]: virt-install error code [$?], check ~/.cache/virt-manager/virt-install.log"
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting bootstrap node"
		delete-kvm-machine bootstrap.${CLUSTERFQDN}
	}
}


process-stage-build-ocp-masternodes() {

	#stagebuildocpmasters

	[ $1 == "progress" ] && {

                advance-stage-progression "KVM Master Nodes Configuration"  && return

		ask-user "Configure OCP master VM hosts" "Y" && {

			build-ocp-node master-0 ${MASTER0MAC} ${MASTERVCPUS} ${MASTERRAMSIZE} ${MASTERDISKSIZE} master.ign
			check-for-error-and-exit $? "Could not build VM for node [master-0]"

			[ ${MASTERNODECOUNT} -eq 3 ] && {
				# It's either 1 or 3 nodes, never 2 AFAWK in 2020

				build-ocp-node master-1 ${MASTER1MAC} ${MASTERVCPUS} ${MASTERRAMSIZE} ${MASTERDISKSIZE} master.ign
				check-for-error-and-exit $? "Could not build VM for node [master-1]"

				build-ocp-node master-2 ${MASTER2MAC} ${MASTERVCPUS} ${MASTERRAMSIZE} ${MASTERDISKSIZE} master.ign
				check-for-error-and-exit $? "Could not build VM for node [master-2]"
			}
		}

	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting OCP master nodes"
		for MASTERNODE in $(virsh list --all --name | grep "master-" | grep ${CLUSTERFQDN})
                do
			delete-kvm-machine ${MASTERNODE}
                done
	}
}


process-stage-build-ocp-workernodes() {

	#stagebuildocpworkers

	[ $1 == "progress" ] && {

                advance-stage-progression "KVM Worker Node Configuration"  && return

		NODESTOBUILD=${WORKERNODECOUNT}

		if [ $NODESTOBUILD -eq 0 ]
		then
			echo "No Worker nodes were requested. Worker nodes can be added later by calling: "
			echo "- yakko infra addnode"
		else
			ask-user "Configure OCP worker VM node(s)" "Y" 
			if [ $? -eq 0 ]
			then
				while [ $NODESTOBUILD -ne 0 ]
				do
					((NODESTOBUILD--))
       	                		((NODECOUNT++))
       	                	 	sed -i "/NODECOUNT=.*/c\NODECOUNT=${NODECOUNT}" ${CLUSTERCONFIGFILE} 2>/dev/null
		
       			               	NEWNODENAME=node-${NODECOUNT}
					NEWNODELIST="${NEWNODELIST} ${NEWNODENAME}"
		
					build-ocp-node ${NEWNODENAME} auto ${WORKERVCPUS} ${WORKERRAMSIZE} ${WORKERDISKSIZE} worker.ign
					check-for-error-and-exit $? "Could not build VM for node [${NEWNODENAME}]"
				done
			fi
		fi

		# Now that the workers are built, we will have a working haproxy config file
		# Since the file will get updated by update-haproxy-config-file, let's make
		# a first release backup
		
		echo
	}     

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting OCP worker nodes"

		# Here's a tricky one since this function can be used during additional node build
		# or during a complete "deletecluster"
		# When it's the latter, we know that the DELETECLUSTERNAME must have the clustername set
		if [ "${DELETECLUSTERNAME}" == "${CLUSTERNAME}" ]
		then
			# Delete ALL worker nodes
			# All other cleanup is done as the cluster gets wiped
                	for NODETODELETE in $(virsh list --all --name | grep "node-" | grep ${CLUSTERFQDN})
                	do
				delete-kvm-machine ${NODETODELETE}
			done
		else
			# Delete nodes just added now with addnode
                	for NODETODELETE in ${NEWNODELIST} 
                	do
				echo "Rollback - deleting node [$NODETODELETE]"
				delete-kvm-machine ${NODETODELETE}
				sed -i "/${NODETODELETE}/d" /root/.ssh/known_hosts >/dev/null 2>&1

				# And just in case, we tell the cluster that the node is no longer
				${OCCOMMAND} delete node ${NODETODELETE}

				# Update the virtual network
				cat ${NETWORKXML} | grep ${NODETODELETE} > ${DHCPXMLTMPFILE} #It's way too hard to pass this as an argument below!
				if [ $? -eq 0 ]
				then
					restart-virtual-network delete ip-dhcp-host # this knows of ${DHCPXMLTMPFILE}
					sed -i "/${NODETODELETE}/d" ${NETWORKXML}
				fi

				#and we update the haproxy
				echo
				echo "Updating and restarting HAproxy"
				sed -i "/${NODETODELETE}/ d" ${SYSTEMSTUBFILE_HAPROXY} #> /dev/null 2>&1
				systemctl restart haproxy
				check-for-error-and-exit $? "Could not start HA Proxy, the cluster cannot function without this."
			done
		fi
	}
}


process-stage-startocpbootstrap() {

	#stagebootstrap

	[ $1 == "progress" ] && {

                advance-stage-progression "OCP Cluster Bootstrap"  && return

		ask-user "Start/continue OCP Cluster bootstrap" "Y" && {
	
			echo You can observe the output of the bootstrap node at this stage by issuing:
			echo ssh -i $OCPSSHKEY core@bootstrap.${CLUSTERFQDN} "sudo journalctl -b -f -u bootkube.service"
			echo 

			# Again. I've seen bootstrap node get stuck because it can't reach the network and
			# this jolt fixes it. RHEL 8.4 on laptop
			systemctl restart libvirtd
			sleep 2
	
			while true
			do
				$OCPINSTALLSOURCE/openshift-install --dir=$CLUSTERSETUPDIR wait-for bootstrap-complete
	
				if [ $? -eq 0 ]
				then
					#the wait-for bootstrap-complete was successful
					virsh list | grep bootstrap.${CLUSTERFQDN} > /dev/null 2>&1
					if [ $? -eq 0 ]
					then
						echo "Bootstrap VM will be deleted in 120 seconds..."
						(sleep ${BOOTSTRAPWAITTIME} && delete-kvm-machine bootstrap.${CLUSTERFQDN}) &

					fi
					break
				else
					echo
					echo "The bootstrap process doesn't appear to have completed successfully. "
					echo "This process downloads a lot of images from quay.io and can take a long time."
					echo
					echo    "Press <ENTER> to re-issue this stage (wait-for bootstrap-complete) and give it some more time, OR... "
					echo -n "Press <CTRL-C> to abort this install and examine then rerun install and return to this point"
					read CONTINUE
					$OCPINSTALLSOURCE/openshift-install --dir=$CLUSTERSETUPDIR wait-for bootstrap-complete
					echo
				fi
			done
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "OCP boostrap stage"
	}
}


process-stage-approvecsrs() {

	#stageapprovecsrs

	[ $1 == "progress" ] && {

                advance-stage-progression "CSR Background Approval"  && return

		ask-user "Approve pending/recurring CSRs" "Y" && {

			echo "CSR approval task will run in the background and will exit automatically on cluster completion."

			CSRAPPROVALPID=0
	
			if [ $CSRAPPROVALPID -eq 0 ]
			then

				approve-csrs-normal $((${MASTERNODECOUNT} + ${WORKERNODECOUNT}))
				CSRAPPROVALPID=$!
			fi
		
			# monitoring the output through the bootstrap requires not deleting it...
			trap 'kill -s SIGTERM $CSRAPPROVALPID ; sleep 2; cleanup-and-exit' SIGINT
		}
	}		

	[ $1 == "rollback" ] && {
		rollback-stage-progression "CSR approvals"
		kill -s SIGKILL $CSRAPPROVALPID > /dev/null 2>&1
	}
}


process-stage-reduceprometheusmemory() {

	#stagereducepromtheus

	[ $1 == "progress" ] && {

                advance-stage-progression "Prometheus Memory Footprint"  && return

		ask-user "Reduce Prometheus pod memory allocation" "${REDUCEPROMETHEUS}" && {

			PROMETHEUSPID=0

			if [ ${PROMETHEUSPID} -eq 0 ]
			then
				{ 
					echo "prometheusK8s:" 
					echo "  resources:" 
					echo "    requests:"
   		   			echo "      memory: 256Mi"
				} > $CLUSTERSETUPDIR/prometheus-config.yaml
		
				sleep 20 # Seen issues before...
				${OCCOMMAND} create configmap cluster-monitoring-config --from-file=config.yaml=${CLUSTERSETUPDIR}/prometheus-config.yaml -n openshift-monitoring
			
				{
					trap "echo; echo 'Prometheus pods not deleted for resizing (oc delete pod prometheus-k8s-* -n openshift-monitoring)'; cleanup-and-exit" SIGTERM
					sleep 30 #This is what the recipe suggested...
		
					PROMETHEUSTIMER=3600
					while true 
					do
						${OCCOMMAND} get pods -n openshift-monitoring 2>/dev/null | grep "prometheus-k8s" > /dev/null 2>&1
						[ $? -eq 0 ] && break

						sleep 15
						PROMETHEUSTIMER=$(($PROMETHEUSTIMER - 15))

						# Time to give up if I am still alive
						[ $PROMETHEUSTIMER -le 0 ] && exit
					done
		
					sleep 10
					${OCCOMMAND} delete pod prometheus-k8s-0 -n openshift-monitoring > /dev/null 2>&1
					${OCCOMMAND} delete pod prometheus-k8s-1 -n openshift-monitoring > /dev/null 2>&1
					echo "Reconfigured  Prometheus for memory footprint reduction"
		
				} &
				PROMETHEUSPID=$!
			fi
		
			# monitoring the output through the bootstrap requires not deleting it...
			trap 'kill -s SIGTERM $PROMETHEUSPID; sleep 2; echo "Shutting down prometheus memory reduction (NOT DONE), please wait..."; sleep 20; cleanup-and-exit' SIGINT
		
		}
	}	

	[ $1 == "rollback" ] && [ ${REDUCEPROMETHEUS} == "Y" ] && {
		rollback-stage-progression "Prometheus memory changes"
		kill -s SIGKILL $PROMETHEUSPID > /dev/null 2>&1
		rm $CLUSTERSETUPDIR/prometheus-config.yaml >/dev/null 2>&1
	}
}


process-stage-waitforocpinstalltocomplete() {

	#stagewaitforinstallertocomplete

	[ $1 == "progress" ] && {

                advance-stage-progression "OCP - Complete Installation"  && return

		ask-user "Wait for OCP install to complete" "Y" && {

			echo "---------------------------------------------------------------------------"
			echo "If you need to debug from within a master node, replace # by a master number:"
			echo "- ssh -i ~/.ssh/id_rsa_ocp.${CLUSTERNAME} -o \"StrictHostKeyChecking no\" core@master-0.${CLUSTERFQDN}"
			echo "- journalctl -b -f -u kubelet.service"
			echo "---------------------------------------------------------------------------"
			echo
			echo Some useful commands while waiting:
			echo "- tail -f $CLUSTERSETUPDIR/.openshift_install.log"
			echo "- source ocp-setup-env ---->  For access to \"oc\" at the command line"
			echo "- oc get clusteroperators ->  To check operator progression, can also be \"oc get co\""
			echo "- oc get clusterversion --->  On build, it shows you % progression, after that, cluster version" 
			echo "- oc get nodes ------------>  To see nodes and node status"
			echo 
			echo "---------------------------------------------------------------------------"
			echo "Output below tracks command: 'openshift-install --dir=$CLUSTERSETUPDIR wait-for install-complete'"
			echo "---------------------------------------------------------------------------"
			echo
		
			$OCPINSTALLSOURCE/openshift-install --dir=$CLUSTERSETUPDIR wait-for install-complete 
			OCPINSTALLCODE=$?
			
			# Stop background "assistants"
			kill -s SIGTERM $CSRAPPROVALPID $PROMETHEUSPID > /dev/null 2>&1
			sleep 15

			echo
			echo ${SEPARATIONLINE}
			echo
			print-in-colour ${YAKKOTEXTCOLOR}  FINISHED OCP INSTALLATION - $(date)
			print-time-elapsed

			if [ $OCPINSTALLCODE -ne 0 ]
			then
				echo 
				print-in-colour red "The OCP Installer exited with code [ $OCPINSTALLCODE ]"
				echo Cluster has $(${OCCOMMAND} get nodes | grep -Ec "worker|master") nodes and $(${OCCOMMAND} get co | awk '{ print $3 }' | grep -c True) operators up 
				echo
				print-in-colour red "You may want to start the installation again. YAKKO will not mark this cluster complete until the OCP installer exits cleanly."
				echo
		
			else

				# We write the first time we believe the cluster was up, for reference
				# It will also let's us know that there is no further building possible

				# This will print the date like 15-06-2021@10:45:46
				CLUSTERCOMPLETE="\"exitcode ${OCPINSTALLCODE} date $(date +"%d-%b-%Y@%T") hostdir ${YAKKOSETUPDIR} \"" 
				echo "CLUSTERCOMPLETE=$CLUSTERCOMPLETE" >> ${CLUSTERCONFIGFILE}
				echo "CLUSTERCONTEXT=$(${OCCOMMAND} whoami -c)" >> ${CLUSTERCONFIGFILE}

				compose-html-cluster-report

				echo
				print-in-colour ${YAKKOTEXTCOLOR} "IMPORTANT:"
				print-in-colour ${YAKKOTEXTCOLOR} " - you can bookmark cluster info at http://${YAKKOHOSTIP}:${WEBSERVERPORT}"
				print-in-colour ${YAKKOTEXTCOLOR} " - you DO NOT have a registry -> yakko ops localregistry"
				print-in-colour ${YAKKOTEXTCOLOR} " - you cannot access the cluster from another computer -> yakko infra openaccess"
				print-in-colour ${YAKKOTEXTCOLOR} " - you have no user DB-> yakko ops htpasswd administrator &  yakko ops useradd <user>"
				print-in-colour ${YAKKOTEXTCOLOR} ${SEPARATIONLINE}
				
				if [ "${ALERTNETWORKDNS}" -ne 0 ]
				then
					echo
					print-in-colour red "ALERT: Your network DNS service does not agree with the name you have given this host."
					print-in-colour red "       This host has IP address: ${YAKKOHOSTIP}"
					print-in-colour red "       The external name lookup for the cluster FQDN returns IP address: ${NAMESERVICESHOST}"
					print-in-colour ${YAKKOTEXTCOLOR} ${SEPARATIONLINE}
				fi
				echo
				echo

				# We build the 'last successful config' file for further auto
				if [ ! -e ${LASTBUILDCONFIG} -o -w ${LASTBUILDCONFIG} ]
				then
					{
						echo "CLUSTERNAME=${CLUSTERNAME}"
						echo "CLUSTERDOMAIN=${CLUSTERDOMAIN}"
						echo "CLUSTERFQDN=${CLUSTERFQDN}"
						echo "BASENETWORK=${BASENETWORK}"
						echo "OCPVMDISKDIR=${OCPVMDISKDIR}"
						echo "MASTERNODECOUNT=${MASTERNODECOUNT}"
						echo "WORKERNODECOUNT=${WORKERNODECOUNT}"
						echo "MASTERRAMSIZE=${MASTERRAMSIZE}"
						echo "WORKERRAMSIZE=${WORKERRAMSIZE}"
						echo "OCPGETCLIENTVERSION=${OCPGETCLIENTVERSION}"
	
					} > ${LASTBUILDCONFIG}
				fi

				# This is my tally, started on 24/11/2020 to keep count of build clusters
				if [ -r ${YAKKOSETUPDIR}/.tallyhosts ]
				then
					for TALLYHOST in $(cat ${YAKKOSETUPDIR}/.tallyhosts)
					do
						if [ "$(hostname)" == "${TALLYHOST}" ]
						then
							echo "Cluster [${CLUSTERNAME}] built on [$(date)] - Masters: ${MASTERNODECOUNT} Workers: ${WORKERNODECOUNT}" >> /YAKKO-TALLY-${TALLYHOST}
						fi
					done
				fi

				check-cluster-state 1
			fi
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "installation of OCP cluster ${CLUSTERNAME}"	
		if [ $DELETECLUSTERMODE -eq 1 ]
		then
			# We are only rolling back THIS stage
			echo "This is a WAIT stage - the cluster is still attempting build in the background."
			echo "Supporting operations already started will run until timing out."
			echo
			echo "Run  yakko  again to finish this stage when ready or follow prompts to delete cluster."
			echo
		fi
	}
}


process-stage-continue-clusterconfiguration() {

	#stagecontinueclusterconfiguration

	[ $1 == "progress" ] && {

        	advance-stage-progression "Continue Cluster Configuration"

		if [ -n "${CLUSTERCOMPLETE}" ]
		then	
			#if there was an install code registered in ${CLUSTERCONFIGFILE} file then the installer did all it could.
			check-cluster-state 1
			cleanup-and-exit
		fi

		echo
		ask-user "Attempt AUTOMATIC configuration of cluster from this point" "Y" noauto
		if [ $? -eq 0 ]
		then 
			AUTOSETUP=1
		else
			echo
			ask-user "MANUAL CONFIGURATION: Resume where you left off (\"y\") or Start from the begining (\"n\")" "Y" noauto
			if [ $? -ne 0 ]
			then
				YAKKOSTAGE=0
			fi
		fi
	}	

	# NOTE: THIS STAGE MUST PRECEDE yakko-process-stages
	# 	SEE MAIN AT BOTTOM

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Cluster configuration"
	}
}


process-stage-gatherclusterconfiguration() {

	#stagegatherclusterconfiguration #stagegatherconfig

	[ $1 == "progress" ] && {

        	advance-stage-progression "Gather Cluster Configuration information"

		# A cluster config does not exist - this should be the first run
		
		# Some of these are more "global" in nature so we store them in ${YAKKODEFAULTS}
		# (which was separate functionality in earlier versions)


		if [ "${YAKKOREBUILD}" -eq 1 ]
		then
			# If ${LASTBUILDCONFING} exists, we created a successful cluster before
			# This can only be called with 'yakko rebuildcluster' with no cluster configured
			# And for this to happen we get here with YAKKOREBUILD == 1

			echo "REBUILD requested, YAKKO will attempt repeating the last known successful cluster configuration:"
			echo
			cat .lastyakkobuild
			source ${LASTBUILDCONFIG}
		else
			# THIS SECTION IS ALL ABOUT QUESTIONS 
			#questions
		
			#This is so that we don't have to update if we add questions :)
			#We just count the number of calls to the function... Terrible? Cool... 
			#We filter "(" to avoid the func definition and the counter call below
			QUESTIONSTOTAL=$(cat ${YAKKOEXECUTABLE} | grep "print-question-separator" | grep -cv "(")
			QUESTIONNUM=1

			echo "This section will gather relevant information to build an OpenShift cluster on this host."
			echo "Default options are in [brackets], press enter to accept them."

			### QUESTION: domain name ## Stored in YAKKO defaults
			print-question-separator DOMAIN NAME
			echo -n "Enter the DOMAIN name to setup your cluster under [\"${CLUSTERDOMAIN}\"]: "
	       	 	read RESPONSE
			[ -n "$RESPONSE" ] && CLUSTERDOMAIN=$RESPONSE


			### QUESTION: Cluster name  ## Not stored in YAKKO defaults
			print-question-separator CLUSTER NAME
			while true
			do
				RESPONSE=""
				
				if [ -n "${CLUSTERNAME}" ]
				then
					echo -n "Enter the name of the OpenShift cluster to create [\"${CLUSTERNAME}\"]: "
				else
					echo -n "Enter the name of the OpenShift cluster to create: "
				fi
				read RESPONSE
	
				if [ -z "${RESPONSE}" ]
				then
					if [ -n "${CLUSTERNAME}" ]
					then
						RESPONSE=${CLUSTERNAME}
					else
						echo "Cluster name cannot be blank!"
						echo
						continue
					fi
				fi
		
				if [[ ! ${RESPONSE} =~ ^[a-z0-9]*$ ]]
				then
					echo "Invalid cluster name. Please use lower-case characters and numbers only."
					echo
					continue
				fi

				# Final check - is there another YAKKO cluster on this host?
				# virsh list --all | grep "master-0.${RESPONSE}.${CLUSTERDOMAIN}" >/dev/null 2>&1
				check-if-another-yakko-cluster-running

				#if [ $? -eq 0 ]
				#then
				#	echo "There is a cluster with that name already defined. You cannot reuse an existing cluster name."
				#	echo
				#	continue
				#else

					CLUSTERNAME=${RESPONSE}
					break

				#fi
			done
	

			### QUESTION: Host's IP address on the network  ## Not stored in YAKKO defaults
			# identifying 'this' host - this can be tricky as we are looking for the interface with the cable (hopefully!)
			# we cycle through the physical ports and compare them to those that are up until we nail one
			print-question-separator HOST IP ADDRESS

			echo "It is recommended that this host have a fixed IP address and a resolvable hostname."
			YAKKOHOSTIP=""
			get-yakko-host-ip 


	       		### QUESTION: basenetwork ## Stored in YAKKO defaults
			print-question-separator BASE VIRTUAL NETWORK

			# We calculate a base network that's unused by looking at how many virtual networks exist.
			# The user can change it or deal with it ;)
			# This also takes care of potential duplicates in mac addresses

			BASENETWORK=140
			while true
			do
				for DEFINEDBASENET in $(virsh -q net-list --all | awk '{print $1}')
		       		do 
					virsh net-dumpxml $DEFINEDBASENET | grep range | cut -f2 -d= | cut -f2 -d\'
				done  | grep 192.168.$BASENETWORK > /dev/null 2>&1
				if [ $? -eq 0 ]
				then
					BASENETWORK=$((BASENETWORK+1))
				else
					BASENETWORK=192.168.$BASENETWORK
					break
				fi
			done

	       		echo -n "Enter the SUBNET (/24) inside KVM that you want cluster under [\"${BASENETWORK}\"]: "
	       		read RESPONSE
	       		[ -n "$RESPONSE" ] && BASENETWORK=$(echo $RESPONSE | cut -f1-3 -d.)

			### QUESTION: Allow open access to the cluster upon creation  # This is recorded only in yakkodefaults
			print-question-separator OPEN ACCESS TO CLUSTER
			echo "YAKKO uses HAproxy to loadbalance access to OpenShift nodes, while also allowing"
			echo "or restricting access to either THIS host only, or clients in your local network." 
			echo "(You can change this later using 'yakko infra changeaccess')"
			ask-user "Allow 'open' cluster access from other clients (other than this server)" Y
			if [ $? -eq 0 ]
			then
				HAPROXYACCESS=0
			else
				HAPROXYACCESS=1
			fi

			### QUESTION: Cluster version
			print-question-separator OPENSHIFT VERSION
	
			# Now we get on with downloading the OCP binaries

			# NOTE: There can be discrepancies between the installer version (OCPGETCLIENTVERSION) and 
			# the RHCOS images version (OCPGETIMAGEVERSION)
			# We will download the lot under OCPGETCLIENTVERSION to keep a single point reference. This seems to make sense 
			# based on what the OCP mirror offers.
			# HOWEVER, outside of the DOWNLOAD section of the script, the version will be known as OCPINSTALLVERSION

			# regular releases are at:
			# INSTALLER: https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/latest
			# IMAGES: https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/latest/latest (with OCP 4.10 it seems to be just 'latest')

			# pre-release are at:
			# INSTALLER: https://mirror.openshift.com/pub/openshift-v4/clients/ocp-dev-preview/latest

			# Latest candidates:
			# INSTALLER: https://mirror.openshift.com/pub/openshift-v4/clients/ocp/candidate/

			# IMAGES: https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/pre-release/latest/
		
			# Get the OCP installer specifically for x86_64. One day this may be useful for IBM ... Power ;)
			OCPPLATFORM=x86_64
			OCPROOT=https://mirror.openshift.com/pub/openshift-v4/$OCPPLATFORM
		
			# This would get you the number for the latest version
			OCPDOWNLOADCLIENT="$OCPROOT/clients/ocp/latest"

			echo -n "Checking for latest OpenShift version - please wait...  "
			OCPDOWNLOADIMAGE="$OCPROOT/dependencies/rhcos/latest/latest" # OCP 4.10 change to layout?
			wget ${OCPDOWNLOADIMAGE} >/dev/null 2>&1
			if [ $? -ne 0 ]
			then
				# latest/latest seemed to be the mirror dir up until OCP 4.9

				# If the below fails, the release.txt get below will fail anyway
				OCPDOWNLOADIMAGE="$OCPROOT/dependencies/rhcos/latest" # OCP 4.10 change to layout?
			fi

			wget -O $OCPWGETTMP $OCPDOWNLOADCLIENT/release.txt > /dev/null 2>&1
			check-for-error-and-exit $? "Failed to download version file for latest OCP - check if https://mirror.openshift.com is reachable" 
			blank-line
				
		        OCPGETCLIENTVERSION=$(cat $OCPWGETTMP | grep Version: | awk '{ print $2 }')
			OCPINSTALLMINORVERSION=$(echo $OCPGETCLIENTVERSION | cut -f2 -d.)
			OCPIMAGESONFILE=$(ls -d images/[0-9]* 2>/dev/null | cut -f2 -d/)

			while true
			do
				echo "What release version do you want to install:"
				echo "    1) Latest release available ($OCPGETCLIENTVERSION)"
				echo "    2) Releases on disk"
				for AVAILIMAGE in $OCPIMAGESONFILE
				do
					echo "        - $AVAILIMAGE"
				done
				echo "    3) Older releases (hard! you will need to pick image version and installer version) "
				echo "    4) Latest release candidate (good luck!)"
				echo "    5) Latest pre-release nightly (unknown territory...)"
				echo -n "Pick option number from above (1-5) [1]: "
				read RESPONSE
	
				if [ "$RESPONSE" == "" -o "$RESPONSE" == 1 ]
				then
					RESPONSE=1
					break
				elif [ "$RESPONSE" == "2" ]
				then
					while true
					do
						echo -n "Select image version from above list of on-disk images (copy/paste from above): "
						read OCPGETCLIENTVERSION
						if [ -d images/${OCPGETCLIENTVERSION} ]
						then
							break
						else
							echo "Image [${OCPGETCLIENTVERSION}] is not a valid/existing image, choose another."
						fi
					done
					break
				elif [ "$RESPONSE" == "3" ]
				then
					# Query what client is desired
					while true
					do
						echo -n  'Enter OCP INSTALLER CLIENT version you require, e.g. "4.5.6" (may not work btw...): ' 
						read OCPGETCLIENTVERSION
						OCPDOWNLOADCLIENT="$OCPROOT/clients/ocp/$OCPGETCLIENTVERSION"
				
						wget -O $OCPWGETTMP $OCPDOWNLOADCLIENT/sha256sum.txt >/dev/null 2>&1
						if [ $? -ne 0 ]
						then
							echo "Invalid version $OCPGETCLIENTVERSION, no content available"
						else
							break
						fi
					done
		
					# Query what RHCOS is desired
					while true
					do
						echo "Please refer to https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/${OCPGETCLIENTVERSION:0:3})"
						echo -n  'Enter OCP RHCOS version you require, e.g. "4.5.6" (may also not work btw...): ' 
						 # this is harder because of how the mirror is laid out
						read OCPGETIMAGEVERSION
						VERSIONMAJOR=$(echo $OCPGETIMAGEVERSION | cut -f1 -d.)
						VERSIONMINOR=$(echo $OCPGETIMAGEVERSION | cut -f2 -d.)
						VERSIONMICRO=$(echo $OCPGETIMAGEVERSION | cut -f3 -d.)
						OCPDOWNLOADIMAGE="$OCPROOT/dependencies/rhcos/$VERSIONMAJOR.$VERSIONMINOR/$OCPGETIMAGEVERSION"
		
						wget -O $OCPWGETTMP $OCPDOWNLOADIMAGE/sha256sum.txt >/dev/null 2>&1
						if [ $? -ne 0 ]
						then
							echo "Invalid version $OCPGETIMAGEVERSION, no content available"
						else
							break 2  # We break out of 2 loops at once
						fi
					done
				elif [ "$RESPONSE" == "4" ]
				then
					# This is the preview of the upcoming release - typically a RC or release candidate
					OCPDOWNLOADCLIENT=https://mirror.openshift.com/pub/openshift-v4/clients/ocp/candidate/
					OCPDOWNLOADIMAGE=https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos/pre-release/latest
					wget -O $OCPWGETTMP $OCPDOWNLOADCLIENT/release.txt > /dev/null 2>&1
					check-for-error-and-exit $? "Failed to download version file for latest pre-buildOCP"
					#OCPGETCLIENTVERSION=$(curl -s ${OCPDOWNLOADIMAGE}/sha256sum.txt | awk '{print $2}' | grep live-kernel-x86_64 | grep fc | cut -f2,3 -d"-")
					check-for-error-and-exit $? "Failed to download version file for latest OCP" 

		        		OCPGETCLIENTVERSION=$(cat $OCPWGETTMP | grep Version: | awk '{ print $2 }')
					echo "OCP pre-release version [$OCPGETCLIENTVERSION] will be downloaded to ${YAKKOSETUPDIR}/images if required"
					break
				elif [ "$RESPONSE" == "5" ]
				then
					# This is the preview of the release after next - the latest is a nightly
					OCPDOWNLOADCLIENT=https://mirror.openshift.com/pub/openshift-v4/clients/ocp-dev-preview/latest
					OCPDOWNLOADIMAGE=https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos/pre-release/latest
					wget -O $OCPWGETTMP $OCPDOWNLOADCLIENT/release.txt > /dev/null 2>&1
					check-for-error-and-exit $? "Failed to download version file for latest pre-buildOCP"
					#OCPGETCLIENTVERSION=$(curl -s ${OCPDOWNLOADIMAGE}/sha256sum.txt | awk '{print $2}' | grep live-kernel-x86_64 | grep fc | cut -f2,3 -d"-")
					check-for-error-and-exit $? "Failed to download version file for latest OCP" 

		        		OCPGETCLIENTVERSION=$(cat $OCPWGETTMP | grep Version: | awk '{ print $2 }')
					echo "OCP nightly version [$OCPGETCLIENTVERSION] will be downloaded to ${YAKKOSETUPDIR}/images if required"

					break
				else
					echo
					echo "Invalid selection, try again!"
					echo
				fi

			done

			# We remove the CLIENT word to make it less confusing if someone reads the ${CLUSTERCONFIGFILE} file
			OCPINSTALLVERSION=$OCPGETCLIENTVERSION
			
			### QUESTION: Get repository for VMs ## Stored in YAKKO defaults
			print-question-separator VM STORAGE

			VMDIRSUCCESS=0
			CAPACITYALERT=0

			while true
			do
				while true
				do
					echo -n "Enter the directory where you wish to place the OCP VM disks for this cluster [\"${OCPVMDISKDIR}\"]: "
					read RESPONSE
					[ -z "$RESPONSE" ] && RESPONSE=${OCPVMDISKDIR} 
					break
		        	done

				OCPVMDISKDIR="$RESPONSE"
				mkdir -p "${OCPVMDISKDIR}" > /dev/null 2>&1
				ERROR=$?
				if [ $ERROR -ne 0 ]
				then
					echo "ERROR: Could not create/access directory [${OCPVMDISKDIR}] (mkdir error #$ERROR)"
					echo "       specify another directory or CTRL-C to inspect your system."
					echo
					continue
				else

					if [ ${SELINUXSTATE} -eq 0 ]
					then
						# The following was discovered by Wayne Boxall, adequate check
						# https://docs.fedoraproject.org/en-US/Fedora/13/html/Virtualization_Guide/sect-Virtualization-Security_for_virtualization-SELinux_and_virtualization.html

						semanage fcontext -a -t virt_image_t "${OCPVMDISKDIR}(/.*)?" >/dev/null 2>&1
						ERROR=$?
						if [ $ERROR -ne 0 -a $ERROR -ne 1 ]
						then
							echo "ERROR: Could not set virt_image_t context on directory [${OCPVMDISKDIR}] (fcontext error #$ERROR)"
							echo "       specify another directory or CTRL-C to inspect your system."
							echo
							continue
						fi

						restorecon -R -v "${OCPVMDISKDIR}" >/dev/null 2>&1
						ERROR=$?
						if [ $ERROR -ne 0 ]
						then
							echo "ERROR: Could not set virt_image_t restorecon context on directory [${OCPVMDISKDIR}] (restorecon error #$ERROR)"
							echo "       specify another directory or CTRL-C to inspect your system."
							echo
							continue
						fi
					fi
				fi

				echo "Changing permissions for [${OCPVMDISKDIR}] and all paths above (qemu:rw access)."

				cd "${OCPVMDISKDIR}"

				# we now add a r+x touch to the directory hierarchy where the VMs reside
				# This really should be in a separate process-stage now
				while true 
				do
					chmod o+rx . > /dev/null 2>&1
					ERROR=$?
					if [ $ERROR -ne 0 ]
					then
						echo "ERROR: Could not change access to directory [${PWD}] (chmod error #$ERROR)"
						echo "       specify another directory or CTRL-C to inspect your system."
						echo
						continue
					fi


					cd .. # This may not be elegant, but it works, we crawl the directory structure to the top
					if [ "$PWD" == "/" ]
					then
						VMDIRSUCCESS=1
						break
					fi
				done

				cd ${YAKKOSETUPDIR} # One day I'll clean this up....

				if [ ${VMDIRSUCCESS} -eq 1 ]
				then
					# All checks on the directory are complete
					break
				fi
			done
			
			# The next set of questions are intertwined, as they are measured against your system

			while true 
			do
				if [ ${OCPINSTALLMINORVERSION} -ge 8  ]
				then
					### QUESTION: Master node count 
					print-question-separator MASTER NODE COUNT
					while true
					do
						# The default comes from .yakkodefaults but is version dependent
						echo -n "How many MASTER nodes do you want to configure (1 or 3) [${MASTERNODECOUNT}]: "
		
						read RESPONSE
		
						if [ -z "${RESPONSE}" ]
						then 
							RESPONSE=${MASTERNODECOUNT}
							break
						else
							if [ $RESPONSE == 1 ]
							then
								MASTERNODECOUNT=1
								break
							elif [ $RESPONSE == 3 ]
							then
								MASTERNODECOUNT=3
								break
							else
								echo "Invalid master node count, choose 1 or 3."
							fi
						fi
					done

					echo ${OCPGETCLIENTVERSION} | grep 4.8 >/dev/null
					if [ $? -eq 0 ]
					then
						echo "NOTE: Single Master clusters are experimental with OpenShift 4.8"
						echo "      You will likely see some errors and yet see your cluster progress."
						echo "      If it does not progress after a while, you may want to restart."
					fi
				else	
					MASTERNODECOUNT=3
				fi

				### QUESTION: RAM size confirmation (MASTERS)  ##
				if [ ${MASTERNODECOUNT} -eq 1 ]
				then
					RECMASTERRAMSIZE=${SINGLEMASTERRAMSIZE}
				else
					RECMASTERRAMSIZE=${THREEMASTERRAMSIZE}
				fi

				print-question-separator MASTER NODE RAM
				while true
		                do
		                	echo -n "How much RAM (MiB) should be allocated to MASTER nodes [${RECMASTERRAMSIZE}]: "
					read VALUE
					if [ -n "$VALUE" ]
					then
						if ! [[ $VALUE =~ $NUMBERRE ]] ; then
							echo "Error: Not a number. Try again..."
							continue
						else
							if [ ${VALUE} -lt ${RECMASTERRAMSIZE} ]
							then 
								ask-user "You are requesting less RAM than recommended. Do you want to limit Prometheus RAM usage" Y
								[ $? -eq  0 ] && REDUCEPROMETHEUS=Y
							fi
							MASTERRAMSIZE=$VALUE
						fi
					else
						MASTERRAMSIZE=${RECMASTERRAMSIZE}
					fi
					break
				done

	
				### QUESTION: Add worker nodes at build ##
				print-question-separator WORKER NODE COUNT
				while true
		                do
					echo "Worker nodes can be built at cluster creation or later."
					echo "To build a cluster with ONLY schedulable MASTER node(s), type '0'"
					echo -n "How many worker nodes do you want to configure at cluster build time [2]: "
					read VALUE
					if [ -n "$VALUE" ]
					then
						if ! [[ $VALUE =~ $NUMBERRE ]] 
						then
							echo "Error: Not a number. Try again..."
							continue
						elif [ ${VALUE} -gt ${MAXWORKERNODES} ]
						then
							echo "You need to specify a number of workers up to [${MAXWORKERNODES}]"
							continue
						elif [ $VALUE -eq 0 ]
						then
							echo "No worker nodes were requested. You can add nodes later with YAKKO."
							break
						fi
						break
					else
						# Note that if $VALUE is 0 then we already have WORKERNODECOUNT properly set
						VALUE=2
						break
					fi
				done
				WORKERNODECOUNT=${VALUE}

	
				### QUESTION: RAM size confirmation (WORKERS)  ##
				if [ ${WORKERNODECOUNT} -gt 0 ]
				then 
					print-question-separator WORKER NODE RAM
				 	while true
		                 	do
		                 		echo -n "How much RAM (MiB) should be allocated to WORKER nodes [${WORKERRAMSIZE}]: "
				 		read VALUE
				 		if [ -n "$VALUE" ]
				 		then
				 			if ! [[ $VALUE =~ $NUMBERRE ]] ; then
				 				echo "Error: Not a number. Try again..."
				 				continue
				 			else
				 				WORKERRAMSIZE=$VALUE
				 			fi
				 		fi
				 		break
				 	done
				fi
	
				TOTMASTERSRAM=$(($MASTERNODECOUNT * $MASTERRAMSIZE)) # This is in MB
				TOTWORKERSRAM=$(($WORKERNODECOUNT * $WORKERRAMSIZE)) # This is in MB
				TOTCLUSTERRAM=$(($TOTMASTERSRAM + $TOTWORKERSRAM))
	
				TOTMASTERSDISK=$(($MASTERNODECOUNT * $MASTERDISKSIZE)) # This is in GB
				TOTWORKERSDISK=$(($WORKERNODECOUNT * $WORKERDISKSIZE)) # This is in GB
				TOTCLUSTERDISK=$(($TOTMASTERSDISK + $TOTWORKERSDISK))
	
				# We won't use PHYSICAL system RAM here as a warning mark
				SYSTEMAVAILRAM=$(free -m | grep Mem:| awk '{ print $7 }')

				# QUESTION - not really but we confirm
				print-question-separator TOTAL CAPACITY REQUIREMENTS
				echo "Requested OpenShift configuration requires:"
			        echo "- RAM:  ${TOTCLUSTERRAM} MiB "
				echo "- DISK: ${TOTCLUSTERDISK} GiB "

				if [ ${SYSTEMAVAILRAM} -lt ${TOTCLUSTERRAM} ]
				then
					CAPACITYALERT=1
					echo
					print-in-colour orange "Not enough free RAM available for your desired configuration:"
					print-in-colour orange "Total requirement is ${TOTCLUSTERRAM} MiB but system only has ${SYSTEMAVAILRAM} MiB free"
					echo 
				fi
	
				TOTSYSTEMDISK=$(df -BGiB ${OCPVMDISKDIR} | grep -v "^Filesystem" | awk '{print $4}' | cut -f1 -dG) 
				if [ ${TOTSYSTEMDISK} -lt ${TOTCLUSTERDISK} ]
				then
					CAPACITYALERT=1
					print-in-colour orange "Not enough disk space available for you desired configuration:"
					print-in-colour orange "Total requirement is [${TOTCLUSTERDISK}] but ${OCPVMDISKDIR} only has [${TOTSYSTEMDISK}]"
				fi
				
				if [ ${CAPACITYALERT} -eq 0 ]
				then
					ask-user "Accept this configuration for cluster build" Y
				else
					ask-user "Accept the above configuration anyway" Y
				fi

				if [ $? -eq 0 ]
				then
					break
				else
					CAPACITYALERT=0
					continue
				fi
				

			done
		fi

		# We write a bunch of stuff for later retrieval in $YAKKODEFAULTS
		CLUSTERSETUPDIR=${YAKKOSETUPDIR}/install-${CLUSTERNAME}
		STUBFILES=${CLUSTERSETUPDIR}/stubfiles
		mkdir $CLUSTERSETUPDIR > /dev/null 2>&1
		mkdir ${STUBFILES} > /dev/null 2>&1

		NETWORKNAME=net-${YAKKONAME}-${CLUSTERNAME}
		NETWORKXML=$CLUSTERSETUPDIR/${NETWORKNAME}.xml
		CLUSTERFQDN=${CLUSTERNAME}.${CLUSTERDOMAIN}
		CLUSTERWEBURL="https://console-openshift-console.apps.${CLUSTERFQDN}"
		CLUSTERAPIURL="https://api.${CLUSTERFQDN}:6443"
		CLUSTERPROXY="${BASENETWORK}.${PROXYADDRESS}"
                WEBSERVERIP=${CLUSTERPROXY}
		OCPSSHKEY=~/.ssh/id_rsa_ocp.${CLUSTERNAME}

		# These are files that will be placed in the right place on cluster boot, SYSTEMSTUBFILE_*
		SYSTEMSTUBFILE_DNSMASQ=/etc/NetworkManager/dnsmasq.d/yakko-${CLUSTERNAME}-dnsmasq.conf
		SYSTEMSTUBFILE_HAPROXY=/etc/haproxy/conf.d/yakko-${CLUSTERNAME}-haproxy.cfg
		SYSTEMSTUBFILE_NETWORKMANAGER=/etc/NetworkManager/conf.d/yakko-${CLUSTERNAME}-NetworkManager.conf
		SYSTEMSTUBFILE_HTTPD=/etc/httpd/conf.d/yakko-${CLUSTERNAME}-httpd.conf
		SYSTEMSTUBFILE_RESOLVED="/etc/systemd/resolved.conf.d/yakko-${CLUSTERNAME}-resolved.conf"

		# We calculate the BASEMACADDRESS last digit here...
		# This in case there is more than one cluster defined... Maybe...
		BASEMACADDRESS=${COREMACADDRESS}:$(echo ${BASENETWORK} | cut -f3 -d. | xargs printf '%x')

		# Is SELinux running?
		set-selinux-state

		populate-clusterconfigfile
		populate-yakkodefaults

		# Last question - Run auto setup?
 
		if [ ${YAKKOREBUILD} == 1 ]
		then
			AUTOSETUP=1
		else
			# V1.1 
			### QUESTION: Allow a PAUSE to edit install-config.yaml
			print-question-separator PAUSE FOR install-config.yaml EDIT
			echo "Although YAKKO automates OpenShift cluster creation, you may want to customise the "
			echo "'install-config.yaml' configuration file before cluster bootstrap, for example,"
		        echo "when wanting to add a proxy server for indirect connection to the internet."	
			ask-user "Pause for edit of 'install-config.yaml' when file becomes available" N noauto
			PAUSEFORCONFIGEDIT=$?  #0 is Y, so pause in process-stage-generateocpinstallerconfig

			print-question-separator AUTOMATIC CLUSTER BUILD
			ask-user "Attempt AUTOMATIC creation of cluster \"${CLUSTERNAME}\"" "Y" noauto  && AUTOSETUP=1

		fi

	}
	# NOTE: THIS STAGE MUST PRECEDE yakko-process-stages
	# 	SEE MAIN AT BOTTOM

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Cluster configuration gather"
		rm ${CLUSTERCONFIGFILE} > /dev/null 2>&1
		rm -rf $CLUSTERSETUPDIR > /dev/null 2>&1
	}
}


yakko-process-stages() {

	ACTION=$1 # progress or rollback

	if [ "${ACTION}" == "rollback" -a ${DELETECLUSTERFORCE} -eq 1 ]
	then
		# This questioning is bypassed if DELETECLUSTERFORCE is 0
		echo
		ask-user "*** CONFIRM *** - Deleting cluster [${CLUSTERNAME}]" "N" noauto
		[ $? -ne 0 ] && { echo; echo "ATTENTION: No action taken. Exiting."; cleanup-and-exit; }
		
		# User wants the cluster gone!
		AUTOSETUP=0
		DELETECLUSTERMODE=0 # We are destroying everything
	fi
	
	process-stage-pullsecret ${ACTION}
	process-stage-downloadocpbinaries ${ACTION}
	process-stage-libvirt ${ACTION}
	process-stage-sshclient ${ACTION}
	process-stage-virtualnetwork ${ACTION}
	process-stage-dns ${ACTION}
	process-stage-httpserver ${ACTION}
	process-stage-haproxy ${ACTION}
	process-stage-changefirewall ${ACTION}
	process-stage-generateocpinstallerconfig ${ACTION}
	process-stage-ingestmanifestsandignition ${ACTION}
	process-stage-build-bootstrapnode ${ACTION}
	process-stage-build-ocp-masternodes ${ACTION}
	process-stage-build-ocp-workernodes ${ACTION}
	process-stage-startocpbootstrap ${ACTION}
	process-stage-approvecsrs ${ACTION}
	process-stage-reduceprometheusmemory ${ACTION}
	process-stage-waitforocpinstalltocomplete ${ACTION}

	if [ "${ACTION}" == "rollback" ]
	then
		#This last one actually deletes the clusterconfig file
		#And when this happens, yakko no longer believes that a cluster exists
		#So this must be done AFTER all stages are cleared
		process-stage-gatherclusterconfiguration rollback
		echo
		echo "Cluster [${CLUSTERNAME}] and all associated configuration have been deleted."
		echo
		check-if-yakko-running # This guy will delete any background yakkos if DELETECLUSTERMODE == 0
		cleanup-and-exit
	fi
}
						

######################################################################################################
##########  If this were a different programming language, you would call this a "main()".... ########
######################################################################################################

YAKKODIRECTORY=$(dirname $(realpath $0))
YAKKOEXECUTABLE=$(realpath $0)

set-selinux-state  # Identify this from the get go

if [ "$1" == "version" ]
then
	echo
	echo "YAKKO version::${YAKKOVERSION} (${YAKKODATE})"
	echo
	echo "Copyright (C) 2020 - Daniel Cifuentes"
    	echo "This is free software and comes with ABSOLUTELY NO WARRANTY."
	echo "You are welcome to redistribute it under certain conditions." 
	echo "Feel free to post comments via GitHub - https://github.com/ozchamo/YAKKO"
	echo

	cleanup-and-exit
fi

if [ $(whoami) != 'root' ]
then 
	echo "ATTENTION: You must be user <root> to run ${YAKKONAME}"
	echo
	cleanup-and-exit
fi

if [ "$1" == "backup" ]
then
	# This is action 0, the developer wants to make a backup
	# There will be no cluster built, nothing
	yakko-backup $*
fi

print-yakko-header

if [ "$1" == "usage" ]
then
	#usage
	echo
	print-in-colour blue  "When NO CLUSTER is configured you can call: "
	echo "    yakko  (no params)    -> build a new cluster"
	echo "    yakko rebuildcluster  -> recreate the last cluster built"
	echo
	print-in-colour blue  "When a CLUSTER IS CONFIGURED you can call:"
	echo "    yakko  (no params)    -> show running cluster state and configuration"
	echo "    yakko startcluster    -> startup or resume the cluster (same as yakko infra startcluster)"
	echo "    yakko stopcluster     -> shutdown or suspend (in-memory) the cluster"
	echo "    yakko deletecluster   -> delete the running or stopped cluster (same as yakko infra deletecluster)"
	echo "    yakko infra <options> -> make infrastructure changes offered by yakko (see below)" 
	echo "    yakko ops <options>   -> make operational changes offered by yakko (see below)"
	echo
	print-in-colour blue  "At any time, you can call:"
	echo "    yakko addcluster      -> add a new cluster (this will setup YAKKO in a new directory)"
	echo "    yakko purgedownloads  -> delete downloaded OCP images"
	echo 
	print-in-colour blue  "Calling 'yakko infra' (with no option) will always remind you of the following:"
	print-yakko-infra-operations-menu
	print-in-colour blue  "Calling 'yakko ops' (with no optiona) will always remind you of the following:"
	print-yakko-ops-operations-menu
	echo "Finally, you can call 'yakko version' at any time for... well, version!"
	echo
	cleanup-and-exit
	echo
fi


if [ ! -e "${YAKKODIRECTORY}/.yakkohome" ]
then
	while true
	do

		# This is not even installed!

		echo
		echo "YAKKO is not installed in [${YAKKODIRECTORY}]."
		echo
		echo -n "Enter the directory where you want to install ${YAKKONAME} [/YAKKO]: "
		read RESPONSE

		if [ -z "${RESPONSE}" ]
		then
			RESPONSE=/YAKKO
		fi

		mkdir ${RESPONSE} > /dev/null 2>&1
		RESULT=$?

		[ $RESULT -ne 0 ] && {

			if [ $RESULT -eq 1 ] 
			then
				# The directory already exists
				if [ $(ls -la ${RESPONSE} | wc -l) -gt 3  ] 
				then
					# And - it has files in it.
					echo
					echo  "Directory [$RESPONSE] already exists and contains files. "
					ask-user "Continue installing ${YAKKONAME} in this directory" "N" noauto
					if [ $? -eq 1 ] 
					then
						continue
					else
						break
					fi
				else
					# It's empty so we can continue
					break
				fi
			fi

			echo "Could not create directory [${RESPONSE}]. Try again."
			echo
			continue
		}

		break
	done

	if [ -e "${RESPONSE}/${YAKKONAME}" ]
	then
		if [ $(ls -i "${RESPONSE}/${YAKKONAME}" | awk '{ print $1 }') -eq $(ls -i ${YAKKOEXECUTABLE} | awk '{ print $1 }') ]
		then
			# We're probably just running yakko from what will be the destination directory
			echo "You are running YAKKO from the destination directory - that's OK"
		fi
	else
		cp ${YAKKOEXECUTABLE} ${RESPONSE}
		check-for-error-and-exit $? "Could not copy ${YAKKONAME} to ${RESPONSE}"
	fi
	chmod +x ${RESPONSE}/${YAKKONAME}
	check-for-error-and-exit $? "Could not make ${RESPONSE}/${YAKKONAME} executable"
	touch ${RESPONSE}/.yakkohome
	check-for-error-and-exit $? "Could not create installer stub in ${RESPONSE}"

	echo
	echo "${YAKKONAME} is now installed. Run again from directory [${RESPONSE}] to continue!"
	echo
	cleanup-and-exit
fi

# We define a set of key config variables and files now that we know where we are running from
YAKKOSETUPDIR=${YAKKODIRECTORY}
IMAGEREPO=${YAKKOSETUPDIR}/images # The webserver will serve from here. oc and openshift-install are here already
CLUSTERCONFIGFILE=${YAKKOSETUPDIR}/.clusterconfig # Filename where all defaults for the cluster you are building are kept
PULLSECRETFILE=${YAKKOSETUPDIR}/.pullsecret
LASTBUILDCONFIG=${YAKKOSETUPDIR}/.lastyakkobuild
YAKKODEFAULTS=${YAKKOSETUPDIR}/.yakkodefaults # Filename where all defaults for YAKKO are kept


# Now that we know where we stand, we can offer a new YAKKO landing place for a second, third etc cluster
cd ${YAKKOSETUPDIR} >/dev/null 2>&1 # Just change to the directory of action from hereon
if [ "$1" == addcluster ]
then
	# New with ~2.5?
	echo "To add a new cluster, you will need to run YAKKO from a new directory altogether."
	echo -n  "Enter a new directory to create and install YAKKO in: "
	read NEWYAKKODIRECTORY

	mkdir ${NEWYAKKODIRECTORY} 2>/dev/null
	check-for-error-and-exit $? "Could not create new directory - try again"

	cp yakko ${NEWYAKKODIRECTORY}
	touch ${NEWYAKKODIRECTORY}/.yakkohome # this marks it as 'installed'
	chmod 544 ${NEWYAKKODIRECTORY}/yakko
	cp .pullsecret ${NEWYAKKODIRECTORY}

	echo
	echo "NOTES:"
        echo "  - YAKKO cannot run both clusters at the same time as HAProxy allows only one cluster "
	echo "    through the same ports (80,443,6443,22623)"
	echo "  - To ensure separation, always use a different terminal when interacting with different"
	echo "    clusters - else you may find that your KUBECONFIG variable will cause problems."
	echo "  - Each YAKKO directory keeps its own images, so be sure to purge accordingly"
	echo
	echo "Done - change directory to [${NEWYAKKODIRECTORY}] to start installing your new cluster!"
	echo
	cleanup-and-exit
fi


# We load YAKKO defaults whether they exist... or not.
source ${YAKKODEFAULTS} > /dev/null 2>&1

# HERE IT ALL BEGINS
# This is the last code group - a cluster config file exists or it doesn't

# if the user passed a parameter, let's capture it here... it could be "infra" or "ops"
YAKKOCALLOPTION=$1

# V2.2 - purgedownloads gets a free pass
if [[ ( "${YAKKOCALLOPTION}" == infra && "$2" == purgedownloads ) || "${YAKKOCALLOPTION}" == purgedownloads ]]
then
	yakko-infra-operations purgedownloads
fi
	
if [ ! -r ${CLUSTERCONFIGFILE} ]
then

	# We check if the user is already messing with another cluster
	if [ -v KUBECONFIG ]
	then
		echo "There is no cluster configured but KUBECONFIG is already set." 
		echo "To run up a new cluster, first 'unset KUBECONFIG'"
		echo
		cleanup-and-exit
	fi

	# Make sure you don't launch it twice
	check-if-yakko-running

	# We check if there are any other clusters running?
	check-if-another-yakko-cluster-running

	if [ -n "${YAKKOCALLOPTION}" ] 
	then
		# There is no cluster, the only $1 option is to rebuild
		if [ "${YAKKOCALLOPTION}" == "rebuildcluster" ] 
		then
			if [ -f "${LASTBUILDCONFIG}" ]
			then
				YAKKOREBUILD=1
			else
				echo
				echo "You can't rebuild a prior cluster config since there is no known configuration stored"
				echo
				cleanup-and-exit
			fi
		else
			echo
			echo "No cluster is configured. To begin, just run \"${YAKKONAME}\"." 
			echo
			cleanup-and-exit
		fi

	fi

	THISPLATFORM="$(cat /etc/os-release | grep '^ID=' | cut -f2 -d= | tr -d "\"") $(cat /etc/os-release | grep '^VERSION_ID=' | cut -f2 -d= | tr -d "\"")"

	echo "${TESTEDPLATFORMS}" | grep "${THISPLATFORM}" > /dev/null 2>&1
	if [ $? -ne 0 ]
	then
		echo "NOTE: This system is using [${THISPLATFORM}], which has not been tested."
		echo "      This version of YAKKO has only been tested against ${TESTEDPLATFORMS}"
	fi

	process-stage-gatherclusterconfiguration progress
	yakko-process-stages progress

else
	# We know we are root, but are we logged in as the administrator into the OpenShift cluster
	if [ -z "${KUBECONFIG}" ]
	then
		NOTSETKUBECONFIG=0
	fi

	source ${CLUSTERCONFIGFILE} # Load config variables that this script accumulates

	# Emergency checks after loading CLUSTERCONFIGFILE
	# To curb strange behaviours seen before
	if [ -z "${CLUSTERNAME}" ]
	then
		echo "ERROR: Reading cluster configuration file, CLUSTERNAME is empty!"
		if [ -z "${CLUSTERCOMPLETE}" ]
		then
			echo "       Since there is no cluster, you should start this build from scratch."
		fi
		echo "       Exiting."
		exit	
	fi

	# Check the cluster yakko version vs the script yakko version
	# Check if we have notified this already...

	echo ${NOTICEYAKKOVERSION} | grep ${YAKKOVERSION} >/dev/null 2>&1
	if [ $? -ne 0 ] # We haven't notified that this version is different to the build
	then
		if [ "$BUILTWITHYAKKOVERSION" != "$YAKKOVERSION" ]
		then
			echo
			print-in-colour red "ALERT: This cluster was built using YAKKO version $BUILTWITHYAKKOVERSION."
			print-in-colour red "       You are using a different YAKKO version - $YAKKOVERSION."
			echo                "       This message will not be repeated for this version"
			echo
			echo "VISIT: https://github.com/ozchamo/YAKKO"
			echo
			echo 
			print-in-colour ${YAKKOTEXTCOLOR}  "<Press any key to continue>"
			read CONTINUE
			NOTICEYAKKOVERSION="\"${NOTICEYAKKOVERSION} ${YAKKOVERSION}\""
			sed -i "s/NOTICEYAKKOVERSION=.*/NOTICEYAKKOVERSION=${NOTICEYAKKOVERSION}/" ${CLUSTERCONFIGFILE}
			echo
		fi
	fi

	# OK - the user wants to complete back out
	if [ "${YAKKOCALLOPTION}" == infra -a "$2" == deletecluster ]
	then
		yakko-infra-operations deletecluster $3
	fi

	if [ "${YAKKOCALLOPTION}" == deletecluster  ]
	then
		yakko-infra-operations deletecluster $2
	fi

	# We check if there are any other clusters running?
	check-if-another-yakko-cluster-running

	# $CLUSTERCOMPLETE is defined if THERE IS a cluster configured
	if [ -n "${CLUSTERCOMPLETE}" ] 
	then
		if [ $# -eq 0 ] # parameters go here when there is a cluster - see above and (backup: for developers)
		then
			check-cluster-power exit

			get-yakko-host-ip notifychange && {
			       	update-services restart
				sleep 30
				print-yakko-header # This to refresh the above update-services call
			}

			check-cluster-state  # yakko is called on an existing cluster - check it!
		fi

		if [[ ( "${YAKKOCALLOPTION}" == infra &&  "$2" == startcluster ) || "${YAKKOCALLOPTION}" == startcluster ]]
		then	
			[ "${YAKKOCALLOPTION}" == infra ] && shift
			shift
			yakko-infra-operations startcluster $*
		fi

		if [[ ( "${YAKKOCALLOPTION}" == infra &&  "$2" == stopcluster ) || "${YAKKOCALLOPTION}" == stopcluster ]]
		then	
			[ "${YAKKOCALLOPTION}" == infra ] && shift
			shift
			yakko-infra-operations stopcluster $*
		fi

		if [ "$YAKKOCALLOPTION" == "infra" ]
		then
			shift # we get rid of "infra"
			yakko-infra-operations $* # always exits
		fi

		if [ "$YAKKOCALLOPTION" == "ops" ]
		then
			shift # we get rid of "ops"
			yakko-ops-operations $* # always exits
		fi

		echo "ERROR: Invalid argument passed [$YAKKOCALLOPTION]. "
		echo
		echo "USAGE: $YAKKONAME [ops <OPTION> [params] | infra <OPTION> [params]]"
		echo 
	else
		# This cluster is NOT OPERATIONAL - it's not technically a cluster at this point

		echo "There is no fully configured/operational OpenShift cluster"
		echo

		ask-user "Continue configuring cluster [${CLUSTERNAME}]" "Y" noauto
		if [ $? -eq 0 ]
		then
			process-stage-continue-clusterconfiguration progress
			yakko-process-stages progress
		else
			# Since there is no cluster, offer to delete
			ask-user "Delete existing configuration progress for [${CLUSTERNAME}]" "Y" noauto
			if [ $? -eq 0 ]
			then
				# In case there is any doubt, this clears, it - all must go!
				DELETECLUSTERNAME=${CLUSTERNAME}
				yakko-process-stages rollback
			fi
		fi
	fi
fi

####################################################################################
#####################                 YAKKO END!             #######################
####################################################################################
